Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
[32m[03/25 13:10:12 d2.engine.defaults]: [39mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[32m[03/25 13:10:12 d2.data.datasets.coco]: [39mLoaded 4280 images in COCO format from ../../dataset/SK_train_annotations.json
[32m[03/25 13:10:12 d2.data.build]: [39mRemoved 0 images with no usable annotations. 4280 images left.
[32m[03/25 13:10:12 d2.data.build]: [39mDistribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
[36m|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
[36m| General trash | 3468         |    Paper    | 5511         | Paper pack | 800          |
[36m|     Metal     | 827          |    Glass    | 900          |  Plastic   | 2591         |
[36m|   Styrofoam   | 1140         | Plastic bag | 4563         |  Battery   | 148          |
[36m|   Clothing    | 416          |             |              |            |              |
[36m|     total     | 20364        |             |              |            |              |
[32m[03/25 13:10:12 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[03/25 13:10:12 d2.data.common]: [39mSerializing 4280 elements to byte tensors and concatenating them all ...
[32m[03/25 13:10:12 d2.data.common]: [39mSerialized dataset takes 1.92 MiB
expected_results:
[]
[32m[03/25 13:10:13 d2.engine.train_loop]: [39mStarting training from iteration 0
/opt/ml/detection/baseline/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)
  num_fg = fg_inds.nonzero().numel()
[32m[03/25 13:10:16 d2.utils.events]: [39m eta: 0:58:42  iter: 9  total_loss: 3.738  loss_cls: 2.301  loss_box_reg: 0.4623  loss_rpn_cls: 1.105  loss_rpn_loc: 0.0655  time: 0.2195  data_time: 0.0301  lr: 9.991e-06  max_mem: 2342M
[32m[03/25 13:10:18 d2.utils.events]: [39m eta: 0:58:38  iter: 19  total_loss: 2.932  loss_cls: 1.785  loss_box_reg: 0.5042  loss_rpn_cls: 0.3971  loss_rpn_loc: 0.04104  time: 0.2200  data_time: 0.0192  lr: 1.9981e-05  max_mem: 2342M
[32m[03/25 13:10:20 d2.utils.events]: [39m eta: 0:58:42  iter: 29  total_loss: 1.957  loss_cls: 0.9668  loss_box_reg: 0.6487  loss_rpn_cls: 0.188  loss_rpn_loc: 0.03044  time: 0.2203  data_time: 0.0082  lr: 2.9971e-05  max_mem: 2342M
[32m[03/25 13:10:22 d2.utils.events]: [39m eta: 0:58:40  iter: 39  total_loss: 1.593  loss_cls: 0.7489  loss_box_reg: 0.6654  loss_rpn_cls: 0.1482  loss_rpn_loc: 0.02283  time: 0.2214  data_time: 0.0080  lr: 3.9961e-05  max_mem: 2342M
[32m[03/25 13:10:25 d2.utils.events]: [39m eta: 0:58:37  iter: 49  total_loss: 1.548  loss_cls: 0.669  loss_box_reg: 0.6737  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.02437  time: 0.2212  data_time: 0.0080  lr: 4.9951e-05  max_mem: 2342M
[32m[03/25 13:10:27 d2.utils.events]: [39m eta: 0:58:35  iter: 59  total_loss: 1.448  loss_cls: 0.6595  loss_box_reg: 0.6702  loss_rpn_cls: 0.1173  loss_rpn_loc: 0.03468  time: 0.2213  data_time: 0.0080  lr: 5.9941e-05  max_mem: 2342M
[32m[03/25 13:10:29 d2.utils.events]: [39m eta: 0:58:34  iter: 69  total_loss: 1.488  loss_cls: 0.647  loss_box_reg: 0.6742  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.03113  time: 0.2212  data_time: 0.0079  lr: 6.9931e-05  max_mem: 2342M
[32m[03/25 13:10:31 d2.utils.events]: [39m eta: 0:58:34  iter: 79  total_loss: 1.428  loss_cls: 0.6371  loss_box_reg: 0.7048  loss_rpn_cls: 0.09824  loss_rpn_loc: 0.02559  time: 0.2214  data_time: 0.0078  lr: 7.9921e-05  max_mem: 2342M
[32m[03/25 13:10:34 d2.utils.events]: [39m eta: 0:58:34  iter: 89  total_loss: 1.344  loss_cls: 0.5839  loss_box_reg: 0.6635  loss_rpn_cls: 0.07479  loss_rpn_loc: 0.01869  time: 0.2214  data_time: 0.0077  lr: 8.9911e-05  max_mem: 2342M
[32m[03/25 13:10:36 d2.utils.events]: [39m eta: 0:58:34  iter: 99  total_loss: 1.597  loss_cls: 0.7276  loss_box_reg: 0.6589  loss_rpn_cls: 0.1151  loss_rpn_loc: 0.04694  time: 0.2214  data_time: 0.0079  lr: 9.9901e-05  max_mem: 2342M
[32m[03/25 13:10:38 d2.utils.events]: [39m eta: 0:58:32  iter: 109  total_loss: 1.515  loss_cls: 0.7059  loss_box_reg: 0.6589  loss_rpn_cls: 0.09337  loss_rpn_loc: 0.03387  time: 0.2215  data_time: 0.0082  lr: 0.00010989  max_mem: 2342M
[32m[03/25 13:10:40 d2.utils.events]: [39m eta: 0:58:29  iter: 119  total_loss: 1.412  loss_cls: 0.6772  loss_box_reg: 0.5843  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.02099  time: 0.2217  data_time: 0.0079  lr: 0.00011988  max_mem: 2342M
[32m[03/25 13:10:42 d2.utils.events]: [39m eta: 0:58:26  iter: 129  total_loss: 1.36  loss_cls: 0.6556  loss_box_reg: 0.5266  loss_rpn_cls: 0.0947  loss_rpn_loc: 0.02398  time: 0.2216  data_time: 0.0077  lr: 0.00012987  max_mem: 2342M
[32m[03/25 13:10:45 d2.utils.events]: [39m eta: 0:58:24  iter: 139  total_loss: 1.395  loss_cls: 0.6835  loss_box_reg: 0.5141  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.03116  time: 0.2215  data_time: 0.0079  lr: 0.00013986  max_mem: 2342M
[32m[03/25 13:10:47 d2.utils.events]: [39m eta: 0:58:21  iter: 149  total_loss: 1.459  loss_cls: 0.6644  loss_box_reg: 0.528  loss_rpn_cls: 0.1677  loss_rpn_loc: 0.04528  time: 0.2214  data_time: 0.0078  lr: 0.00014985  max_mem: 2342M
[32m[03/25 13:10:49 d2.utils.events]: [39m eta: 0:58:19  iter: 159  total_loss: 1.401  loss_cls: 0.6915  loss_box_reg: 0.5407  loss_rpn_cls: 0.1389  loss_rpn_loc: 0.02704  time: 0.2214  data_time: 0.0077  lr: 0.00015984  max_mem: 2342M
[32m[03/25 13:10:51 d2.utils.events]: [39m eta: 0:58:18  iter: 169  total_loss: 1.401  loss_cls: 0.711  loss_box_reg: 0.5575  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.02515  time: 0.2215  data_time: 0.0078  lr: 0.00016983  max_mem: 2342M
[32m[03/25 13:10:54 d2.utils.events]: [39m eta: 0:58:15  iter: 179  total_loss: 1.512  loss_cls: 0.7313  loss_box_reg: 0.5941  loss_rpn_cls: 0.1254  loss_rpn_loc: 0.04972  time: 0.2214  data_time: 0.0080  lr: 0.00017982  max_mem: 2342M
[32m[03/25 13:10:56 d2.utils.events]: [39m eta: 0:58:14  iter: 189  total_loss: 1.47  loss_cls: 0.7266  loss_box_reg: 0.5661  loss_rpn_cls: 0.1456  loss_rpn_loc: 0.03792  time: 0.2218  data_time: 0.0083  lr: 0.00018981  max_mem: 2342M
[32m[03/25 13:10:58 d2.utils.events]: [39m eta: 0:58:12  iter: 199  total_loss: 1.361  loss_cls: 0.7192  loss_box_reg: 0.5219  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.02325  time: 0.2217  data_time: 0.0081  lr: 0.0001998  max_mem: 2342M
[32m[03/25 13:11:00 d2.utils.events]: [39m eta: 0:58:10  iter: 209  total_loss: 1.349  loss_cls: 0.7172  loss_box_reg: 0.5229  loss_rpn_cls: 0.09974  loss_rpn_loc: 0.01912  time: 0.2217  data_time: 0.0077  lr: 0.00020979  max_mem: 2342M
[32m[03/25 13:11:03 d2.utils.events]: [39m eta: 0:58:08  iter: 219  total_loss: 1.205  loss_cls: 0.6413  loss_box_reg: 0.4802  loss_rpn_cls: 0.09948  loss_rpn_loc: 0.01673  time: 0.2216  data_time: 0.0078  lr: 0.00021978  max_mem: 2342M
[32m[03/25 13:11:05 d2.utils.events]: [39m eta: 0:58:06  iter: 229  total_loss: 1.434  loss_cls: 0.6946  loss_box_reg: 0.5371  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.03465  time: 0.2216  data_time: 0.0078  lr: 0.00022977  max_mem: 2342M
[32m[03/25 13:11:07 d2.utils.events]: [39m eta: 0:58:04  iter: 239  total_loss: 1.523  loss_cls: 0.7288  loss_box_reg: 0.5921  loss_rpn_cls: 0.1582  loss_rpn_loc: 0.04095  time: 0.2216  data_time: 0.0077  lr: 0.00023976  max_mem: 2342M
[32m[03/25 13:11:09 d2.utils.events]: [39m eta: 0:58:02  iter: 249  total_loss: 1.523  loss_cls: 0.7297  loss_box_reg: 0.5969  loss_rpn_cls: 0.1925  loss_rpn_loc: 0.04245  time: 0.2216  data_time: 0.0077  lr: 0.00024975  max_mem: 2342M
[32m[03/25 13:11:11 d2.utils.events]: [39m eta: 0:58:01  iter: 259  total_loss: 1.46  loss_cls: 0.7202  loss_box_reg: 0.5328  loss_rpn_cls: 0.1452  loss_rpn_loc: 0.03632  time: 0.2217  data_time: 0.0078  lr: 0.00025974  max_mem: 2342M
[32m[03/25 13:11:14 d2.utils.events]: [39m eta: 0:57:59  iter: 269  total_loss: 1.415  loss_cls: 0.6927  loss_box_reg: 0.5425  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.03345  time: 0.2217  data_time: 0.0080  lr: 0.00026973  max_mem: 2342M
[32m[03/25 13:11:16 d2.utils.events]: [39m eta: 0:57:57  iter: 279  total_loss: 1.349  loss_cls: 0.673  loss_box_reg: 0.5354  loss_rpn_cls: 0.1399  loss_rpn_loc: 0.03715  time: 0.2216  data_time: 0.0080  lr: 0.00027972  max_mem: 2342M
[32m[03/25 13:11:18 d2.utils.events]: [39m eta: 0:57:55  iter: 289  total_loss: 1.284  loss_cls: 0.6284  loss_box_reg: 0.4837  loss_rpn_cls: 0.1747  loss_rpn_loc: 0.04466  time: 0.2216  data_time: 0.0078  lr: 0.00028971  max_mem: 2342M
[32m[03/25 13:11:20 d2.utils.events]: [39m eta: 0:57:53  iter: 299  total_loss: 1.162  loss_cls: 0.5824  loss_box_reg: 0.4302  loss_rpn_cls: 0.1154  loss_rpn_loc: 0.03606  time: 0.2216  data_time: 0.0078  lr: 0.0002997  max_mem: 2342M
[32m[03/25 13:11:23 d2.utils.events]: [39m eta: 0:57:51  iter: 309  total_loss: 1.326  loss_cls: 0.6725  loss_box_reg: 0.5176  loss_rpn_cls: 0.1154  loss_rpn_loc: 0.03606  time: 0.2216  data_time: 0.0078  lr: 0.00030969  max_mem: 2342M
[32m[03/25 13:11:25 d2.utils.events]: [39m eta: 0:57:49  iter: 319  total_loss: 1.546  loss_cls: 0.7361  loss_box_reg: 0.5428  loss_rpn_cls: 0.182  loss_rpn_loc: 0.06858  time: 0.2216  data_time: 0.0078  lr: 0.00031968  max_mem: 2342M
[32m[03/25 13:11:27 d2.utils.events]: [39m eta: 0:57:47  iter: 329  total_loss: 1.563  loss_cls: 0.7252  loss_box_reg: 0.5374  loss_rpn_cls: 0.205  loss_rpn_loc: 0.08784  time: 0.2220  data_time: 0.0080  lr: 0.00032967  max_mem: 2342M
[32m[03/25 13:11:29 d2.utils.events]: [39m eta: 0:57:45  iter: 339  total_loss: 1.511  loss_cls: 0.7241  loss_box_reg: 0.5005  loss_rpn_cls: 0.1609  loss_rpn_loc: 0.04199  time: 0.2221  data_time: 0.0083  lr: 0.00033966  max_mem: 2342M
[32m[03/25 13:11:32 d2.utils.events]: [39m eta: 0:57:44  iter: 349  total_loss: 1.408  loss_cls: 0.7078  loss_box_reg: 0.5148  loss_rpn_cls: 0.1256  loss_rpn_loc: 0.03076  time: 0.2221  data_time: 0.0084  lr: 0.00034965  max_mem: 2342M
[32m[03/25 13:11:34 d2.utils.events]: [39m eta: 0:57:42  iter: 359  total_loss: 1.371  loss_cls: 0.6301  loss_box_reg: 0.5406  loss_rpn_cls: 0.1446  loss_rpn_loc: 0.06067  time: 0.2222  data_time: 0.0085  lr: 0.00035964  max_mem: 2342M
[32m[03/25 13:11:36 d2.utils.events]: [39m eta: 0:57:41  iter: 369  total_loss: 1.386  loss_cls: 0.6887  loss_box_reg: 0.5236  loss_rpn_cls: 0.1261  loss_rpn_loc: 0.04575  time: 0.2223  data_time: 0.0083  lr: 0.00036963  max_mem: 2342M
[32m[03/25 13:11:38 d2.utils.events]: [39m eta: 0:57:40  iter: 379  total_loss: 1.395  loss_cls: 0.7326  loss_box_reg: 0.5192  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.03425  time: 0.2223  data_time: 0.0083  lr: 0.00037962  max_mem: 2342M
[32m[03/25 13:11:41 d2.utils.events]: [39m eta: 0:57:40  iter: 389  total_loss: 1.428  loss_cls: 0.7115  loss_box_reg: 0.5134  loss_rpn_cls: 0.1152  loss_rpn_loc: 0.03425  time: 0.2224  data_time: 0.0083  lr: 0.00038961  max_mem: 2342M
[32m[03/25 13:11:43 d2.utils.events]: [39m eta: 0:57:39  iter: 399  total_loss: 1.452  loss_cls: 0.6933  loss_box_reg: 0.5592  loss_rpn_cls: 0.1566  loss_rpn_loc: 0.04727  time: 0.2224  data_time: 0.0082  lr: 0.0003996  max_mem: 2342M
[32m[03/25 13:11:45 d2.utils.events]: [39m eta: 0:57:37  iter: 409  total_loss: 1.398  loss_cls: 0.67  loss_box_reg: 0.5409  loss_rpn_cls: 0.1735  loss_rpn_loc: 0.04968  time: 0.2226  data_time: 0.0088  lr: 0.00040959  max_mem: 2342M
[32m[03/25 13:11:48 d2.utils.events]: [39m eta: 0:57:36  iter: 419  total_loss: 1.407  loss_cls: 0.6979  loss_box_reg: 0.524  loss_rpn_cls: 0.1581  loss_rpn_loc: 0.04968  time: 0.2227  data_time: 0.0095  lr: 0.00041958  max_mem: 2342M
[32m[03/25 13:11:50 d2.utils.events]: [39m eta: 0:57:35  iter: 429  total_loss: 1.297  loss_cls: 0.7168  loss_box_reg: 0.4883  loss_rpn_cls: 0.141  loss_rpn_loc: 0.05831  time: 0.2227  data_time: 0.0088  lr: 0.00042957  max_mem: 2342M
[32m[03/25 13:11:52 d2.utils.events]: [39m eta: 0:57:33  iter: 439  total_loss: 1.361  loss_cls: 0.6496  loss_box_reg: 0.5026  loss_rpn_cls: 0.1589  loss_rpn_loc: 0.04901  time: 0.2228  data_time: 0.0086  lr: 0.00043956  max_mem: 2342M
[32m[03/25 13:11:54 d2.utils.events]: [39m eta: 0:57:32  iter: 449  total_loss: 1.52  loss_cls: 0.6918  loss_box_reg: 0.5519  loss_rpn_cls: 0.1702  loss_rpn_loc: 0.06209  time: 0.2228  data_time: 0.0085  lr: 0.00044955  max_mem: 2342M
[32m[03/25 13:11:57 d2.utils.events]: [39m eta: 0:57:32  iter: 459  total_loss: 1.453  loss_cls: 0.6837  loss_box_reg: 0.5403  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.02966  time: 0.2232  data_time: 0.0089  lr: 0.00045954  max_mem: 2342M
[32m[03/25 13:11:59 d2.utils.events]: [39m eta: 0:57:30  iter: 469  total_loss: 1.404  loss_cls: 0.7141  loss_box_reg: 0.5576  loss_rpn_cls: 0.09031  loss_rpn_loc: 0.02278  time: 0.2232  data_time: 0.0089  lr: 0.00046953  max_mem: 2342M
[32m[03/25 13:12:01 d2.utils.events]: [39m eta: 0:57:30  iter: 479  total_loss: 1.444  loss_cls: 0.7141  loss_box_reg: 0.5834  loss_rpn_cls: 0.0979  loss_rpn_loc: 0.02894  time: 0.2233  data_time: 0.0079  lr: 0.00047952  max_mem: 2342M
[32m[03/25 13:12:04 d2.utils.events]: [39m eta: 0:57:28  iter: 489  total_loss: 1.478  loss_cls: 0.6907  loss_box_reg: 0.5813  loss_rpn_cls: 0.1422  loss_rpn_loc: 0.05518  time: 0.2234  data_time: 0.0079  lr: 0.00048951  max_mem: 2342M
[32m[03/25 13:12:06 d2.utils.events]: [39m eta: 0:57:27  iter: 499  total_loss: 1.418  loss_cls: 0.6946  loss_box_reg: 0.5322  loss_rpn_cls: 0.1509  loss_rpn_loc: 0.05518  time: 0.2235  data_time: 0.0079  lr: 0.0004995  max_mem: 2342M
[32m[03/25 13:12:08 d2.utils.events]: [39m eta: 0:57:24  iter: 509  total_loss: 1.311  loss_cls: 0.6909  loss_box_reg: 0.5204  loss_rpn_cls: 0.1295  loss_rpn_loc: 0.03352  time: 0.2234  data_time: 0.0078  lr: 0.00050949  max_mem: 2342M
[32m[03/25 13:12:10 d2.utils.events]: [39m eta: 0:57:21  iter: 519  total_loss: 1.533  loss_cls: 0.7248  loss_box_reg: 0.5204  loss_rpn_cls: 0.2037  loss_rpn_loc: 0.07967  time: 0.2234  data_time: 0.0077  lr: 0.00051948  max_mem: 2342M
[32m[03/25 13:12:12 d2.utils.events]: [39m eta: 0:57:19  iter: 529  total_loss: 1.535  loss_cls: 0.6958  loss_box_reg: 0.5553  loss_rpn_cls: 0.1884  loss_rpn_loc: 0.07543  time: 0.2234  data_time: 0.0081  lr: 0.00052947  max_mem: 2342M
[32m[03/25 13:12:15 d2.utils.events]: [39m eta: 0:57:18  iter: 539  total_loss: 1.347  loss_cls: 0.6688  loss_box_reg: 0.551  loss_rpn_cls: 0.08825  loss_rpn_loc: 0.01959  time: 0.2234  data_time: 0.0081  lr: 0.00053946  max_mem: 2342M
[32m[03/25 13:12:17 d2.utils.events]: [39m eta: 0:57:17  iter: 549  total_loss: 1.393  loss_cls: 0.7237  loss_box_reg: 0.5198  loss_rpn_cls: 0.1361  loss_rpn_loc: 0.03944  time: 0.2234  data_time: 0.0077  lr: 0.00054945  max_mem: 2342M
[32m[03/25 13:12:19 d2.utils.events]: [39m eta: 0:57:15  iter: 559  total_loss: 1.401  loss_cls: 0.6759  loss_box_reg: 0.5036  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.0625  time: 0.2234  data_time: 0.0079  lr: 0.00055944  max_mem: 2342M
[32m[03/25 13:12:21 d2.utils.events]: [39m eta: 0:57:14  iter: 569  total_loss: 1.435  loss_cls: 0.7238  loss_box_reg: 0.5381  loss_rpn_cls: 0.1252  loss_rpn_loc: 0.03559  time: 0.2234  data_time: 0.0081  lr: 0.00056943  max_mem: 2342M
[32m[03/25 13:12:24 d2.utils.events]: [39m eta: 0:57:12  iter: 579  total_loss: 1.434  loss_cls: 0.7657  loss_box_reg: 0.5911  loss_rpn_cls: 0.0977  loss_rpn_loc: 0.02865  time: 0.2236  data_time: 0.0087  lr: 0.00057942  max_mem: 2342M
[32m[03/25 13:12:26 d2.utils.events]: [39m eta: 0:57:12  iter: 589  total_loss: 1.447  loss_cls: 0.7009  loss_box_reg: 0.5989  loss_rpn_cls: 0.1283  loss_rpn_loc: 0.03554  time: 0.2237  data_time: 0.0087  lr: 0.00058941  max_mem: 2342M
[32m[03/25 13:12:28 d2.utils.events]: [39m eta: 0:57:09  iter: 599  total_loss: 1.752  loss_cls: 0.845  loss_box_reg: 0.6352  loss_rpn_cls: 0.1737  loss_rpn_loc: 0.05173  time: 0.2238  data_time: 0.0081  lr: 0.0005994  max_mem: 2342M
[32m[03/25 13:12:31 d2.utils.events]: [39m eta: 0:57:08  iter: 609  total_loss: 1.576  loss_cls: 0.7623  loss_box_reg: 0.6213  loss_rpn_cls: 0.1475  loss_rpn_loc: 0.03655  time: 0.2238  data_time: 0.0083  lr: 0.00060939  max_mem: 2342M
[32m[03/25 13:12:33 d2.utils.events]: [39m eta: 0:57:07  iter: 619  total_loss: 1.436  loss_cls: 0.6458  loss_box_reg: 0.5211  loss_rpn_cls: 0.1488  loss_rpn_loc: 0.0404  time: 0.2239  data_time: 0.0086  lr: 0.00061938  max_mem: 2342M
[32m[03/25 13:12:35 d2.utils.events]: [39m eta: 0:57:06  iter: 629  total_loss: 1.364  loss_cls: 0.6564  loss_box_reg: 0.5088  loss_rpn_cls: 0.1522  loss_rpn_loc: 0.04012  time: 0.2239  data_time: 0.0083  lr: 0.00062937  max_mem: 2342M
[32m[03/25 13:12:38 d2.utils.events]: [39m eta: 0:57:05  iter: 639  total_loss: 1.349  loss_cls: 0.6716  loss_box_reg: 0.5088  loss_rpn_cls: 0.1626  loss_rpn_loc: 0.04908  time: 0.2240  data_time: 0.0081  lr: 0.00063936  max_mem: 2342M
[32m[03/25 13:12:40 d2.utils.events]: [39m eta: 0:57:04  iter: 649  total_loss: 1.392  loss_cls: 0.6578  loss_box_reg: 0.5087  loss_rpn_cls: 0.1707  loss_rpn_loc: 0.06335  time: 0.2240  data_time: 0.0084  lr: 0.00064935  max_mem: 2342M
[32m[03/25 13:12:42 d2.utils.events]: [39m eta: 0:57:02  iter: 659  total_loss: 1.319  loss_cls: 0.618  loss_box_reg: 0.4689  loss_rpn_cls: 0.1333  loss_rpn_loc: 0.03702  time: 0.2241  data_time: 0.0082  lr: 0.00065934  max_mem: 2342M
[32m[03/25 13:12:44 d2.utils.events]: [39m eta: 0:57:00  iter: 669  total_loss: 1.286  loss_cls: 0.6236  loss_box_reg: 0.5048  loss_rpn_cls: 0.1317  loss_rpn_loc: 0.02639  time: 0.2241  data_time: 0.0084  lr: 0.00066933  max_mem: 2342M
[32m[03/25 13:12:47 d2.utils.events]: [39m eta: 0:56:59  iter: 679  total_loss: 1.495  loss_cls: 0.6875  loss_box_reg: 0.5474  loss_rpn_cls: 0.1762  loss_rpn_loc: 0.04842  time: 0.2242  data_time: 0.0085  lr: 0.00067932  max_mem: 2342M
[32m[03/25 13:12:49 d2.utils.events]: [39m eta: 0:56:58  iter: 689  total_loss: 1.589  loss_cls: 0.7355  loss_box_reg: 0.5838  loss_rpn_cls: 0.1997  loss_rpn_loc: 0.05967  time: 0.2242  data_time: 0.0082  lr: 0.00068931  max_mem: 2342M
[32m[03/25 13:12:51 d2.utils.events]: [39m eta: 0:56:56  iter: 699  total_loss: 1.543  loss_cls: 0.7192  loss_box_reg: 0.558  loss_rpn_cls: 0.1368  loss_rpn_loc: 0.03939  time: 0.2242  data_time: 0.0082  lr: 0.0006993  max_mem: 2342M
[32m[03/25 13:12:53 d2.utils.events]: [39m eta: 0:56:55  iter: 709  total_loss: 1.41  loss_cls: 0.6702  loss_box_reg: 0.5161  loss_rpn_cls: 0.1466  loss_rpn_loc: 0.04242  time: 0.2242  data_time: 0.0080  lr: 0.00070929  max_mem: 2342M
[32m[03/25 13:12:56 d2.utils.events]: [39m eta: 0:56:53  iter: 719  total_loss: 1.574  loss_cls: 0.7113  loss_box_reg: 0.5505  loss_rpn_cls: 0.1724  loss_rpn_loc: 0.06087  time: 0.2242  data_time: 0.0079  lr: 0.00071928  max_mem: 2342M
[32m[03/25 13:12:58 d2.utils.events]: [39m eta: 0:56:51  iter: 729  total_loss: 1.528  loss_cls: 0.7138  loss_box_reg: 0.5677  loss_rpn_cls: 0.1586  loss_rpn_loc: 0.04273  time: 0.2243  data_time: 0.0077  lr: 0.00072927  max_mem: 2342M
[32m[03/25 13:13:00 d2.utils.events]: [39m eta: 0:56:49  iter: 739  total_loss: 1.421  loss_cls: 0.6699  loss_box_reg: 0.5498  loss_rpn_cls: 0.1285  loss_rpn_loc: 0.0339  time: 0.2242  data_time: 0.0077  lr: 0.00073926  max_mem: 2342M
[32m[03/25 13:13:03 d2.utils.events]: [39m eta: 0:56:47  iter: 749  total_loss: 1.467  loss_cls: 0.6566  loss_box_reg: 0.5401  loss_rpn_cls: 0.139  loss_rpn_loc: 0.0368  time: 0.2243  data_time: 0.0078  lr: 0.00074925  max_mem: 2342M
[32m[03/25 13:13:05 d2.utils.events]: [39m eta: 0:56:45  iter: 759  total_loss: 1.493  loss_cls: 0.6689  loss_box_reg: 0.5358  loss_rpn_cls: 0.1555  loss_rpn_loc: 0.04731  time: 0.2243  data_time: 0.0080  lr: 0.00075924  max_mem: 2342M
[32m[03/25 13:13:07 d2.utils.events]: [39m eta: 0:56:44  iter: 769  total_loss: 1.44  loss_cls: 0.653  loss_box_reg: 0.5263  loss_rpn_cls: 0.1511  loss_rpn_loc: 0.04454  time: 0.2243  data_time: 0.0083  lr: 0.00076923  max_mem: 2342M
[32m[03/25 13:13:09 d2.utils.events]: [39m eta: 0:56:42  iter: 779  total_loss: 1.306  loss_cls: 0.6253  loss_box_reg: 0.5179  loss_rpn_cls: 0.149  loss_rpn_loc: 0.03468  time: 0.2243  data_time: 0.0081  lr: 0.00077922  max_mem: 2342M
[32m[03/25 13:13:12 d2.utils.events]: [39m eta: 0:56:40  iter: 789  total_loss: 1.42  loss_cls: 0.6766  loss_box_reg: 0.5207  loss_rpn_cls: 0.1916  loss_rpn_loc: 0.05455  time: 0.2243  data_time: 0.0080  lr: 0.00078921  max_mem: 2342M
[32m[03/25 13:13:14 d2.utils.events]: [39m eta: 0:56:39  iter: 799  total_loss: 1.481  loss_cls: 0.6989  loss_box_reg: 0.6161  loss_rpn_cls: 0.1743  loss_rpn_loc: 0.0441  time: 0.2244  data_time: 0.0081  lr: 0.0007992  max_mem: 2342M
[32m[03/25 13:13:16 d2.utils.events]: [39m eta: 0:56:37  iter: 809  total_loss: 1.485  loss_cls: 0.6707  loss_box_reg: 0.55  loss_rpn_cls: 0.1593  loss_rpn_loc: 0.0455  time: 0.2243  data_time: 0.0081  lr: 0.00080919  max_mem: 2342M
[32m[03/25 13:13:18 d2.utils.events]: [39m eta: 0:56:34  iter: 819  total_loss: 1.407  loss_cls: 0.6706  loss_box_reg: 0.5334  loss_rpn_cls: 0.1694  loss_rpn_loc: 0.05944  time: 0.2243  data_time: 0.0079  lr: 0.00081918  max_mem: 2342M
[32m[03/25 13:13:21 d2.utils.events]: [39m eta: 0:56:32  iter: 829  total_loss: 1.402  loss_cls: 0.7033  loss_box_reg: 0.5403  loss_rpn_cls: 0.09074  loss_rpn_loc: 0.02965  time: 0.2243  data_time: 0.0081  lr: 0.00082917  max_mem: 2342M
[32m[03/25 13:13:23 d2.utils.events]: [39m eta: 0:56:30  iter: 839  total_loss: 1.423  loss_cls: 0.7206  loss_box_reg: 0.5461  loss_rpn_cls: 0.1177  loss_rpn_loc: 0.02993  time: 0.2243  data_time: 0.0082  lr: 0.00083916  max_mem: 2342M
[32m[03/25 13:13:25 d2.utils.events]: [39m eta: 0:56:28  iter: 849  total_loss: 1.574  loss_cls: 0.7109  loss_box_reg: 0.6207  loss_rpn_cls: 0.1387  loss_rpn_loc: 0.03789  time: 0.2243  data_time: 0.0078  lr: 0.00084915  max_mem: 2342M
[32m[03/25 13:13:27 d2.utils.events]: [39m eta: 0:56:25  iter: 859  total_loss: 1.627  loss_cls: 0.699  loss_box_reg: 0.6435  loss_rpn_cls: 0.123  loss_rpn_loc: 0.03866  time: 0.2243  data_time: 0.0077  lr: 0.00085914  max_mem: 2342M
[32m[03/25 13:13:30 d2.utils.events]: [39m eta: 0:56:23  iter: 869  total_loss: 1.416  loss_cls: 0.6463  loss_box_reg: 0.5746  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.03936  time: 0.2243  data_time: 0.0076  lr: 0.00086913  max_mem: 2342M
[32m[03/25 13:13:32 d2.utils.events]: [39m eta: 0:56:22  iter: 879  total_loss: 1.53  loss_cls: 0.6784  loss_box_reg: 0.5671  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.04804  time: 0.2243  data_time: 0.0079  lr: 0.00087912  max_mem: 2342M
[32m[03/25 13:13:34 d2.utils.events]: [39m eta: 0:56:20  iter: 889  total_loss: 1.53  loss_cls: 0.6998  loss_box_reg: 0.593  loss_rpn_cls: 0.1585  loss_rpn_loc: 0.04801  time: 0.2243  data_time: 0.0080  lr: 0.00088911  max_mem: 2342M
[32m[03/25 13:13:36 d2.utils.events]: [39m eta: 0:56:18  iter: 899  total_loss: 1.47  loss_cls: 0.7067  loss_box_reg: 0.5522  loss_rpn_cls: 0.1462  loss_rpn_loc: 0.03639  time: 0.2243  data_time: 0.0077  lr: 0.0008991  max_mem: 2342M
[32m[03/25 13:13:39 d2.utils.events]: [39m eta: 0:56:16  iter: 909  total_loss: 1.445  loss_cls: 0.7119  loss_box_reg: 0.5782  loss_rpn_cls: 0.1519  loss_rpn_loc: 0.03508  time: 0.2243  data_time: 0.0077  lr: 0.00090909  max_mem: 2342M
[32m[03/25 13:13:41 d2.utils.events]: [39m eta: 0:56:14  iter: 919  total_loss: 1.369  loss_cls: 0.6497  loss_box_reg: 0.5732  loss_rpn_cls: 0.1519  loss_rpn_loc: 0.03056  time: 0.2243  data_time: 0.0078  lr: 0.00091908  max_mem: 2342M
[32m[03/25 13:13:43 d2.utils.events]: [39m eta: 0:56:12  iter: 929  total_loss: 1.625  loss_cls: 0.6838  loss_box_reg: 0.5993  loss_rpn_cls: 0.1695  loss_rpn_loc: 0.05582  time: 0.2243  data_time: 0.0082  lr: 0.00092907  max_mem: 2342M
[32m[03/25 13:13:45 d2.utils.events]: [39m eta: 0:56:10  iter: 939  total_loss: 1.621  loss_cls: 0.7092  loss_box_reg: 0.5918  loss_rpn_cls: 0.1998  loss_rpn_loc: 0.06549  time: 0.2243  data_time: 0.0081  lr: 0.00093906  max_mem: 2342M
[32m[03/25 13:13:48 d2.utils.events]: [39m eta: 0:56:08  iter: 949  total_loss: 1.574  loss_cls: 0.7207  loss_box_reg: 0.5802  loss_rpn_cls: 0.179  loss_rpn_loc: 0.06606  time: 0.2243  data_time: 0.0078  lr: 0.00094905  max_mem: 2342M
[32m[03/25 13:13:50 d2.utils.events]: [39m eta: 0:56:06  iter: 959  total_loss: 1.503  loss_cls: 0.7019  loss_box_reg: 0.5964  loss_rpn_cls: 0.1587  loss_rpn_loc: 0.05635  time: 0.2243  data_time: 0.0078  lr: 0.00095904  max_mem: 2342M
[32m[03/25 13:13:52 d2.utils.events]: [39m eta: 0:56:04  iter: 969  total_loss: 1.321  loss_cls: 0.659  loss_box_reg: 0.5251  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.02981  time: 0.2243  data_time: 0.0078  lr: 0.00096903  max_mem: 2342M
[32m[03/25 13:13:54 d2.utils.events]: [39m eta: 0:56:03  iter: 979  total_loss: 1.534  loss_cls: 0.7041  loss_box_reg: 0.5667  loss_rpn_cls: 0.1581  loss_rpn_loc: 0.04178  time: 0.2244  data_time: 0.0095  lr: 0.00097902  max_mem: 2342M
[32m[03/25 13:13:57 d2.utils.events]: [39m eta: 0:56:00  iter: 989  total_loss: 1.626  loss_cls: 0.7113  loss_box_reg: 0.5654  loss_rpn_cls: 0.1708  loss_rpn_loc: 0.06669  time: 0.2243  data_time: 0.0095  lr: 0.00098901  max_mem: 2342M
[32m[03/25 13:13:59 d2.utils.events]: [39m eta: 0:55:58  iter: 999  total_loss: 1.545  loss_cls: 0.7073  loss_box_reg: 0.5669  loss_rpn_cls: 0.2166  loss_rpn_loc: 0.06508  time: 0.2244  data_time: 0.0089  lr: 0.000999  max_mem: 2342M
[32m[03/25 13:14:01 d2.utils.events]: [39m eta: 0:55:57  iter: 1009  total_loss: 1.432  loss_cls: 0.6654  loss_box_reg: 0.5684  loss_rpn_cls: 0.1194  loss_rpn_loc: 0.04307  time: 0.2244  data_time: 0.0089  lr: 0.001  max_mem: 2342M
[32m[03/25 13:14:04 d2.utils.events]: [39m eta: 0:55:54  iter: 1019  total_loss: 1.432  loss_cls: 0.6316  loss_box_reg: 0.5639  loss_rpn_cls: 0.1283  loss_rpn_loc: 0.04079  time: 0.2244  data_time: 0.0082  lr: 0.001  max_mem: 2342M
[32m[03/25 13:14:06 d2.utils.events]: [39m eta: 0:55:52  iter: 1029  total_loss: 1.457  loss_cls: 0.6417  loss_box_reg: 0.5263  loss_rpn_cls: 0.1567  loss_rpn_loc: 0.04321  time: 0.2244  data_time: 0.0081  lr: 0.001  max_mem: 2342M
[32m[03/25 13:14:08 d2.utils.events]: [39m eta: 0:55:50  iter: 1039  total_loss: 1.192  loss_cls: 0.5716  loss_box_reg: 0.4752  loss_rpn_cls: 0.1258  loss_rpn_loc: 0.03324  time: 0.2244  data_time: 0.0079  lr: 0.001  max_mem: 2342M
[32m[03/25 13:14:10 d2.utils.events]: [39m eta: 0:55:48  iter: 1049  total_loss: 1.509  loss_cls: 0.6858  loss_box_reg: 0.5411  loss_rpn_cls: 0.1587  loss_rpn_loc: 0.04706  time: 0.2244  data_time: 0.0081  lr: 0.001  max_mem: 2342M
[32m[03/25 13:14:13 d2.utils.events]: [39m eta: 0:55:46  iter: 1059  total_loss: 1.496  loss_cls: 0.7296  loss_box_reg: 0.5753  loss_rpn_cls: 0.1565  loss_rpn_loc: 0.05165  time: 0.2245  data_time: 0.0085  lr: 0.001  max_mem: 2342M
Traceback (most recent call last):
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/catalog.py", line 51, in get
    f = self[name]
  File "/opt/conda/envs/detection/lib/python3.7/collections/__init__.py", line 1027, in __getitem__
    raise KeyError(key)
KeyError: 'coco_test_train'
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "train.py", line 123, in <module>
    trainer.train()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 491, in train
    super().train(self.start_iter, self.max_iter)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 151, in train
    self.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 181, in after_step
    h.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 449, in after_step
    self._do_eval()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 422, in _do_eval
    results = self._func()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 460, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 600, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 556, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name)
  File "/opt/ml/detection/baseline/detectron2/detectron2/config/config.py", line 207, in wrapped
    explicit_args = _get_args_from_config(from_config, *args, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/config/config.py", line 245, in _get_args_from_config
    ret = from_config_func(*args, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/build.py", line 417, in _test_loader_from_config
    else None,
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/build.py", line 232, in get_detection_dataset_dicts
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in names]
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/build.py", line 232, in <listcomp>
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in names]
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/catalog.py", line 57, in get
    ) from e
KeyError: "Dataset 'coco_test_train' is not registered! Available datasets are: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_minival_100, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2014_minival_100, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_train_panoptic, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_panoptic, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, coco_2017_val_100_panoptic, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, cityscapes_fine_panoptic_train, cityscapes_fine_panoptic_val, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, ade20k_sem_seg_train, ade20k_sem_seg_val, coco_trash_train, coco_trash_test"
[31m[4m[5mERROR[39m[24m[25m [32m[03/25 13:14:16 d2.engine.train_loop]: [39mException during training:
Traceback (most recent call last):
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/catalog.py", line 51, in get
    f = self[name]
  File "/opt/conda/envs/detection/lib/python3.7/collections/__init__.py", line 1027, in __getitem__
    raise KeyError(key)
KeyError: 'coco_test_train'
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 151, in train
    self.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 181, in after_step
    h.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 449, in after_step
    self._do_eval()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 422, in _do_eval
    results = self._func()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 460, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 600, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 556, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name)
  File "/opt/ml/detection/baseline/detectron2/detectron2/config/config.py", line 207, in wrapped
    explicit_args = _get_args_from_config(from_config, *args, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/config/config.py", line 245, in _get_args_from_config
    ret = from_config_func(*args, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/build.py", line 417, in _test_loader_from_config
    else None,
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/build.py", line 232, in get_detection_dataset_dicts
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in names]
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/build.py", line 232, in <listcomp>
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in names]
  File "/opt/ml/detection/baseline/detectron2/detectron2/data/catalog.py", line 57, in get
    ) from e
KeyError: "Dataset 'coco_test_train' is not registered! Available datasets are: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_minival_100, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2014_minival_100, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_train_panoptic, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_panoptic, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, coco_2017_val_100_panoptic, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, cityscapes_fine_panoptic_train, cityscapes_fine_panoptic_val, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, ade20k_sem_seg_train, ade20k_sem_seg_val, coco_trash_train, coco_trash_test"
[32m[03/25 13:14:16 d2.engine.hooks]: [39mOverall training speed: 1067 iterations in 0:03:59 (0.2248 s / it)
[32m[03/25 13:14:16 d2.engine.hooks]: [39mTotal training time: 0:04:01 (0:00:01 on hooks)
[32m[03/25 13:14:16 d2.utils.events]: [39m eta: 0:55:44  iter: 1069  total_loss: 1.424  loss_cls: 0.6656  loss_box_reg: 0.5648  loss_rpn_cls: 0.1299  loss_rpn_loc: 0.04767  time: 0.2245  data_time: 0.0087  lr: 0.001  max_mem: 2342M