Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
/opt/ml/detection/baseline/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)
  num_fg = fg_inds.nonzero().numel()
[32m[03/25 12:13:01 d2.engine.defaults]: [39mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[32m[03/25 12:13:01 d2.data.datasets.coco]: [39mLoaded 4883 images in COCO format from ../../dataset/train.json
[32m[03/25 12:13:02 d2.data.build]: [39mRemoved 0 images with no usable annotations. 4883 images left.
[32m[03/25 12:13:02 d2.data.build]: [39mDistribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
[36m|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
[36m| General trash | 3966         |    Paper    | 6352         | Paper pack | 897          |
[36m|     Metal     | 936          |    Glass    | 982          |  Plastic   | 2943         |
[36m|   Styrofoam   | 1263         | Plastic bag | 5178         |  Battery   | 159          |
[36m|   Clothing    | 468          |             |              |            |              |
[36m|     total     | 23144        |             |              |            |              |
[32m[03/25 12:13:02 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[03/25 12:13:02 d2.data.common]: [39mSerializing 4883 elements to byte tensors and concatenating them all ...
[32m[03/25 12:13:02 d2.data.common]: [39mSerialized dataset takes 2.19 MiB
expected_results:
[]
[32m[03/25 12:13:02 d2.engine.train_loop]: [39mStarting training from iteration 0
[32m[03/25 12:13:15 d2.utils.events]: [39m eta: 2:28:01  iter: 19  total_loss: 2.824  loss_cls: 2.023  loss_box_reg: 0.731  loss_rpn_cls: 0.07195  loss_rpn_loc: 0.03075  time: 0.5942  data_time: 0.0303  lr: 1.9981e-05  max_mem: 6536M
[32m[03/25 12:13:27 d2.utils.events]: [39m eta: 2:27:06  iter: 39  total_loss: 1.693  loss_cls: 0.7845  loss_box_reg: 0.7782  loss_rpn_cls: 0.05177  loss_rpn_loc: 0.04244  time: 0.5932  data_time: 0.0130  lr: 3.9961e-05  max_mem: 6536M
[32m[03/25 12:13:39 d2.utils.events]: [39m eta: 2:26:42  iter: 59  total_loss: 1.609  loss_cls: 0.7118  loss_box_reg: 0.7178  loss_rpn_cls: 0.04382  loss_rpn_loc: 0.04622  time: 0.5916  data_time: 0.0129  lr: 5.9941e-05  max_mem: 6536M
[32m[03/25 12:13:50 d2.utils.events]: [39m eta: 2:26:28  iter: 79  total_loss: 1.419  loss_cls: 0.6144  loss_box_reg: 0.6957  loss_rpn_cls: 0.02751  loss_rpn_loc: 0.02808  time: 0.5912  data_time: 0.0122  lr: 7.9921e-05  max_mem: 6536M
[32m[03/25 12:14:02 d2.utils.events]: [39m eta: 2:26:15  iter: 99  total_loss: 1.33  loss_cls: 0.6991  loss_box_reg: 0.554  loss_rpn_cls: 0.02715  loss_rpn_loc: 0.02811  time: 0.5909  data_time: 0.0122  lr: 9.9901e-05  max_mem: 6536M
[32m[03/25 12:14:14 d2.utils.events]: [39m eta: 2:26:04  iter: 119  total_loss: 1.376  loss_cls: 0.6978  loss_box_reg: 0.53  loss_rpn_cls: 0.04511  loss_rpn_loc: 0.04834  time: 0.5906  data_time: 0.0126  lr: 0.00011988  max_mem: 6536M
[32m[03/25 12:14:26 d2.utils.events]: [39m eta: 2:25:58  iter: 139  total_loss: 1.261  loss_cls: 0.6524  loss_box_reg: 0.5132  loss_rpn_cls: 0.05472  loss_rpn_loc: 0.03278  time: 0.5914  data_time: 0.0145  lr: 0.00013986  max_mem: 6536M
[32m[03/25 12:14:38 d2.utils.events]: [39m eta: 2:25:47  iter: 159  total_loss: 1.197  loss_cls: 0.6668  loss_box_reg: 0.4249  loss_rpn_cls: 0.05033  loss_rpn_loc: 0.02343  time: 0.5914  data_time: 0.0122  lr: 0.00015984  max_mem: 6536M
[32m[03/25 12:14:50 d2.utils.events]: [39m eta: 2:25:31  iter: 179  total_loss: 1.189  loss_cls: 0.6679  loss_box_reg: 0.4505  loss_rpn_cls: 0.02965  loss_rpn_loc: 0.01983  time: 0.5910  data_time: 0.0122  lr: 0.00017982  max_mem: 6536M
[32m[03/25 12:15:01 d2.utils.events]: [39m eta: 2:25:21  iter: 199  total_loss: 1.221  loss_cls: 0.6312  loss_box_reg: 0.4473  loss_rpn_cls: 0.04954  loss_rpn_loc: 0.02441  time: 0.5909  data_time: 0.0125  lr: 0.0001998  max_mem: 6536M
[32m[03/25 12:15:13 d2.utils.events]: [39m eta: 2:25:09  iter: 219  total_loss: 1.277  loss_cls: 0.6511  loss_box_reg: 0.4753  loss_rpn_cls: 0.0677  loss_rpn_loc: 0.05039  time: 0.5909  data_time: 0.0131  lr: 0.00021978  max_mem: 6536M
[32m[03/25 12:15:25 d2.utils.events]: [39m eta: 2:24:58  iter: 239  total_loss: 1.181  loss_cls: 0.6028  loss_box_reg: 0.4398  loss_rpn_cls: 0.06966  loss_rpn_loc: 0.06044  time: 0.5908  data_time: 0.0121  lr: 0.00023976  max_mem: 6536M
[32m[03/25 12:15:37 d2.utils.events]: [39m eta: 2:24:47  iter: 259  total_loss: 1.303  loss_cls: 0.6828  loss_box_reg: 0.4669  loss_rpn_cls: 0.05008  loss_rpn_loc: 0.06058  time: 0.5907  data_time: 0.0123  lr: 0.00025974  max_mem: 6536M
[32m[03/25 12:15:49 d2.utils.events]: [39m eta: 2:24:33  iter: 279  total_loss: 1.124  loss_cls: 0.6232  loss_box_reg: 0.4265  loss_rpn_cls: 0.05409  loss_rpn_loc: 0.04065  time: 0.5905  data_time: 0.0122  lr: 0.00027972  max_mem: 6536M
[32m[03/25 12:16:01 d2.utils.events]: [39m eta: 2:24:22  iter: 299  total_loss: 1.338  loss_cls: 0.6981  loss_box_reg: 0.4726  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.04481  time: 0.5906  data_time: 0.0136  lr: 0.0002997  max_mem: 6536M
[32m[03/25 12:16:12 d2.utils.events]: [39m eta: 2:24:11  iter: 319  total_loss: 1.24  loss_cls: 0.6309  loss_box_reg: 0.4972  loss_rpn_cls: 0.06677  loss_rpn_loc: 0.04142  time: 0.5906  data_time: 0.0125  lr: 0.00031968  max_mem: 6536M
[32m[03/25 12:16:24 d2.utils.events]: [39m eta: 2:23:57  iter: 339  total_loss: 1.251  loss_cls: 0.6649  loss_box_reg: 0.4752  loss_rpn_cls: 0.05805  loss_rpn_loc: 0.03687  time: 0.5905  data_time: 0.0129  lr: 0.00033966  max_mem: 6536M
[32m[03/25 12:16:36 d2.utils.events]: [39m eta: 2:23:45  iter: 359  total_loss: 1.404  loss_cls: 0.6983  loss_box_reg: 0.5012  loss_rpn_cls: 0.06378  loss_rpn_loc: 0.03456  time: 0.5904  data_time: 0.0123  lr: 0.00035964  max_mem: 6536M
[32m[03/25 12:16:48 d2.utils.events]: [39m eta: 2:23:34  iter: 379  total_loss: 1.146  loss_cls: 0.6234  loss_box_reg: 0.4586  loss_rpn_cls: 0.05062  loss_rpn_loc: 0.03058  time: 0.5905  data_time: 0.0137  lr: 0.00037962  max_mem: 6536M
[32m[03/25 12:17:00 d2.utils.events]: [39m eta: 2:23:24  iter: 399  total_loss: 1.225  loss_cls: 0.6101  loss_box_reg: 0.4919  loss_rpn_cls: 0.06506  loss_rpn_loc: 0.03917  time: 0.5905  data_time: 0.0127  lr: 0.0003996  max_mem: 6536M
[32m[03/25 12:17:11 d2.utils.events]: [39m eta: 2:23:12  iter: 419  total_loss: 1.392  loss_cls: 0.7197  loss_box_reg: 0.4909  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.07335  time: 0.5905  data_time: 0.0123  lr: 0.00041958  max_mem: 6536M
[32m[03/25 12:17:23 d2.utils.events]: [39m eta: 2:22:59  iter: 439  total_loss: 1.271  loss_cls: 0.6583  loss_box_reg: 0.4638  loss_rpn_cls: 0.06362  loss_rpn_loc: 0.04143  time: 0.5904  data_time: 0.0125  lr: 0.00043956  max_mem: 6536M
[32m[03/25 12:17:35 d2.utils.events]: [39m eta: 2:22:48  iter: 459  total_loss: 1.21  loss_cls: 0.5702  loss_box_reg: 0.4635  loss_rpn_cls: 0.09455  loss_rpn_loc: 0.04201  time: 0.5903  data_time: 0.0123  lr: 0.00045954  max_mem: 6536M
[32m[03/25 12:17:47 d2.utils.events]: [39m eta: 2:22:36  iter: 479  total_loss: 1.275  loss_cls: 0.6143  loss_box_reg: 0.4699  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.04752  time: 0.5904  data_time: 0.0123  lr: 0.00047952  max_mem: 6536M
[32m[03/25 12:17:59 d2.utils.events]: [39m eta: 2:22:25  iter: 499  total_loss: 1.231  loss_cls: 0.6237  loss_box_reg: 0.4723  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.04108  time: 0.5904  data_time: 0.0128  lr: 0.0004995  max_mem: 6536M
[32m[03/25 12:18:10 d2.utils.events]: [39m eta: 2:22:13  iter: 519  total_loss: 1.207  loss_cls: 0.5937  loss_box_reg: 0.4585  loss_rpn_cls: 0.0823  loss_rpn_loc: 0.03897  time: 0.5904  data_time: 0.0128  lr: 0.00051948  max_mem: 6536M
[32m[03/25 12:18:22 d2.utils.events]: [39m eta: 2:22:02  iter: 539  total_loss: 1.383  loss_cls: 0.7384  loss_box_reg: 0.5606  loss_rpn_cls: 0.06769  loss_rpn_loc: 0.02702  time: 0.5903  data_time: 0.0127  lr: 0.00053946  max_mem: 6536M
[32m[03/25 12:18:34 d2.utils.events]: [39m eta: 2:21:50  iter: 559  total_loss: 1.267  loss_cls: 0.635  loss_box_reg: 0.5062  loss_rpn_cls: 0.07116  loss_rpn_loc: 0.04195  time: 0.5904  data_time: 0.0129  lr: 0.00055944  max_mem: 6536M
[32m[03/25 12:18:46 d2.utils.events]: [39m eta: 2:21:39  iter: 579  total_loss: 1.253  loss_cls: 0.6428  loss_box_reg: 0.5094  loss_rpn_cls: 0.05756  loss_rpn_loc: 0.03191  time: 0.5904  data_time: 0.0130  lr: 0.00057942  max_mem: 6536M
[32m[03/25 12:18:58 d2.utils.events]: [39m eta: 2:21:28  iter: 599  total_loss: 1.352  loss_cls: 0.6657  loss_box_reg: 0.5007  loss_rpn_cls: 0.0811  loss_rpn_loc: 0.06036  time: 0.5904  data_time: 0.0132  lr: 0.0005994  max_mem: 6536M
[32m[03/25 12:19:10 d2.utils.events]: [39m eta: 2:21:17  iter: 619  total_loss: 1.432  loss_cls: 0.7159  loss_box_reg: 0.5492  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.06076  time: 0.5905  data_time: 0.0131  lr: 0.00061938  max_mem: 6536M
[32m[03/25 12:19:21 d2.utils.events]: [39m eta: 2:21:05  iter: 639  total_loss: 1.156  loss_cls: 0.5593  loss_box_reg: 0.4514  loss_rpn_cls: 0.06174  loss_rpn_loc: 0.04189  time: 0.5905  data_time: 0.0125  lr: 0.00063936  max_mem: 6536M
[32m[03/25 12:19:33 d2.utils.events]: [39m eta: 2:20:55  iter: 659  total_loss: 1.521  loss_cls: 0.7419  loss_box_reg: 0.5871  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.05319  time: 0.5906  data_time: 0.0136  lr: 0.00065934  max_mem: 6536M
[32m[03/25 12:19:45 d2.utils.events]: [39m eta: 2:20:43  iter: 679  total_loss: 1.365  loss_cls: 0.7237  loss_box_reg: 0.5202  loss_rpn_cls: 0.07438  loss_rpn_loc: 0.05291  time: 0.5906  data_time: 0.0134  lr: 0.00067932  max_mem: 6536M
[32m[03/25 12:19:57 d2.utils.events]: [39m eta: 2:20:32  iter: 699  total_loss: 1.404  loss_cls: 0.6994  loss_box_reg: 0.5063  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.05789  time: 0.5906  data_time: 0.0127  lr: 0.0006993  max_mem: 6536M
[32m[03/25 12:20:09 d2.utils.events]: [39m eta: 2:20:20  iter: 719  total_loss: 1.407  loss_cls: 0.6115  loss_box_reg: 0.5362  loss_rpn_cls: 0.1367  loss_rpn_loc: 0.0445  time: 0.5908  data_time: 0.0134  lr: 0.00071928  max_mem: 6536M
[32m[03/25 12:20:21 d2.utils.events]: [39m eta: 2:20:09  iter: 739  total_loss: 1.533  loss_cls: 0.7311  loss_box_reg: 0.5943  loss_rpn_cls: 0.1497  loss_rpn_loc: 0.05483  time: 0.5909  data_time: 0.0132  lr: 0.00073926  max_mem: 6536M
[32m[03/25 12:20:33 d2.utils.events]: [39m eta: 2:19:58  iter: 759  total_loss: 2.058  loss_cls: 0.7976  loss_box_reg: 0.5651  loss_rpn_cls: 0.2942  loss_rpn_loc: 0.1287  time: 0.5910  data_time: 0.0133  lr: 0.00075924  max_mem: 6536M
[32m[03/25 12:20:45 d2.utils.events]: [39m eta: 2:19:46  iter: 779  total_loss: 5.348  loss_cls: 2.46  loss_box_reg: 0.899  loss_rpn_cls: 1.164  loss_rpn_loc: 0.3666  time: 0.5909  data_time: 0.0132  lr: 0.00077922  max_mem: 6536M
[32m[03/25 12:20:56 d2.utils.events]: [39m eta: 2:19:34  iter: 799  total_loss: 468  loss_cls: 104  loss_box_reg: 15.05  loss_rpn_cls: 121.6  loss_rpn_loc: 34.81  time: 0.5908  data_time: 0.0126  lr: 0.0007992  max_mem: 6536M
[32m[03/25 12:21:08 d2.utils.events]: [39m eta: 2:19:21  iter: 819  total_loss: 8081  loss_cls: 1524  loss_box_reg: 2657  loss_rpn_cls: 2021  loss_rpn_loc: 984.4  time: 0.5904  data_time: 0.0125  lr: 0.00081918  max_mem: 6536M
[32m[03/25 12:21:19 d2.utils.events]: [39m eta: 2:19:09  iter: 839  total_loss: 903.6  loss_cls: 296.4  loss_box_reg: 277.1  loss_rpn_cls: 182.9  loss_rpn_loc: 54.87  time: 0.5900  data_time: 0.0140  lr: 0.00083916  max_mem: 6536M
[32m[03/25 12:21:31 d2.utils.events]: [39m eta: 2:18:57  iter: 859  total_loss: 8216  loss_cls: 1901  loss_box_reg: 4311  loss_rpn_cls: 1575  loss_rpn_loc: 525  time: 0.5895  data_time: 0.0130  lr: 0.00085914  max_mem: 6536M
[32m[03/25 12:21:42 d2.utils.events]: [39m eta: 2:18:44  iter: 879  total_loss: 3.267e+04  loss_cls: 1.605e+04  loss_box_reg: 1.159e+04  loss_rpn_cls: 4218  loss_rpn_loc: 1056  time: 0.5891  data_time: 0.0132  lr: 0.00087912  max_mem: 6536M
[32m[03/25 12:21:54 d2.utils.events]: [39m eta: 2:18:31  iter: 899  total_loss: 3.102e+04  loss_cls: 7388  loss_box_reg: 1.494e+04  loss_rpn_cls: 1847  loss_rpn_loc: 1395  time: 0.5887  data_time: 0.0134  lr: 0.0008991  max_mem: 6536M
[32m[03/25 12:22:05 d2.utils.events]: [39m eta: 2:18:18  iter: 919  total_loss: 4.765e+04  loss_cls: 9343  loss_box_reg: 1.657e+04  loss_rpn_cls: 1.479e+04  loss_rpn_loc: 8754  time: 0.5883  data_time: 0.0134  lr: 0.00091908  max_mem: 6536M
[32m[03/25 12:22:16 d2.utils.events]: [39m eta: 2:18:05  iter: 939  total_loss: 5.292e+04  loss_cls: 1.201e+04  loss_box_reg: 2.429e+04  loss_rpn_cls: 5406  loss_rpn_loc: 2509  time: 0.5878  data_time: 0.0123  lr: 0.00093906  max_mem: 6536M
[32m[03/25 12:22:28 d2.utils.events]: [39m eta: 2:17:53  iter: 959  total_loss: 4.355e+04  loss_cls: 8287  loss_box_reg: 1.889e+04  loss_rpn_cls: 4356  loss_rpn_loc: 3994  time: 0.5875  data_time: 0.0128  lr: 0.00095904  max_mem: 6536M
[32m[03/25 12:22:39 d2.utils.events]: [39m eta: 2:17:40  iter: 979  total_loss: 1.643e+05  loss_cls: 2.9e+04  loss_box_reg: 8.669e+04  loss_rpn_cls: 8583  loss_rpn_loc: 5947  time: 0.5871  data_time: 0.0145  lr: 0.00097902  max_mem: 6536M
[32m[03/25 12:22:51 d2.utils.events]: [39m eta: 2:17:28  iter: 999  total_loss: 1.006e+05  loss_cls: 3.081e+04  loss_box_reg: 6.09e+04  loss_rpn_cls: 3488  loss_rpn_loc: 2040  time: 0.5868  data_time: 0.0126  lr: 0.000999  max_mem: 6536M
[32m[03/25 12:23:02 d2.utils.events]: [39m eta: 2:17:15  iter: 1019  total_loss: 5.873e+06  loss_cls: 1.433e+06  loss_box_reg: 3.642e+06  loss_rpn_cls: 5.72e+05  loss_rpn_loc: 4.311e+05  time: 0.5864  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:23:13 d2.utils.events]: [39m eta: 2:17:01  iter: 1039  total_loss: 3.051e+06  loss_cls: 3.416e+05  loss_box_reg: 1.588e+06  loss_rpn_cls: 5.75e+05  loss_rpn_loc: 5.929e+05  time: 0.5860  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:23:25 d2.utils.events]: [39m eta: 2:16:48  iter: 1059  total_loss: 7.152e+05  loss_cls: 1.582e+05  loss_box_reg: 3.092e+05  loss_rpn_cls: 8.987e+04  loss_rpn_loc: 9.941e+04  time: 0.5856  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:23:36 d2.utils.events]: [39m eta: 2:16:36  iter: 1079  total_loss: 1.094e+06  loss_cls: 8634  loss_box_reg: 5665  loss_rpn_cls: 4.463e+05  loss_rpn_loc: 4.114e+05  time: 0.5853  data_time: 0.0133  lr: 0.001  max_mem: 6536M
[32m[03/25 12:23:48 d2.utils.events]: [39m eta: 2:16:22  iter: 1099  total_loss: 1.51e+07  loss_cls: 2.393  loss_box_reg: 0.05389  loss_rpn_cls: 1.126e+07  loss_rpn_loc: 4.386e+06  time: 0.5851  data_time: 0.0148  lr: 0.001  max_mem: 6536M
[32m[03/25 12:23:59 d2.utils.events]: [39m eta: 2:16:09  iter: 1119  total_loss: 6.401e+07  loss_cls: 2.397  loss_box_reg: 0.01867  loss_rpn_cls: 3.038e+07  loss_rpn_loc: 4.133e+07  time: 0.5848  data_time: 0.0136  lr: 0.001  max_mem: 6536M
[32m[03/25 12:24:10 d2.utils.events]: [39m eta: 2:15:55  iter: 1139  total_loss: 4.091e+08  loss_cls: 2.417  loss_box_reg: 0.01485  loss_rpn_cls: 3.302e+07  loss_rpn_loc: 1.619e+08  time: 0.5845  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:24:22 d2.utils.events]: [39m eta: 2:15:41  iter: 1159  total_loss: 4.359e+06  loss_cls: 2.409  loss_box_reg: 0.006212  loss_rpn_cls: 1.132e+06  loss_rpn_loc: 3.236e+06  time: 0.5841  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:24:33 d2.utils.events]: [39m eta: 2:15:28  iter: 1179  total_loss: 2.808e+07  loss_cls: 2.356  loss_box_reg: 0.003981  loss_rpn_cls: 1.014e+07  loss_rpn_loc: 1.932e+07  time: 0.5839  data_time: 0.0141  lr: 0.001  max_mem: 6536M
[32m[03/25 12:24:44 d2.utils.events]: [39m eta: 2:15:14  iter: 1199  total_loss: 4.391e+07  loss_cls: 2.341  loss_box_reg: 0.003134  loss_rpn_cls: 1.563e+07  loss_rpn_loc: 2.858e+07  time: 0.5836  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:24:56 d2.utils.events]: [39m eta: 2:14:59  iter: 1219  total_loss: 1.413e+08  loss_cls: 2.342  loss_box_reg: 0.002637  loss_rpn_cls: 4.584e+07  loss_rpn_loc: 9.629e+07  time: 0.5833  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:25:07 d2.utils.events]: [39m eta: 2:14:44  iter: 1239  total_loss: 3.58e+09  loss_cls: 2.287  loss_box_reg: 0.002789  loss_rpn_cls: 1.416e+09  loss_rpn_loc: 2.309e+09  time: 0.5831  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:25:19 d2.utils.events]: [39m eta: 2:14:29  iter: 1259  total_loss: 2.479e+09  loss_cls: 2.236  loss_box_reg: 0.004685  loss_rpn_cls: 1.277e+09  loss_rpn_loc: 8.691e+08  time: 0.5830  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:25:30 d2.utils.events]: [39m eta: 2:14:12  iter: 1279  total_loss: 4.46e+10  loss_cls: 2.212  loss_box_reg: 0.004519  loss_rpn_cls: 2.241e+10  loss_rpn_loc: 1.434e+10  time: 0.5828  data_time: 0.0125  lr: 0.001  max_mem: 6536M
[32m[03/25 12:25:41 d2.utils.events]: [39m eta: 2:13:28  iter: 1299  total_loss: 7.239e+08  loss_cls: 2.297  loss_box_reg: 0.003451  loss_rpn_cls: 3.638e+08  loss_rpn_loc: 3.706e+08  time: 0.5826  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:25:53 d2.utils.events]: [39m eta: 2:12:36  iter: 1319  total_loss: 1.109e+09  loss_cls: 2.302  loss_box_reg: 0.002882  loss_rpn_cls: 3.884e+08  loss_rpn_loc: 7.645e+08  time: 0.5824  data_time: 0.0143  lr: 0.001  max_mem: 6536M
[32m[03/25 12:26:04 d2.utils.events]: [39m eta: 2:11:46  iter: 1339  total_loss: 2.677e+10  loss_cls: 2.317  loss_box_reg: 0.006432  loss_rpn_cls: 1.468e+10  loss_rpn_loc: 1.274e+10  time: 0.5822  data_time: 0.0145  lr: 0.001  max_mem: 6536M
[32m[03/25 12:26:16 d2.utils.events]: [39m eta: 2:11:05  iter: 1359  total_loss: 3.072e+09  loss_cls: 2.288  loss_box_reg: 0.002968  loss_rpn_cls: 1.999e+09  loss_rpn_loc: 1.146e+09  time: 0.5820  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:26:27 d2.utils.events]: [39m eta: 2:10:35  iter: 1379  total_loss: 1.906e+10  loss_cls: 2.287  loss_box_reg: 0.002782  loss_rpn_cls: 4.839e+09  loss_rpn_loc: 1.55e+10  time: 0.5818  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:26:39 d2.utils.events]: [39m eta: 2:10:11  iter: 1399  total_loss: 8.68e+09  loss_cls: 2.105  loss_box_reg: 0.002637  loss_rpn_cls: 6.691e+09  loss_rpn_loc: 2.705e+09  time: 0.5817  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:26:50 d2.utils.events]: [39m eta: 2:09:50  iter: 1419  total_loss: 2.52e+09  loss_cls: 2.076  loss_box_reg: 0.001637  loss_rpn_cls: 8.515e+08  loss_rpn_loc: 1.62e+09  time: 0.5816  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:27:02 d2.utils.events]: [39m eta: 2:09:30  iter: 1439  total_loss: 1.432e+10  loss_cls: 2.072  loss_box_reg: 0.002386  loss_rpn_cls: 3.714e+09  loss_rpn_loc: 9.17e+09  time: 0.5815  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:27:13 d2.utils.events]: [39m eta: 2:09:16  iter: 1459  total_loss: 2.22e+09  loss_cls: 2.04  loss_box_reg: 0.2497  loss_rpn_cls: 1.321e+09  loss_rpn_loc: 5.553e+08  time: 0.5814  data_time: 0.0125  lr: 0.001  max_mem: 6536M
[32m[03/25 12:27:25 d2.utils.events]: [39m eta: 2:09:03  iter: 1479  total_loss: 3.603e+09  loss_cls: 1.983  loss_box_reg: 0.2488  loss_rpn_cls: 2e+09  loss_rpn_loc: 6.296e+08  time: 0.5814  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:27:36 d2.utils.events]: [39m eta: 2:08:50  iter: 1499  total_loss: 6.461e+10  loss_cls: 1.931  loss_box_reg: 0.001492  loss_rpn_cls: 4.232e+10  loss_rpn_loc: 2.229e+10  time: 0.5813  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:27:48 d2.utils.events]: [39m eta: 2:08:38  iter: 1519  total_loss: 2.378e+11  loss_cls: 1.887  loss_box_reg: 0.0001303  loss_rpn_cls: 8.082e+10  loss_rpn_loc: 1.57e+11  time: 0.5813  data_time: 0.0125  lr: 0.001  max_mem: 6536M
[32m[03/25 12:28:00 d2.utils.events]: [39m eta: 2:08:26  iter: 1539  total_loss: 1.994e+08  loss_cls: 1.837  loss_box_reg: 4.205e-05  loss_rpn_cls: 1.094e+08  loss_rpn_loc: 0.103  time: 0.5813  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:28:11 d2.utils.events]: [39m eta: 2:08:15  iter: 1559  total_loss: 1.617e+12  loss_cls: 1.802  loss_box_reg: 4.469e-05  loss_rpn_cls: 7.752e+11  loss_rpn_loc: 6.531e+11  time: 0.5813  data_time: 0.0135  lr: 0.001  max_mem: 6536M
[32m[03/25 12:28:23 d2.utils.events]: [39m eta: 2:08:03  iter: 1579  total_loss: 1.209e+12  loss_cls: 1.758  loss_box_reg: 3.619e-05  loss_rpn_cls: 3.251e+11  loss_rpn_loc: 3.415e+11  time: 0.5813  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:28:35 d2.utils.events]: [39m eta: 2:07:52  iter: 1599  total_loss: 3.324e+09  loss_cls: 1.721  loss_box_reg: 1.238e-05  loss_rpn_cls: 1.586e+09  loss_rpn_loc: 0.09951  time: 0.5814  data_time: 0.0132  lr: 0.001  max_mem: 6536M
[32m[03/25 12:28:46 d2.utils.events]: [39m eta: 2:07:41  iter: 1619  total_loss: 2.003e+11  loss_cls: 1.682  loss_box_reg: 1.328e-05  loss_rpn_cls: 2.003e+11  loss_rpn_loc: 0.0713  time: 0.5814  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:28:58 d2.utils.events]: [39m eta: 2:07:27  iter: 1639  total_loss: 1.158e+13  loss_cls: 1.659  loss_box_reg: 0.0001908  loss_rpn_cls: 6.207e+12  loss_rpn_loc: 2.152e+12  time: 0.5814  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:29:10 d2.utils.events]: [39m eta: 2:07:16  iter: 1659  total_loss: 2.735e+11  loss_cls: 1.619  loss_box_reg: 0.0001059  loss_rpn_cls: 1.333e+11  loss_rpn_loc: 5.38e+10  time: 0.5814  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:29:21 d2.utils.events]: [39m eta: 2:07:05  iter: 1679  total_loss: 5.099e+13  loss_cls: 1.585  loss_box_reg: 5.144e-05  loss_rpn_cls: 4.696e+13  loss_rpn_loc: 0.07541  time: 0.5815  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:29:33 d2.utils.events]: [39m eta: 2:06:53  iter: 1699  total_loss: 3.607e+12  loss_cls: 1.554  loss_box_reg: 4.004e-05  loss_rpn_cls: 8.143e+11  loss_rpn_loc: 1.129e+12  time: 0.5815  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:29:45 d2.utils.events]: [39m eta: 2:06:41  iter: 1719  total_loss: 5.629e+11  loss_cls: 1.524  loss_box_reg: 8.436e-05  loss_rpn_cls: 3.179e+11  loss_rpn_loc: 2.187e+11  time: 0.5815  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:29:56 d2.utils.events]: [39m eta: 2:06:30  iter: 1739  total_loss: 2.34  loss_cls: 1.498  loss_box_reg: 2.53e-05  loss_rpn_cls: 0.6794  loss_rpn_loc: 0.1248  time: 0.5816  data_time: 0.0143  lr: 0.001  max_mem: 6536M
[32m[03/25 12:30:08 d2.utils.events]: [39m eta: 2:06:18  iter: 1759  total_loss: 2.189  loss_cls: 1.46  loss_box_reg: 8.937e-06  loss_rpn_cls: 0.6703  loss_rpn_loc: 0.05257  time: 0.5816  data_time: 0.0136  lr: 0.001  max_mem: 6536M
[32m[03/25 12:30:20 d2.utils.events]: [39m eta: 2:06:10  iter: 1779  total_loss: 2.094  loss_cls: 1.421  loss_box_reg: 3.616e-06  loss_rpn_cls: 0.654  loss_rpn_loc: 0.025  time: 0.5817  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:30:32 d2.utils.events]: [39m eta: 2:06:00  iter: 1799  total_loss: 2.089  loss_cls: 1.39  loss_box_reg: 5.751e-06  loss_rpn_cls: 0.6409  loss_rpn_loc: 0.05596  time: 0.5817  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:30:43 d2.utils.events]: [39m eta: 2:05:59  iter: 1819  total_loss: 2.084  loss_cls: 1.367  loss_box_reg: 4.323e-06  loss_rpn_cls: 0.6322  loss_rpn_loc: 0.07622  time: 0.5817  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:30:55 d2.utils.events]: [39m eta: 2:05:53  iter: 1839  total_loss: 2.017  loss_cls: 1.345  loss_box_reg: 7.088e-06  loss_rpn_cls: 0.6177  loss_rpn_loc: 0.05237  time: 0.5818  data_time: 0.0140  lr: 0.001  max_mem: 6536M
[32m[03/25 12:31:07 d2.utils.events]: [39m eta: 2:05:48  iter: 1859  total_loss: 1.977  loss_cls: 1.314  loss_box_reg: 4.574e-06  loss_rpn_cls: 0.6064  loss_rpn_loc: 0.05166  time: 0.5819  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:31:19 d2.utils.events]: [39m eta: 2:05:45  iter: 1879  total_loss: 1.953  loss_cls: 1.3  loss_box_reg: 7.657e-06  loss_rpn_cls: 0.5969  loss_rpn_loc: 0.05515  time: 0.5819  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:31:30 d2.utils.events]: [39m eta: 2:05:40  iter: 1899  total_loss: 1.892  loss_cls: 1.259  loss_box_reg: 4.016e-06  loss_rpn_cls: 0.5814  loss_rpn_loc: 0.04157  time: 0.5820  data_time: 0.0154  lr: 0.001  max_mem: 6536M
[32m[03/25 12:31:42 d2.utils.events]: [39m eta: 2:05:38  iter: 1919  total_loss: 1.902  loss_cls: 1.253  loss_box_reg: 1.139e-05  loss_rpn_cls: 0.5791  loss_rpn_loc: 0.06335  time: 0.5821  data_time: 0.0139  lr: 0.001  max_mem: 6536M
[32m[03/25 12:31:54 d2.utils.events]: [39m eta: 2:05:34  iter: 1939  total_loss: 1.829  loss_cls: 1.205  loss_box_reg: 7.152e-06  loss_rpn_cls: 0.5664  loss_rpn_loc: 0.04266  time: 0.5821  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:32:06 d2.utils.events]: [39m eta: 2:05:30  iter: 1959  total_loss: 1.789  loss_cls: 1.186  loss_box_reg: 3.288e-06  loss_rpn_cls: 0.5523  loss_rpn_loc: 0.04123  time: 0.5822  data_time: 0.0133  lr: 0.001  max_mem: 6536M
[32m[03/25 12:32:18 d2.utils.events]: [39m eta: 2:05:28  iter: 1979  total_loss: 1.743  loss_cls: 1.156  loss_box_reg: 3.573e-06  loss_rpn_cls: 0.5402  loss_rpn_loc: 0.03513  time: 0.5822  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:32:29 d2.utils.events]: [39m eta: 2:05:29  iter: 1999  total_loss: 1.741  loss_cls: 1.153  loss_box_reg: 7.764e-06  loss_rpn_cls: 0.5407  loss_rpn_loc: 0.04374  time: 0.5823  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:32:41 d2.utils.events]: [39m eta: 2:05:37  iter: 2019  total_loss: 1.76  loss_cls: 1.127  loss_box_reg: 4.735e-06  loss_rpn_cls: 0.5399  loss_rpn_loc: 0.07892  time: 0.5823  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:32:53 d2.utils.events]: [39m eta: 2:05:36  iter: 2039  total_loss: 1.638  loss_cls: 1.098  loss_box_reg: 5.241e-06  loss_rpn_cls: 0.5128  loss_rpn_loc: 0.03231  time: 0.5824  data_time: 0.0136  lr: 0.001  max_mem: 6536M
[32m[03/25 12:33:05 d2.utils.events]: [39m eta: 2:05:32  iter: 2059  total_loss: 1.607  loss_cls: 1.075  loss_box_reg: 4.35e-06  loss_rpn_cls: 0.505  loss_rpn_loc: 0.03108  time: 0.5824  data_time: 0.0135  lr: 0.001  max_mem: 6536M
[32m[03/25 12:33:16 d2.utils.events]: [39m eta: 2:05:27  iter: 2079  total_loss: 1.619  loss_cls: 1.058  loss_box_reg: 4.129e-06  loss_rpn_cls: 0.5098  loss_rpn_loc: 0.04881  time: 0.5825  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:33:28 d2.utils.events]: [39m eta: 2:05:22  iter: 2099  total_loss: 1.578  loss_cls: 1.034  loss_box_reg: 4.062e-06  loss_rpn_cls: 0.4993  loss_rpn_loc: 0.0398  time: 0.5825  data_time: 0.0132  lr: 0.001  max_mem: 6536M
[32m[03/25 12:33:40 d2.utils.events]: [39m eta: 2:05:15  iter: 2119  total_loss: 1.566  loss_cls: 1.02  loss_box_reg: 3.274e-06  loss_rpn_cls: 0.495  loss_rpn_loc: 0.04223  time: 0.5826  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:33:52 d2.utils.events]: [39m eta: 2:05:07  iter: 2139  total_loss: 1.533  loss_cls: 1.008  loss_box_reg: 3.605e-06  loss_rpn_cls: 0.4852  loss_rpn_loc: 0.03416  time: 0.5826  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:34:03 d2.utils.events]: [39m eta: 2:04:58  iter: 2159  total_loss: 1.46  loss_cls: 0.9701  loss_box_reg: 3.906e-06  loss_rpn_cls: 0.4657  loss_rpn_loc: 0.02252  time: 0.5827  data_time: 0.0131  lr: 0.001  max_mem: 6536M
[32m[03/25 12:34:15 d2.utils.events]: [39m eta: 2:04:48  iter: 2179  total_loss: 1.578  loss_cls: 0.9767  loss_box_reg: 4.844e-06  loss_rpn_cls: 0.5039  loss_rpn_loc: 0.07437  time: 0.5827  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:34:27 d2.utils.events]: [39m eta: 2:04:38  iter: 2199  total_loss: 1.478  loss_cls: 0.9519  loss_box_reg: 7.231e-06  loss_rpn_cls: 0.4748  loss_rpn_loc: 0.04828  time: 0.5828  data_time: 0.0131  lr: 0.001  max_mem: 6536M
[32m[03/25 12:34:39 d2.utils.events]: [39m eta: 2:04:28  iter: 2219  total_loss: 1.484  loss_cls: 0.9355  loss_box_reg: 1.092e-05  loss_rpn_cls: 0.4764  loss_rpn_loc: 0.06867  time: 0.5828  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:34:50 d2.utils.events]: [39m eta: 2:04:18  iter: 2239  total_loss: 1.451  loss_cls: 0.9226  loss_box_reg: 7.587e-06  loss_rpn_cls: 0.4719  loss_rpn_loc: 0.05568  time: 0.5829  data_time: 0.0133  lr: 0.001  max_mem: 6536M
[32m[03/25 12:35:02 d2.utils.events]: [39m eta: 2:04:08  iter: 2259  total_loss: 1.387  loss_cls: 0.8944  loss_box_reg: 6.108e-06  loss_rpn_cls: 0.4475  loss_rpn_loc: 0.0446  time: 0.5829  data_time: 0.0136  lr: 0.001  max_mem: 6536M
[32m[03/25 12:35:14 d2.utils.events]: [39m eta: 2:03:58  iter: 2279  total_loss: 1.411  loss_cls: 0.8766  loss_box_reg: 6.171e-06  loss_rpn_cls: 0.4624  loss_rpn_loc: 0.06473  time: 0.5830  data_time: 0.0137  lr: 0.001  max_mem: 6536M
[32m[03/25 12:35:26 d2.utils.events]: [39m eta: 2:03:47  iter: 2299  total_loss: 1.332  loss_cls: 0.8555  loss_box_reg: 4.727e-06  loss_rpn_cls: 0.437  loss_rpn_loc: 0.03781  time: 0.5830  data_time: 0.0134  lr: 0.001  max_mem: 6536M
[32m[03/25 12:35:38 d2.utils.events]: [39m eta: 2:03:37  iter: 2319  total_loss: 1.387  loss_cls: 0.8607  loss_box_reg: 6.315e-06  loss_rpn_cls: 0.4555  loss_rpn_loc: 0.06525  time: 0.5831  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:35:49 d2.utils.events]: [39m eta: 2:03:26  iter: 2339  total_loss: 1.323  loss_cls: 0.828  loss_box_reg: 6.984e-06  loss_rpn_cls: 0.4343  loss_rpn_loc: 0.0425  time: 0.5831  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:36:01 d2.utils.events]: [39m eta: 2:03:15  iter: 2359  total_loss: 1.257  loss_cls: 0.8028  loss_box_reg: 4.174e-06  loss_rpn_cls: 0.4183  loss_rpn_loc: 0.03422  time: 0.5832  data_time: 0.0132  lr: 0.001  max_mem: 6536M
[32m[03/25 12:36:13 d2.utils.events]: [39m eta: 2:03:05  iter: 2379  total_loss: 1.324  loss_cls: 0.8167  loss_box_reg: 5.938e-06  loss_rpn_cls: 0.4395  loss_rpn_loc: 0.06342  time: 0.5832  data_time: 0.0156  lr: 0.001  max_mem: 6536M
[32m[03/25 12:36:25 d2.utils.events]: [39m eta: 2:02:54  iter: 2399  total_loss: 1.319  loss_cls: 0.8015  loss_box_reg: 7.506e-06  loss_rpn_cls: 0.4426  loss_rpn_loc: 0.05696  time: 0.5833  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:36:37 d2.utils.events]: [39m eta: 2:02:42  iter: 2419  total_loss: 1.288  loss_cls: 0.7787  loss_box_reg: 5.991e-06  loss_rpn_cls: 0.4327  loss_rpn_loc: 0.06081  time: 0.5833  data_time: 0.0127  lr: 0.001  max_mem: 6536M
[32m[03/25 12:36:48 d2.utils.events]: [39m eta: 2:02:31  iter: 2439  total_loss: 1.295  loss_cls: 0.7792  loss_box_reg: 7.211e-06  loss_rpn_cls: 0.4416  loss_rpn_loc: 0.06184  time: 0.5833  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:37:00 d2.utils.events]: [39m eta: 2:02:20  iter: 2459  total_loss: 1.23  loss_cls: 0.7497  loss_box_reg: 1.379e-05  loss_rpn_cls: 0.4215  loss_rpn_loc: 0.0585  time: 0.5833  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:37:12 d2.utils.events]: [39m eta: 2:02:09  iter: 2479  total_loss: 1.237  loss_cls: 0.7434  loss_box_reg: 1.039e-05  loss_rpn_cls: 0.4159  loss_rpn_loc: 0.04583  time: 0.5834  data_time: 0.0124  lr: 0.001  max_mem: 6536M
[32m[03/25 12:37:24 d2.utils.events]: [39m eta: 2:01:57  iter: 2499  total_loss: 1.223  loss_cls: 0.7427  loss_box_reg: 7.421e-06  loss_rpn_cls: 0.4085  loss_rpn_loc: 0.04791  time: 0.5834  data_time: 0.0142  lr: 0.001  max_mem: 6536M
[32m[03/25 12:37:35 d2.utils.events]: [39m eta: 2:01:46  iter: 2519  total_loss: 1.251  loss_cls: 0.7259  loss_box_reg: 1.155e-05  loss_rpn_cls: 0.4291  loss_rpn_loc: 0.05688  time: 0.5834  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:37:47 d2.utils.events]: [39m eta: 2:01:35  iter: 2539  total_loss: 1.212  loss_cls: 0.7104  loss_box_reg: 6.128e-06  loss_rpn_cls: 0.4208  loss_rpn_loc: 0.05871  time: 0.5834  data_time: 0.0128  lr: 0.001  max_mem: 6536M
[32m[03/25 12:37:59 d2.utils.events]: [39m eta: 2:01:23  iter: 2559  total_loss: 1.101  loss_cls: 0.6878  loss_box_reg: 7.872e-06  loss_rpn_cls: 0.3815  loss_rpn_loc: 0.03433  time: 0.5835  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:38:10 d2.utils.events]: [39m eta: 2:01:12  iter: 2579  total_loss: 1.105  loss_cls: 0.6894  loss_box_reg: 7.923e-06  loss_rpn_cls: 0.3822  loss_rpn_loc: 0.02942  time: 0.5835  data_time: 0.0131  lr: 0.001  max_mem: 6536M
[32m[03/25 12:38:22 d2.utils.events]: [39m eta: 2:01:00  iter: 2599  total_loss: 1.134  loss_cls: 0.6492  loss_box_reg: 4.59e-06  loss_rpn_cls: 0.3972  loss_rpn_loc: 0.05485  time: 0.5835  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:38:34 d2.utils.events]: [39m eta: 2:00:48  iter: 2619  total_loss: 1.117  loss_cls: 0.6657  loss_box_reg: 1.198e-05  loss_rpn_cls: 0.3914  loss_rpn_loc: 0.04962  time: 0.5835  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:38:46 d2.utils.events]: [39m eta: 2:00:37  iter: 2639  total_loss: 1.077  loss_cls: 0.6443  loss_box_reg: 9.777e-06  loss_rpn_cls: 0.3778  loss_rpn_loc: 0.0459  time: 0.5835  data_time: 0.0132  lr: 0.001  max_mem: 6536M
[32m[03/25 12:38:58 d2.utils.events]: [39m eta: 2:00:26  iter: 2659  total_loss: 1.002  loss_cls: 0.6234  loss_box_reg: 5.299e-06  loss_rpn_cls: 0.3532  loss_rpn_loc: 0.02414  time: 0.5836  data_time: 0.0133  lr: 0.001  max_mem: 6536M
[32m[03/25 12:39:09 d2.utils.events]: [39m eta: 2:00:16  iter: 2679  total_loss: 1.074  loss_cls: 0.6318  loss_box_reg: 8.446e-06  loss_rpn_cls: 0.3827  loss_rpn_loc: 0.04643  time: 0.5836  data_time: 0.0154  lr: 0.001  max_mem: 6536M
[32m[03/25 12:39:21 d2.utils.events]: [39m eta: 2:00:04  iter: 2699  total_loss: 0.9861  loss_cls: 0.5926  loss_box_reg: 4.72e-06  loss_rpn_cls: 0.3551  loss_rpn_loc: 0.0312  time: 0.5836  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:39:33 d2.utils.events]: [39m eta: 1:59:53  iter: 2719  total_loss: 5.778e+27  loss_cls: 5.693e+27  loss_box_reg: 7.829e+25  loss_rpn_cls: 0.3973  loss_rpn_loc: 0.06424  time: 0.5837  data_time: 0.0136  lr: 0.001  max_mem: 6536M
[32m[03/25 12:39:45 d2.utils.events]: [39m eta: 1:59:41  iter: 2739  total_loss: 6.104e+27  loss_cls: 5.869e+27  loss_box_reg: 1.43e+26  loss_rpn_cls: 0.3862  loss_rpn_loc: 0.06281  time: 0.5837  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:39:57 d2.utils.events]: [39m eta: 1:59:29  iter: 2759  total_loss: 5.777e+27  loss_cls: 5.748e+27  loss_box_reg: 3.531e+25  loss_rpn_cls: 0.3726  loss_rpn_loc: 0.06076  time: 0.5838  data_time: 0.0133  lr: 0.001  max_mem: 6536M
[32m[03/25 12:40:08 d2.utils.events]: [39m eta: 1:59:18  iter: 2779  total_loss: 5.98e+27  loss_cls: 5.871e+27  loss_box_reg: 9.307e+25  loss_rpn_cls: 0.3823  loss_rpn_loc: 0.06726  time: 0.5838  data_time: 0.0135  lr: 0.001  max_mem: 6536M
[32m[03/25 12:40:20 d2.utils.events]: [39m eta: 1:59:06  iter: 2799  total_loss: 5.969e+27  loss_cls: 5.821e+27  loss_box_reg: 1.291e+26  loss_rpn_cls: 0.394  loss_rpn_loc: 0.0568  time: 0.5838  data_time: 0.0126  lr: 0.001  max_mem: 6536M
[32m[03/25 12:40:32 d2.utils.events]: [39m eta: 1:58:55  iter: 2819  total_loss: 6.007e+27  loss_cls: 5.872e+27  loss_box_reg: 1.723e+26  loss_rpn_cls: 0.3763  loss_rpn_loc: 0.05951  time: 0.5839  data_time: 0.0136  lr: 0.001  max_mem: 6536M
[32m[03/25 12:40:44 d2.utils.events]: [39m eta: 1:58:43  iter: 2839  total_loss: 5.813e+27  loss_cls: 5.774e+27  loss_box_reg: 4.783e+25  loss_rpn_cls: 0.3278  loss_rpn_loc: 0.03515  time: 0.5839  data_time: 0.0132  lr: 0.001  max_mem: 6536M
[32m[03/25 12:40:55 d2.utils.events]: [39m eta: 1:58:32  iter: 2859  total_loss: 5.76e+27  loss_cls: 5.62e+27  loss_box_reg: 7.535e+25  loss_rpn_cls: 0.3505  loss_rpn_loc: 0.04632  time: 0.5839  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:41:07 d2.utils.events]: [39m eta: 1:58:20  iter: 2879  total_loss: 5.836e+27  loss_cls: 5.704e+27  loss_box_reg: 7.504e+25  loss_rpn_cls: 0.3485  loss_rpn_loc: 0.03886  time: 0.5840  data_time: 0.0129  lr: 0.001  max_mem: 6536M
[32m[03/25 12:41:19 d2.utils.events]: [39m eta: 1:58:08  iter: 2899  total_loss: 5.784e+27  loss_cls: 5.736e+27  loss_box_reg: 1.626e+26  loss_rpn_cls: 0.3615  loss_rpn_loc: 0.04706  time: 0.5840  data_time: 0.0138  lr: 0.001  max_mem: 6536M
[32m[03/25 12:41:31 d2.utils.events]: [39m eta: 1:57:56  iter: 2919  total_loss: 6.032e+27  loss_cls: 5.768e+27  loss_box_reg: 2.448e+26  loss_rpn_cls: 0.392  loss_rpn_loc: 0.07455  time: 0.5840  data_time: 0.0132  lr: 0.001  max_mem: 6536M
[32m[03/25 12:41:43 d2.utils.events]: [39m eta: 1:57:44  iter: 2939  total_loss: 5.753e+27  loss_cls: 5.698e+27  loss_box_reg: 1.062e+26  loss_rpn_cls: 0.3705  loss_rpn_loc: 0.05862  time: 0.5840  data_time: 0.0143  lr: 0.001  max_mem: 6536M
[32m[03/25 12:41:54 d2.utils.events]: [39m eta: 1:57:33  iter: 2959  total_loss: 5.744e+27  loss_cls: 5.628e+27  loss_box_reg: 1.026e+26  loss_rpn_cls: 0.3298  loss_rpn_loc: 0.038  time: 0.5841  data_time: 0.0150  lr: 0.001  max_mem: 6536M
[32m[03/25 12:42:06 d2.utils.events]: [39m eta: 1:57:22  iter: 2979  total_loss: 5.861e+27  loss_cls: 5.712e+27  loss_box_reg: 1.222e+26  loss_rpn_cls: 0.3525  loss_rpn_loc: 0.04872  time: 0.5841  data_time: 0.0130  lr: 0.001  max_mem: 6536M
[32m[03/25 12:42:20 d2.data.datasets.coco]: [39mLoaded 4883 images in COCO format from ../../dataset/train.json
[32m[03/25 12:42:20 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/25 12:42:20 d2.data.common]: [39mSerializing 4883 elements to byte tensors and concatenating them all ...
[32m[03/25 12:42:20 d2.data.common]: [39mSerialized dataset takes 2.19 MiB
[31m[5mWARNING[39m[25m [32m[03/25 12:42:20 d2.evaluation.coco_evaluation]: [39mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[03/25 12:42:20 d2.evaluation.evaluator]: [39mStart inference on 4883 batches
[32m[03/25 12:42:21 d2.evaluation.evaluator]: [39mInference done 11/4883. Dataloading: 0.0008 s/iter. Inference: 0.0518 s/iter. Eval: 0.0001 s/iter. Total: 0.0527 s/iter. ETA=0:04:16
[32m[03/25 12:42:26 d2.evaluation.evaluator]: [39mInference done 117/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0001 s/iter. Total: 0.0475 s/iter. ETA=0:03:46
[32m[03/25 12:42:31 d2.evaluation.evaluator]: [39mInference done 225/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:03:39
[32m[03/25 12:42:36 d2.evaluation.evaluator]: [39mInference done 333/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0469 s/iter. ETA=0:03:33
[32m[03/25 12:42:41 d2.evaluation.evaluator]: [39mInference done 441/4883. Dataloading: 0.0012 s/iter. Inference: 0.0455 s/iter. Eval: 0.0001 s/iter. Total: 0.0468 s/iter. ETA=0:03:27
[32m[03/25 12:42:46 d2.evaluation.evaluator]: [39mInference done 549/4883. Dataloading: 0.0011 s/iter. Inference: 0.0455 s/iter. Eval: 0.0001 s/iter. Total: 0.0468 s/iter. ETA=0:03:22
[32m[03/25 12:42:51 d2.evaluation.evaluator]: [39mInference done 656/4883. Dataloading: 0.0012 s/iter. Inference: 0.0455 s/iter. Eval: 0.0001 s/iter. Total: 0.0468 s/iter. ETA=0:03:17
[32m[03/25 12:42:56 d2.evaluation.evaluator]: [39mInference done 762/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0469 s/iter. ETA=0:03:13
[32m[03/25 12:43:01 d2.evaluation.evaluator]: [39mInference done 868/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:03:08
[32m[03/25 12:43:06 d2.evaluation.evaluator]: [39mInference done 975/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:03:03
[32m[03/25 12:43:11 d2.evaluation.evaluator]: [39mInference done 1081/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:58
[32m[03/25 12:43:16 d2.evaluation.evaluator]: [39mInference done 1188/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:53
[32m[03/25 12:43:21 d2.evaluation.evaluator]: [39mInference done 1295/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:48
[32m[03/25 12:43:26 d2.evaluation.evaluator]: [39mInference done 1402/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:43
[32m[03/25 12:43:31 d2.evaluation.evaluator]: [39mInference done 1509/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:38
[32m[03/25 12:43:36 d2.evaluation.evaluator]: [39mInference done 1616/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:33
[32m[03/25 12:43:41 d2.evaluation.evaluator]: [39mInference done 1723/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:28
[32m[03/25 12:43:46 d2.evaluation.evaluator]: [39mInference done 1829/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:23
[32m[03/25 12:43:51 d2.evaluation.evaluator]: [39mInference done 1936/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:18
[32m[03/25 12:43:56 d2.evaluation.evaluator]: [39mInference done 2043/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:13
[32m[03/25 12:44:01 d2.evaluation.evaluator]: [39mInference done 2151/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:08
[32m[03/25 12:44:06 d2.evaluation.evaluator]: [39mInference done 2255/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:02:03
[32m[03/25 12:44:11 d2.evaluation.evaluator]: [39mInference done 2363/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:01:58
[32m[03/25 12:44:16 d2.evaluation.evaluator]: [39mInference done 2471/4883. Dataloading: 0.0012 s/iter. Inference: 0.0456 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:01:53
[32m[03/25 12:44:21 d2.evaluation.evaluator]: [39mInference done 2575/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0470 s/iter. ETA=0:01:48
[32m[03/25 12:44:26 d2.evaluation.evaluator]: [39mInference done 2677/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:43
[32m[03/25 12:44:31 d2.evaluation.evaluator]: [39mInference done 2784/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:38
[32m[03/25 12:44:37 d2.evaluation.evaluator]: [39mInference done 2890/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:33
[32m[03/25 12:44:42 d2.evaluation.evaluator]: [39mInference done 2997/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:28
[32m[03/25 12:44:47 d2.evaluation.evaluator]: [39mInference done 3104/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:23
[32m[03/25 12:44:52 d2.evaluation.evaluator]: [39mInference done 3211/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:18
[32m[03/25 12:44:57 d2.evaluation.evaluator]: [39mInference done 3319/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:13
[32m[03/25 12:45:02 d2.evaluation.evaluator]: [39mInference done 3425/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:08
[32m[03/25 12:45:07 d2.evaluation.evaluator]: [39mInference done 3531/4883. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:01:03
[32m[03/25 12:45:12 d2.evaluation.evaluator]: [39mInference done 3638/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:00:58
[32m[03/25 12:45:17 d2.evaluation.evaluator]: [39mInference done 3745/4883. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0001 s/iter. Total: 0.0471 s/iter. ETA=0:00:53
[32m[03/25 12:45:18 d2.engine.hooks]: [39mOverall training speed: 2997 iterations in 0:29:11 (0.5843 s / it)
[32m[03/25 12:45:18 d2.engine.hooks]: [39mTotal training time: 0:32:13 (0:03:02 on hooks)
[32m[03/25 12:45:18 d2.utils.events]: [39m eta: 1:57:10  iter: 2999  total_loss: 5.778e+27  loss_cls: 5.65e+27  loss_box_reg: 9.884e+25  loss_rpn_cls: 0.3378  loss_rpn_loc: 0.04387  time: 0.5841  data_time: 0.0129  lr: 0.001  max_mem: 6536M
Traceback (most recent call last):
  File "train.py", line 120, in <module>
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 491, in train
    super().train(self.start_iter, self.max_iter)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 151, in train
    self.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 181, in after_step
    h.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 449, in after_step
    self._do_eval()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 422, in _do_eval
    results = self._func()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 460, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 615, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/opt/ml/detection/baseline/detectron2/detectron2/evaluation/evaluator.py", line 158, in inference_on_dataset
    outputs = model(inputs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/meta_arch/rcnn.py", line 146, in forward
    return self.inference(batched_inputs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/meta_arch/rcnn.py", line 200, in inference
    features = self.backbone(images.tensor)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/backbone/fpn.py", line 126, in forward
    bottom_up_features = self.bottom_up(x)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/backbone/resnet.py", line 449, in forward
    x = stage(x)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/backbone/resnet.py", line 198, in forward
    out = self.conv2(out)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/layers/wrappers.py", line 85, in forward
    x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups
KeyboardInterrupt