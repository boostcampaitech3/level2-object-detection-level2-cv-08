[32m[03/25 09:41:52 d2.engine.defaults]: [39mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[32m[03/25 09:41:52 d2.data.datasets.coco]: [39mLoaded 4883 images in COCO format from ../../dataset/train.json
[32m[03/25 09:41:52 d2.data.build]: [39mRemoved 0 images with no usable annotations. 4883 images left.
[32m[03/25 09:41:52 d2.data.build]: [39mDistribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
[36m|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
[36m| General trash | 3966         |    Paper    | 6352         | Paper pack | 897          |
[36m|     Metal     | 936          |    Glass    | 982          |  Plastic   | 2943         |
[36m|   Styrofoam   | 1263         | Plastic bag | 5178         |  Battery   | 159          |
[36m|   Clothing    | 468          |             |              |            |              |
[36m|     total     | 23144        |             |              |            |              |
[32m[03/25 09:41:52 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[03/25 09:41:52 d2.data.common]: [39mSerializing 4883 elements to byte tensors and concatenating them all ...
[32m[03/25 09:41:52 d2.data.common]: [39mSerialized dataset takes 2.19 MiB
expected_results:
[]
[32m[03/25 09:41:53 d2.engine.train_loop]: [39mStarting training from iteration 0
/opt/ml/detection/baseline/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)
  num_fg = fg_inds.nonzero().numel()
[32m[03/25 09:42:05 d2.utils.events]: [39m eta: 2:24:06  iter: 19  total_loss: 2.958  loss_cls: 2.199  loss_box_reg: 0.6817  loss_rpn_cls: 0.04809  loss_rpn_loc: 0.02208  time: 0.5791  data_time: 0.0332  lr: 1.9981e-05  max_mem: 6307M
[32m[03/25 09:42:17 d2.utils.events]: [39m eta: 2:24:03  iter: 39  total_loss: 2.713  loss_cls: 1.806  loss_box_reg: 0.6957  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.03758  time: 0.5784  data_time: 0.0115  lr: 3.9961e-05  max_mem: 6307M
[32m[03/25 09:42:29 d2.utils.events]: [39m eta: 2:23:58  iter: 59  total_loss: 2.105  loss_cls: 1.118  loss_box_reg: 0.7678  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.03884  time: 0.5796  data_time: 0.0124  lr: 5.9941e-05  max_mem: 6307M
[32m[03/25 09:42:40 d2.utils.events]: [39m eta: 2:23:49  iter: 79  total_loss: 1.759  loss_cls: 0.8624  loss_box_reg: 0.749  loss_rpn_cls: 0.08323  loss_rpn_loc: 0.02707  time: 0.5797  data_time: 0.0118  lr: 7.9921e-05  max_mem: 6307M
[32m[03/25 09:42:52 d2.utils.events]: [39m eta: 2:23:39  iter: 99  total_loss: 1.581  loss_cls: 0.7696  loss_box_reg: 0.7281  loss_rpn_cls: 0.03281  loss_rpn_loc: 0.02504  time: 0.5797  data_time: 0.0125  lr: 9.9901e-05  max_mem: 6307M
[32m[03/25 09:43:03 d2.utils.events]: [39m eta: 2:23:27  iter: 119  total_loss: 1.547  loss_cls: 0.7112  loss_box_reg: 0.6924  loss_rpn_cls: 0.02601  loss_rpn_loc: 0.0279  time: 0.5799  data_time: 0.0128  lr: 0.00011988  max_mem: 6307M
[32m[03/25 09:43:15 d2.utils.events]: [39m eta: 2:23:16  iter: 139  total_loss: 1.619  loss_cls: 0.7428  loss_box_reg: 0.7711  loss_rpn_cls: 0.03069  loss_rpn_loc: 0.02843  time: 0.5798  data_time: 0.0120  lr: 0.00013986  max_mem: 6307M
[32m[03/25 09:43:27 d2.utils.events]: [39m eta: 2:23:04  iter: 159  total_loss: 1.542  loss_cls: 0.7145  loss_box_reg: 0.7586  loss_rpn_cls: 0.0414  loss_rpn_loc: 0.04699  time: 0.5796  data_time: 0.0119  lr: 0.00015984  max_mem: 6307M
[32m[03/25 09:43:38 d2.utils.events]: [39m eta: 2:22:53  iter: 179  total_loss: 1.39  loss_cls: 0.6359  loss_box_reg: 0.7041  loss_rpn_cls: 0.03119  loss_rpn_loc: 0.01945  time: 0.5797  data_time: 0.0124  lr: 0.00017982  max_mem: 6307M
[32m[03/25 09:43:50 d2.utils.events]: [39m eta: 2:22:44  iter: 199  total_loss: 1.432  loss_cls: 0.6374  loss_box_reg: 0.7032  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.03691  time: 0.5798  data_time: 0.0127  lr: 0.0001998  max_mem: 6307M
[32m[03/25 09:44:02 d2.utils.events]: [39m eta: 2:22:34  iter: 219  total_loss: 1.318  loss_cls: 0.6081  loss_box_reg: 0.6725  loss_rpn_cls: 0.02352  loss_rpn_loc: 0.02315  time: 0.5799  data_time: 0.0130  lr: 0.00021978  max_mem: 6307M
[32m[03/25 09:44:13 d2.utils.events]: [39m eta: 2:22:24  iter: 239  total_loss: 1.339  loss_cls: 0.5716  loss_box_reg: 0.6998  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.02372  time: 0.5803  data_time: 0.0140  lr: 0.00023976  max_mem: 6307M
[32m[03/25 09:44:25 d2.utils.events]: [39m eta: 2:22:13  iter: 259  total_loss: 1.402  loss_cls: 0.6238  loss_box_reg: 0.684  loss_rpn_cls: 0.03541  loss_rpn_loc: 0.02737  time: 0.5803  data_time: 0.0132  lr: 0.00025974  max_mem: 6307M
[32m[03/25 09:44:37 d2.utils.events]: [39m eta: 2:22:02  iter: 279  total_loss: 1.41  loss_cls: 0.6263  loss_box_reg: 0.6896  loss_rpn_cls: 0.0387  loss_rpn_loc: 0.0306  time: 0.5806  data_time: 0.0120  lr: 0.00027972  max_mem: 6307M
[32m[03/25 09:44:48 d2.utils.events]: [39m eta: 2:21:51  iter: 299  total_loss: 1.202  loss_cls: 0.5284  loss_box_reg: 0.5657  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.01997  time: 0.5805  data_time: 0.0120  lr: 0.0002997  max_mem: 6307M
[32m[03/25 09:45:00 d2.utils.events]: [39m eta: 2:21:42  iter: 319  total_loss: 1.097  loss_cls: 0.5072  loss_box_reg: 0.5428  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.02638  time: 0.5806  data_time: 0.0130  lr: 0.00031968  max_mem: 6307M
[32m[03/25 09:45:11 d2.utils.events]: [39m eta: 2:21:31  iter: 339  total_loss: 1.184  loss_cls: 0.5623  loss_box_reg: 0.5822  loss_rpn_cls: 0.02285  loss_rpn_loc: 0.02782  time: 0.5807  data_time: 0.0127  lr: 0.00033966  max_mem: 6307M
[32m[03/25 09:45:23 d2.utils.events]: [39m eta: 2:21:18  iter: 359  total_loss: 1.137  loss_cls: 0.5286  loss_box_reg: 0.5031  loss_rpn_cls: 0.03036  loss_rpn_loc: 0.02779  time: 0.5805  data_time: 0.0123  lr: 0.00035964  max_mem: 6307M
[32m[03/25 09:45:35 d2.utils.events]: [39m eta: 2:21:07  iter: 379  total_loss: 1.06  loss_cls: 0.5183  loss_box_reg: 0.4664  loss_rpn_cls: 0.02959  loss_rpn_loc: 0.01849  time: 0.5804  data_time: 0.0124  lr: 0.00037962  max_mem: 6307M
[32m[03/25 09:45:46 d2.utils.events]: [39m eta: 2:20:57  iter: 399  total_loss: 0.9172  loss_cls: 0.4572  loss_box_reg: 0.4056  loss_rpn_cls: 0.02535  loss_rpn_loc: 0.02492  time: 0.5806  data_time: 0.0135  lr: 0.0003996  max_mem: 6307M
[32m[03/25 09:45:58 d2.utils.events]: [39m eta: 2:20:45  iter: 419  total_loss: 1.091  loss_cls: 0.5385  loss_box_reg: 0.4539  loss_rpn_cls: 0.02645  loss_rpn_loc: 0.02428  time: 0.5806  data_time: 0.0123  lr: 0.00041958  max_mem: 6307M
[32m[03/25 09:46:10 d2.utils.events]: [39m eta: 2:20:32  iter: 439  total_loss: 0.9726  loss_cls: 0.4945  loss_box_reg: 0.3954  loss_rpn_cls: 0.02447  loss_rpn_loc: 0.03858  time: 0.5805  data_time: 0.0127  lr: 0.00043956  max_mem: 6307M
[32m[03/25 09:46:21 d2.utils.events]: [39m eta: 2:20:22  iter: 459  total_loss: 1.046  loss_cls: 0.505  loss_box_reg: 0.4102  loss_rpn_cls: 0.03483  loss_rpn_loc: 0.03912  time: 0.5810  data_time: 0.0155  lr: 0.00045954  max_mem: 6307M
[32m[03/25 09:46:33 d2.utils.events]: [39m eta: 2:20:12  iter: 479  total_loss: 1.032  loss_cls: 0.5363  loss_box_reg: 0.4406  loss_rpn_cls: 0.03212  loss_rpn_loc: 0.0235  time: 0.5812  data_time: 0.0130  lr: 0.00047952  max_mem: 6307M
[32m[03/25 09:46:45 d2.utils.events]: [39m eta: 2:20:02  iter: 499  total_loss: 1.093  loss_cls: 0.5303  loss_box_reg: 0.4153  loss_rpn_cls: 0.02686  loss_rpn_loc: 0.04394  time: 0.5814  data_time: 0.0128  lr: 0.0004995  max_mem: 6307M
[32m[03/25 09:46:57 d2.utils.events]: [39m eta: 2:19:52  iter: 519  total_loss: 0.9981  loss_cls: 0.5407  loss_box_reg: 0.3624  loss_rpn_cls: 0.02439  loss_rpn_loc: 0.02204  time: 0.5815  data_time: 0.0129  lr: 0.00051948  max_mem: 6307M
[32m[03/25 09:47:08 d2.utils.events]: [39m eta: 2:19:42  iter: 539  total_loss: 0.9556  loss_cls: 0.4967  loss_box_reg: 0.3286  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.0177  time: 0.5818  data_time: 0.0150  lr: 0.00053946  max_mem: 6307M
[32m[03/25 09:47:20 d2.utils.events]: [39m eta: 2:19:31  iter: 559  total_loss: 1.153  loss_cls: 0.5965  loss_box_reg: 0.4041  loss_rpn_cls: 0.04335  loss_rpn_loc: 0.03988  time: 0.5818  data_time: 0.0132  lr: 0.00055944  max_mem: 6307M
[32m[03/25 09:47:32 d2.utils.events]: [39m eta: 2:19:21  iter: 579  total_loss: 0.7672  loss_cls: 0.4568  loss_box_reg: 0.2867  loss_rpn_cls: 0.02379  loss_rpn_loc: 0.01157  time: 0.5819  data_time: 0.0130  lr: 0.00057942  max_mem: 6307M
[32m[03/25 09:47:43 d2.utils.events]: [39m eta: 2:19:11  iter: 599  total_loss: 0.7985  loss_cls: 0.4783  loss_box_reg: 0.3361  loss_rpn_cls: 0.0174  loss_rpn_loc: 0.02106  time: 0.5820  data_time: 0.0151  lr: 0.0005994  max_mem: 6307M
[32m[03/25 09:47:55 d2.utils.events]: [39m eta: 2:19:00  iter: 619  total_loss: 0.9029  loss_cls: 0.4943  loss_box_reg: 0.3545  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.02057  time: 0.5821  data_time: 0.0142  lr: 0.00061938  max_mem: 6307M
[32m[03/25 09:48:07 d2.utils.events]: [39m eta: 2:18:49  iter: 639  total_loss: 0.9282  loss_cls: 0.4939  loss_box_reg: 0.3386  loss_rpn_cls: 0.03804  loss_rpn_loc: 0.02752  time: 0.5820  data_time: 0.0126  lr: 0.00063936  max_mem: 6307M
[32m[03/25 09:48:18 d2.utils.events]: [39m eta: 2:18:36  iter: 659  total_loss: 0.9218  loss_cls: 0.5144  loss_box_reg: 0.3311  loss_rpn_cls: 0.05196  loss_rpn_loc: 0.03706  time: 0.5819  data_time: 0.0127  lr: 0.00065934  max_mem: 6307M
[32m[03/25 09:48:30 d2.utils.events]: [39m eta: 2:18:25  iter: 679  total_loss: 0.9834  loss_cls: 0.5389  loss_box_reg: 0.3819  loss_rpn_cls: 0.02475  loss_rpn_loc: 0.02748  time: 0.5819  data_time: 0.0129  lr: 0.00067932  max_mem: 6307M
[32m[03/25 09:48:42 d2.utils.events]: [39m eta: 2:18:14  iter: 699  total_loss: 1.029  loss_cls: 0.4907  loss_box_reg: 0.3509  loss_rpn_cls: 0.04295  loss_rpn_loc: 0.06798  time: 0.5819  data_time: 0.0130  lr: 0.0006993  max_mem: 6307M
[32m[03/25 09:48:53 d2.utils.events]: [39m eta: 2:18:04  iter: 719  total_loss: 0.9131  loss_cls: 0.5021  loss_box_reg: 0.3518  loss_rpn_cls: 0.03105  loss_rpn_loc: 0.02636  time: 0.5820  data_time: 0.0150  lr: 0.00071928  max_mem: 6307M
[32m[03/25 09:49:05 d2.utils.events]: [39m eta: 2:17:53  iter: 739  total_loss: 0.913  loss_cls: 0.4437  loss_box_reg: 0.3542  loss_rpn_cls: 0.03669  loss_rpn_loc: 0.02951  time: 0.5821  data_time: 0.0136  lr: 0.00073926  max_mem: 6307M
[32m[03/25 09:49:17 d2.utils.events]: [39m eta: 2:17:43  iter: 759  total_loss: 0.7944  loss_cls: 0.4751  loss_box_reg: 0.2886  loss_rpn_cls: 0.01912  loss_rpn_loc: 0.01827  time: 0.5822  data_time: 0.0138  lr: 0.00075924  max_mem: 6307M
[32m[03/25 09:49:28 d2.utils.events]: [39m eta: 2:17:33  iter: 779  total_loss: 0.8266  loss_cls: 0.4621  loss_box_reg: 0.3253  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.02124  time: 0.5822  data_time: 0.0151  lr: 0.00077922  max_mem: 6307M
[32m[03/25 09:49:40 d2.utils.events]: [39m eta: 2:17:21  iter: 799  total_loss: 0.8545  loss_cls: 0.4754  loss_box_reg: 0.3148  loss_rpn_cls: 0.04201  loss_rpn_loc: 0.03437  time: 0.5822  data_time: 0.0129  lr: 0.0007992  max_mem: 6307M
[32m[03/25 09:49:52 d2.utils.events]: [39m eta: 2:17:08  iter: 819  total_loss: 0.904  loss_cls: 0.4686  loss_box_reg: 0.3081  loss_rpn_cls: 0.02669  loss_rpn_loc: 0.02884  time: 0.5821  data_time: 0.0128  lr: 0.00081918  max_mem: 6307M
[32m[03/25 09:50:03 d2.utils.events]: [39m eta: 2:16:56  iter: 839  total_loss: 0.9111  loss_cls: 0.499  loss_box_reg: 0.3484  loss_rpn_cls: 0.02354  loss_rpn_loc: 0.02377  time: 0.5820  data_time: 0.0125  lr: 0.00083916  max_mem: 6307M
[32m[03/25 09:50:15 d2.utils.events]: [39m eta: 2:16:43  iter: 859  total_loss: 0.7775  loss_cls: 0.4267  loss_box_reg: 0.2976  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.01686  time: 0.5820  data_time: 0.0136  lr: 0.00085914  max_mem: 6307M
[32m[03/25 09:50:27 d2.utils.events]: [39m eta: 2:16:33  iter: 879  total_loss: 0.9632  loss_cls: 0.5258  loss_box_reg: 0.3761  loss_rpn_cls: 0.0384  loss_rpn_loc: 0.03824  time: 0.5821  data_time: 0.0150  lr: 0.00087912  max_mem: 6307M
[32m[03/25 09:50:38 d2.utils.events]: [39m eta: 2:16:21  iter: 899  total_loss: 0.8749  loss_cls: 0.4588  loss_box_reg: 0.2993  loss_rpn_cls: 0.02042  loss_rpn_loc: 0.02648  time: 0.5821  data_time: 0.0126  lr: 0.0008991  max_mem: 6307M
[32m[03/25 09:50:50 d2.utils.events]: [39m eta: 2:16:10  iter: 919  total_loss: 1.021  loss_cls: 0.5346  loss_box_reg: 0.3473  loss_rpn_cls: 0.04055  loss_rpn_loc: 0.05976  time: 0.5821  data_time: 0.0128  lr: 0.00091908  max_mem: 6307M
[32m[03/25 09:51:02 d2.utils.events]: [39m eta: 2:15:59  iter: 939  total_loss: 0.8481  loss_cls: 0.4804  loss_box_reg: 0.3421  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.03435  time: 0.5821  data_time: 0.0129  lr: 0.00093906  max_mem: 6307M
[32m[03/25 09:51:13 d2.utils.events]: [39m eta: 2:15:48  iter: 959  total_loss: 1.015  loss_cls: 0.5482  loss_box_reg: 0.3533  loss_rpn_cls: 0.04329  loss_rpn_loc: 0.04577  time: 0.5820  data_time: 0.0127  lr: 0.00095904  max_mem: 6307M
[32m[03/25 09:51:25 d2.utils.events]: [39m eta: 2:15:37  iter: 979  total_loss: 0.7394  loss_cls: 0.4142  loss_box_reg: 0.2824  loss_rpn_cls: 0.03135  loss_rpn_loc: 0.017  time: 0.5821  data_time: 0.0141  lr: 0.00097902  max_mem: 6307M
[32m[03/25 09:51:37 d2.utils.events]: [39m eta: 2:15:26  iter: 999  total_loss: 0.909  loss_cls: 0.4997  loss_box_reg: 0.3122  loss_rpn_cls: 0.02889  loss_rpn_loc: 0.0356  time: 0.5821  data_time: 0.0131  lr: 0.000999  max_mem: 6307M
[32m[03/25 09:51:48 d2.utils.events]: [39m eta: 2:15:15  iter: 1019  total_loss: 0.8901  loss_cls: 0.4866  loss_box_reg: 0.2942  loss_rpn_cls: 0.02362  loss_rpn_loc: 0.0246  time: 0.5821  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 09:52:00 d2.utils.events]: [39m eta: 2:15:05  iter: 1039  total_loss: 0.744  loss_cls: 0.3383  loss_box_reg: 0.272  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.0178  time: 0.5821  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 09:52:12 d2.utils.events]: [39m eta: 2:14:54  iter: 1059  total_loss: 0.7071  loss_cls: 0.3837  loss_box_reg: 0.2674  loss_rpn_cls: 0.03118  loss_rpn_loc: 0.02821  time: 0.5821  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 09:52:23 d2.utils.events]: [39m eta: 2:14:44  iter: 1079  total_loss: 0.8722  loss_cls: 0.4617  loss_box_reg: 0.3124  loss_rpn_cls: 0.0227  loss_rpn_loc: 0.03408  time: 0.5822  data_time: 0.0147  lr: 0.001  max_mem: 6307M
[32m[03/25 09:52:35 d2.utils.events]: [39m eta: 2:14:34  iter: 1099  total_loss: 0.7541  loss_cls: 0.4367  loss_box_reg: 0.2479  loss_rpn_cls: 0.02916  loss_rpn_loc: 0.02291  time: 0.5824  data_time: 0.0143  lr: 0.001  max_mem: 6307M
[32m[03/25 09:52:47 d2.utils.events]: [39m eta: 2:14:23  iter: 1119  total_loss: 0.7837  loss_cls: 0.4321  loss_box_reg: 0.3188  loss_rpn_cls: 0.02399  loss_rpn_loc: 0.03088  time: 0.5825  data_time: 0.0147  lr: 0.001  max_mem: 6307M
[32m[03/25 09:52:59 d2.utils.events]: [39m eta: 2:14:12  iter: 1139  total_loss: 0.7998  loss_cls: 0.438  loss_box_reg: 0.2962  loss_rpn_cls: 0.02786  loss_rpn_loc: 0.02508  time: 0.5824  data_time: 0.0130  lr: 0.001  max_mem: 6307M
[32m[03/25 09:53:10 d2.utils.events]: [39m eta: 2:14:03  iter: 1159  total_loss: 0.8546  loss_cls: 0.4704  loss_box_reg: 0.354  loss_rpn_cls: 0.03111  loss_rpn_loc: 0.0304  time: 0.5825  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 09:53:22 d2.utils.events]: [39m eta: 2:13:53  iter: 1179  total_loss: 0.8655  loss_cls: 0.4645  loss_box_reg: 0.3147  loss_rpn_cls: 0.02186  loss_rpn_loc: 0.02324  time: 0.5826  data_time: 0.0136  lr: 0.001  max_mem: 6307M
[32m[03/25 09:53:34 d2.utils.events]: [39m eta: 2:13:43  iter: 1199  total_loss: 0.7551  loss_cls: 0.456  loss_box_reg: 0.2706  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.02486  time: 0.5827  data_time: 0.0149  lr: 0.001  max_mem: 6307M
[32m[03/25 09:53:46 d2.utils.events]: [39m eta: 2:13:33  iter: 1219  total_loss: 0.9015  loss_cls: 0.454  loss_box_reg: 0.3211  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.05322  time: 0.5828  data_time: 0.0138  lr: 0.001  max_mem: 6307M
[32m[03/25 09:53:57 d2.utils.events]: [39m eta: 2:13:22  iter: 1239  total_loss: 0.6857  loss_cls: 0.3855  loss_box_reg: 0.2463  loss_rpn_cls: 0.02329  loss_rpn_loc: 0.01515  time: 0.5828  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 09:54:09 d2.utils.events]: [39m eta: 2:13:11  iter: 1259  total_loss: 0.9365  loss_cls: 0.4553  loss_box_reg: 0.3669  loss_rpn_cls: 0.02726  loss_rpn_loc: 0.04833  time: 0.5828  data_time: 0.0135  lr: 0.001  max_mem: 6307M
[32m[03/25 09:54:21 d2.utils.events]: [39m eta: 2:13:00  iter: 1279  total_loss: 0.9261  loss_cls: 0.4768  loss_box_reg: 0.326  loss_rpn_cls: 0.02656  loss_rpn_loc: 0.03529  time: 0.5829  data_time: 0.0154  lr: 0.001  max_mem: 6307M
[32m[03/25 09:54:33 d2.utils.events]: [39m eta: 2:12:50  iter: 1299  total_loss: 0.8484  loss_cls: 0.4516  loss_box_reg: 0.312  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.02254  time: 0.5830  data_time: 0.0152  lr: 0.001  max_mem: 6307M
[32m[03/25 09:54:44 d2.utils.events]: [39m eta: 2:12:38  iter: 1319  total_loss: 0.6672  loss_cls: 0.3535  loss_box_reg: 0.2324  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.02384  time: 0.5830  data_time: 0.0131  lr: 0.001  max_mem: 6307M
[32m[03/25 09:54:56 d2.utils.events]: [39m eta: 2:12:26  iter: 1339  total_loss: 0.7293  loss_cls: 0.4056  loss_box_reg: 0.2576  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.01429  time: 0.5829  data_time: 0.0132  lr: 0.001  max_mem: 6307M
[32m[03/25 09:55:08 d2.utils.events]: [39m eta: 2:12:15  iter: 1359  total_loss: 0.7  loss_cls: 0.4057  loss_box_reg: 0.2512  loss_rpn_cls: 0.02269  loss_rpn_loc: 0.02251  time: 0.5829  data_time: 0.0133  lr: 0.001  max_mem: 6307M
[32m[03/25 09:55:19 d2.utils.events]: [39m eta: 2:12:05  iter: 1379  total_loss: 0.8448  loss_cls: 0.4273  loss_box_reg: 0.3194  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.02004  time: 0.5830  data_time: 0.0141  lr: 0.001  max_mem: 6307M
[32m[03/25 09:55:31 d2.utils.events]: [39m eta: 2:11:53  iter: 1399  total_loss: 0.7651  loss_cls: 0.4057  loss_box_reg: 0.2739  loss_rpn_cls: 0.01684  loss_rpn_loc: 0.0171  time: 0.5830  data_time: 0.0132  lr: 0.001  max_mem: 6307M
[32m[03/25 09:55:43 d2.utils.events]: [39m eta: 2:11:43  iter: 1419  total_loss: 0.7443  loss_cls: 0.4137  loss_box_reg: 0.2727  loss_rpn_cls: 0.0274  loss_rpn_loc: 0.03543  time: 0.5832  data_time: 0.0156  lr: 0.001  max_mem: 6307M
[32m[03/25 09:55:55 d2.utils.events]: [39m eta: 2:11:32  iter: 1439  total_loss: 0.7761  loss_cls: 0.4014  loss_box_reg: 0.2732  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.02728  time: 0.5831  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 09:56:06 d2.utils.events]: [39m eta: 2:11:19  iter: 1459  total_loss: 0.7394  loss_cls: 0.3906  loss_box_reg: 0.2646  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.01723  time: 0.5831  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 09:56:18 d2.utils.events]: [39m eta: 2:11:06  iter: 1479  total_loss: 0.7563  loss_cls: 0.4228  loss_box_reg: 0.307  loss_rpn_cls: 0.0201  loss_rpn_loc: 0.02247  time: 0.5831  data_time: 0.0133  lr: 0.001  max_mem: 6307M
[32m[03/25 09:56:30 d2.utils.events]: [39m eta: 2:10:54  iter: 1499  total_loss: 0.7778  loss_cls: 0.4283  loss_box_reg: 0.2841  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.02859  time: 0.5831  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 09:56:41 d2.utils.events]: [39m eta: 2:10:43  iter: 1519  total_loss: 0.7808  loss_cls: 0.4411  loss_box_reg: 0.2866  loss_rpn_cls: 0.02982  loss_rpn_loc: 0.02719  time: 0.5833  data_time: 0.0145  lr: 0.001  max_mem: 6307M
[32m[03/25 09:56:53 d2.utils.events]: [39m eta: 2:10:33  iter: 1539  total_loss: 0.7315  loss_cls: 0.3952  loss_box_reg: 0.2725  loss_rpn_cls: 0.01737  loss_rpn_loc: 0.01792  time: 0.5834  data_time: 0.0143  lr: 0.001  max_mem: 6307M
[32m[03/25 09:57:05 d2.utils.events]: [39m eta: 2:10:22  iter: 1559  total_loss: 0.7102  loss_cls: 0.4252  loss_box_reg: 0.2907  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.01138  time: 0.5834  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 09:57:17 d2.utils.events]: [39m eta: 2:10:11  iter: 1579  total_loss: 0.9096  loss_cls: 0.4998  loss_box_reg: 0.3317  loss_rpn_cls: 0.0246  loss_rpn_loc: 0.04374  time: 0.5835  data_time: 0.0142  lr: 0.001  max_mem: 6307M
[32m[03/25 09:57:28 d2.utils.events]: [39m eta: 2:09:59  iter: 1599  total_loss: 0.7381  loss_cls: 0.4151  loss_box_reg: 0.2721  loss_rpn_cls: 0.02093  loss_rpn_loc: 0.03427  time: 0.5834  data_time: 0.0125  lr: 0.001  max_mem: 6307M
[32m[03/25 09:57:40 d2.utils.events]: [39m eta: 2:09:48  iter: 1619  total_loss: 0.999  loss_cls: 0.522  loss_box_reg: 0.3461  loss_rpn_cls: 0.03099  loss_rpn_loc: 0.04473  time: 0.5835  data_time: 0.0149  lr: 0.001  max_mem: 6307M
[32m[03/25 09:57:52 d2.utils.events]: [39m eta: 2:09:37  iter: 1639  total_loss: 0.813  loss_cls: 0.4509  loss_box_reg: 0.305  loss_rpn_cls: 0.02351  loss_rpn_loc: 0.02526  time: 0.5835  data_time: 0.0126  lr: 0.001  max_mem: 6307M
[32m[03/25 09:58:04 d2.utils.events]: [39m eta: 2:09:26  iter: 1659  total_loss: 0.7165  loss_cls: 0.3769  loss_box_reg: 0.2639  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.01812  time: 0.5835  data_time: 0.0127  lr: 0.001  max_mem: 6307M
[32m[03/25 09:58:15 d2.utils.events]: [39m eta: 2:09:15  iter: 1679  total_loss: 0.8566  loss_cls: 0.4616  loss_box_reg: 0.2484  loss_rpn_cls: 0.02391  loss_rpn_loc: 0.0338  time: 0.5835  data_time: 0.0145  lr: 0.001  max_mem: 6307M
[32m[03/25 09:58:27 d2.utils.events]: [39m eta: 2:09:04  iter: 1699  total_loss: 0.8833  loss_cls: 0.4794  loss_box_reg: 0.2841  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.0311  time: 0.5835  data_time: 0.0139  lr: 0.001  max_mem: 6307M
[32m[03/25 09:58:39 d2.utils.events]: [39m eta: 2:08:50  iter: 1719  total_loss: 0.8156  loss_cls: 0.4611  loss_box_reg: 0.3034  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.0261  time: 0.5835  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 09:58:50 d2.utils.events]: [39m eta: 2:08:37  iter: 1739  total_loss: 0.8373  loss_cls: 0.4415  loss_box_reg: 0.2925  loss_rpn_cls: 0.02605  loss_rpn_loc: 0.01399  time: 0.5834  data_time: 0.0130  lr: 0.001  max_mem: 6307M
[32m[03/25 09:59:02 d2.utils.events]: [39m eta: 2:08:25  iter: 1759  total_loss: 0.658  loss_cls: 0.3882  loss_box_reg: 0.2705  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.01719  time: 0.5834  data_time: 0.0130  lr: 0.001  max_mem: 6307M
[32m[03/25 09:59:13 d2.utils.events]: [39m eta: 2:08:11  iter: 1779  total_loss: 0.7403  loss_cls: 0.377  loss_box_reg: 0.2934  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.02319  time: 0.5833  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 09:59:25 d2.utils.events]: [39m eta: 2:07:59  iter: 1799  total_loss: 0.8065  loss_cls: 0.4301  loss_box_reg: 0.2902  loss_rpn_cls: 0.02127  loss_rpn_loc: 0.02855  time: 0.5833  data_time: 0.0149  lr: 0.001  max_mem: 6307M
[32m[03/25 09:59:37 d2.utils.events]: [39m eta: 2:07:49  iter: 1819  total_loss: 0.8316  loss_cls: 0.4428  loss_box_reg: 0.3131  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.02108  time: 0.5833  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 09:59:48 d2.utils.events]: [39m eta: 2:07:38  iter: 1839  total_loss: 0.7839  loss_cls: 0.4659  loss_box_reg: 0.2529  loss_rpn_cls: 0.02482  loss_rpn_loc: 0.03197  time: 0.5833  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:00:00 d2.utils.events]: [39m eta: 2:07:27  iter: 1859  total_loss: 0.7696  loss_cls: 0.4451  loss_box_reg: 0.2521  loss_rpn_cls: 0.02711  loss_rpn_loc: 0.02759  time: 0.5833  data_time: 0.0132  lr: 0.001  max_mem: 6307M
[32m[03/25 10:00:12 d2.utils.events]: [39m eta: 2:07:15  iter: 1879  total_loss: 0.778  loss_cls: 0.4214  loss_box_reg: 0.2805  loss_rpn_cls: 0.02001  loss_rpn_loc: 0.02465  time: 0.5833  data_time: 0.0138  lr: 0.001  max_mem: 6307M
[32m[03/25 10:00:23 d2.utils.events]: [39m eta: 2:07:05  iter: 1899  total_loss: 0.644  loss_cls: 0.3609  loss_box_reg: 0.231  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.01509  time: 0.5833  data_time: 0.0130  lr: 0.001  max_mem: 6307M
[32m[03/25 10:00:35 d2.utils.events]: [39m eta: 2:06:52  iter: 1919  total_loss: 0.8874  loss_cls: 0.4911  loss_box_reg: 0.3262  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.03245  time: 0.5832  data_time: 0.0131  lr: 0.001  max_mem: 6307M
[32m[03/25 10:00:47 d2.utils.events]: [39m eta: 2:06:40  iter: 1939  total_loss: 0.9532  loss_cls: 0.4508  loss_box_reg: 0.3464  loss_rpn_cls: 0.02534  loss_rpn_loc: 0.04145  time: 0.5832  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 10:00:58 d2.utils.events]: [39m eta: 2:06:29  iter: 1959  total_loss: 0.8059  loss_cls: 0.4263  loss_box_reg: 0.2648  loss_rpn_cls: 0.02215  loss_rpn_loc: 0.02599  time: 0.5832  data_time: 0.0132  lr: 0.001  max_mem: 6307M
[32m[03/25 10:01:10 d2.utils.events]: [39m eta: 2:06:16  iter: 1979  total_loss: 0.8173  loss_cls: 0.443  loss_box_reg: 0.3248  loss_rpn_cls: 0.02897  loss_rpn_loc: 0.02632  time: 0.5832  data_time: 0.0127  lr: 0.001  max_mem: 6307M
[32m[03/25 10:01:21 d2.utils.events]: [39m eta: 2:06:03  iter: 1999  total_loss: 0.7388  loss_cls: 0.3751  loss_box_reg: 0.2593  loss_rpn_cls: 0.02245  loss_rpn_loc: 0.03728  time: 0.5831  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:01:33 d2.utils.events]: [39m eta: 2:05:50  iter: 2019  total_loss: 0.8699  loss_cls: 0.4875  loss_box_reg: 0.3065  loss_rpn_cls: 0.02167  loss_rpn_loc: 0.0308  time: 0.5831  data_time: 0.0126  lr: 0.001  max_mem: 6307M
[32m[03/25 10:01:45 d2.utils.events]: [39m eta: 2:05:38  iter: 2039  total_loss: 0.6722  loss_cls: 0.3516  loss_box_reg: 0.2767  loss_rpn_cls: 0.02187  loss_rpn_loc: 0.02351  time: 0.5830  data_time: 0.0133  lr: 0.001  max_mem: 6307M
[32m[03/25 10:01:56 d2.utils.events]: [39m eta: 2:05:27  iter: 2059  total_loss: 0.6387  loss_cls: 0.4038  loss_box_reg: 0.2675  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.01941  time: 0.5830  data_time: 0.0133  lr: 0.001  max_mem: 6307M
[32m[03/25 10:02:08 d2.utils.events]: [39m eta: 2:05:15  iter: 2079  total_loss: 0.9902  loss_cls: 0.5048  loss_box_reg: 0.3594  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.03015  time: 0.5831  data_time: 0.0144  lr: 0.001  max_mem: 6307M
[32m[03/25 10:02:20 d2.utils.events]: [39m eta: 2:05:02  iter: 2099  total_loss: 0.9129  loss_cls: 0.453  loss_box_reg: 0.3641  loss_rpn_cls: 0.03066  loss_rpn_loc: 0.041  time: 0.5830  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:02:31 d2.utils.events]: [39m eta: 2:04:50  iter: 2119  total_loss: 0.8244  loss_cls: 0.47  loss_box_reg: 0.27  loss_rpn_cls: 0.02437  loss_rpn_loc: 0.02819  time: 0.5831  data_time: 0.0140  lr: 0.001  max_mem: 6307M
[32m[03/25 10:02:43 d2.utils.events]: [39m eta: 2:04:39  iter: 2139  total_loss: 0.7279  loss_cls: 0.3891  loss_box_reg: 0.2812  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.01765  time: 0.5831  data_time: 0.0164  lr: 0.001  max_mem: 6307M
[32m[03/25 10:02:55 d2.utils.events]: [39m eta: 2:04:27  iter: 2159  total_loss: 0.7158  loss_cls: 0.3928  loss_box_reg: 0.2919  loss_rpn_cls: 0.02758  loss_rpn_loc: 0.0182  time: 0.5831  data_time: 0.0143  lr: 0.001  max_mem: 6307M
[32m[03/25 10:03:07 d2.utils.events]: [39m eta: 2:04:14  iter: 2179  total_loss: 0.6372  loss_cls: 0.3466  loss_box_reg: 0.2413  loss_rpn_cls: 0.01997  loss_rpn_loc: 0.02741  time: 0.5831  data_time: 0.0151  lr: 0.001  max_mem: 6307M
[32m[03/25 10:03:18 d2.utils.events]: [39m eta: 2:04:02  iter: 2199  total_loss: 0.7061  loss_cls: 0.3308  loss_box_reg: 0.2605  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.03345  time: 0.5831  data_time: 0.0141  lr: 0.001  max_mem: 6307M
[32m[03/25 10:03:30 d2.utils.events]: [39m eta: 2:03:50  iter: 2219  total_loss: 0.7629  loss_cls: 0.4236  loss_box_reg: 0.2841  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.02526  time: 0.5831  data_time: 0.0127  lr: 0.001  max_mem: 6307M
[32m[03/25 10:03:42 d2.utils.events]: [39m eta: 2:03:39  iter: 2239  total_loss: 0.7678  loss_cls: 0.4058  loss_box_reg: 0.2848  loss_rpn_cls: 0.02235  loss_rpn_loc: 0.02508  time: 0.5831  data_time: 0.0130  lr: 0.001  max_mem: 6307M
[32m[03/25 10:03:53 d2.utils.events]: [39m eta: 2:03:27  iter: 2259  total_loss: 0.8053  loss_cls: 0.4629  loss_box_reg: 0.2682  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.02149  time: 0.5831  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 10:04:05 d2.utils.events]: [39m eta: 2:03:14  iter: 2279  total_loss: 0.6306  loss_cls: 0.3683  loss_box_reg: 0.2227  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.01397  time: 0.5831  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 10:04:17 d2.utils.events]: [39m eta: 2:03:01  iter: 2299  total_loss: 0.6986  loss_cls: 0.3803  loss_box_reg: 0.2482  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.01446  time: 0.5831  data_time: 0.0134  lr: 0.001  max_mem: 6307M
[32m[03/25 10:04:28 d2.utils.events]: [39m eta: 2:02:50  iter: 2319  total_loss: 0.8384  loss_cls: 0.4216  loss_box_reg: 0.3535  loss_rpn_cls: 0.02228  loss_rpn_loc: 0.02479  time: 0.5831  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 10:04:40 d2.utils.events]: [39m eta: 2:02:40  iter: 2339  total_loss: 0.8172  loss_cls: 0.432  loss_box_reg: 0.2527  loss_rpn_cls: 0.0256  loss_rpn_loc: 0.02959  time: 0.5830  data_time: 0.0125  lr: 0.001  max_mem: 6307M
[32m[03/25 10:04:52 d2.utils.events]: [39m eta: 2:02:28  iter: 2359  total_loss: 0.7015  loss_cls: 0.3852  loss_box_reg: 0.2872  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.02661  time: 0.5831  data_time: 0.0137  lr: 0.001  max_mem: 6307M
[32m[03/25 10:05:03 d2.utils.events]: [39m eta: 2:02:15  iter: 2379  total_loss: 0.7725  loss_cls: 0.4395  loss_box_reg: 0.2562  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.02402  time: 0.5830  data_time: 0.0127  lr: 0.001  max_mem: 6307M
[32m[03/25 10:05:15 d2.utils.events]: [39m eta: 2:02:02  iter: 2399  total_loss: 0.6368  loss_cls: 0.3661  loss_box_reg: 0.2444  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.01643  time: 0.5830  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:05:26 d2.utils.events]: [39m eta: 2:01:48  iter: 2419  total_loss: 0.7378  loss_cls: 0.4393  loss_box_reg: 0.2513  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.02492  time: 0.5830  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:05:38 d2.utils.events]: [39m eta: 2:01:37  iter: 2439  total_loss: 0.7987  loss_cls: 0.4521  loss_box_reg: 0.2786  loss_rpn_cls: 0.03247  loss_rpn_loc: 0.02943  time: 0.5830  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:05:50 d2.utils.events]: [39m eta: 2:01:26  iter: 2459  total_loss: 0.5997  loss_cls: 0.3468  loss_box_reg: 0.1983  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.01225  time: 0.5830  data_time: 0.0133  lr: 0.001  max_mem: 6307M
[32m[03/25 10:06:01 d2.utils.events]: [39m eta: 2:01:15  iter: 2479  total_loss: 0.8245  loss_cls: 0.4399  loss_box_reg: 0.2733  loss_rpn_cls: 0.0336  loss_rpn_loc: 0.02728  time: 0.5830  data_time: 0.0135  lr: 0.001  max_mem: 6307M
[32m[03/25 10:06:13 d2.utils.events]: [39m eta: 2:01:03  iter: 2499  total_loss: 0.5677  loss_cls: 0.3218  loss_box_reg: 0.201  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.01547  time: 0.5830  data_time: 0.0137  lr: 0.001  max_mem: 6307M
[32m[03/25 10:06:25 d2.utils.events]: [39m eta: 2:00:50  iter: 2519  total_loss: 0.7745  loss_cls: 0.3868  loss_box_reg: 0.2819  loss_rpn_cls: 0.01949  loss_rpn_loc: 0.02705  time: 0.5829  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:06:36 d2.utils.events]: [39m eta: 2:00:37  iter: 2539  total_loss: 0.7597  loss_cls: 0.3957  loss_box_reg: 0.2924  loss_rpn_cls: 0.02427  loss_rpn_loc: 0.0237  time: 0.5829  data_time: 0.0131  lr: 0.001  max_mem: 6307M
[32m[03/25 10:06:48 d2.utils.events]: [39m eta: 2:00:25  iter: 2559  total_loss: 0.6886  loss_cls: 0.3672  loss_box_reg: 0.2506  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.02678  time: 0.5829  data_time: 0.0135  lr: 0.001  max_mem: 6307M
[32m[03/25 10:07:00 d2.utils.events]: [39m eta: 2:00:13  iter: 2579  total_loss: 0.7106  loss_cls: 0.3812  loss_box_reg: 0.2381  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.02114  time: 0.5830  data_time: 0.0144  lr: 0.001  max_mem: 6307M
[32m[03/25 10:07:11 d2.utils.events]: [39m eta: 2:00:02  iter: 2599  total_loss: 0.7365  loss_cls: 0.4327  loss_box_reg: 0.2625  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.02213  time: 0.5830  data_time: 0.0138  lr: 0.001  max_mem: 6307M
[32m[03/25 10:07:23 d2.utils.events]: [39m eta: 1:59:51  iter: 2619  total_loss: 0.6702  loss_cls: 0.3535  loss_box_reg: 0.2691  loss_rpn_cls: 0.01674  loss_rpn_loc: 0.03059  time: 0.5830  data_time: 0.0161  lr: 0.001  max_mem: 6307M
[32m[03/25 10:07:35 d2.utils.events]: [39m eta: 1:59:40  iter: 2639  total_loss: 0.7853  loss_cls: 0.4238  loss_box_reg: 0.3038  loss_rpn_cls: 0.01945  loss_rpn_loc: 0.02546  time: 0.5830  data_time: 0.0132  lr: 0.001  max_mem: 6307M
[32m[03/25 10:07:47 d2.utils.events]: [39m eta: 1:59:27  iter: 2659  total_loss: 0.7493  loss_cls: 0.4354  loss_box_reg: 0.272  loss_rpn_cls: 0.02635  loss_rpn_loc: 0.03007  time: 0.5830  data_time: 0.0127  lr: 0.001  max_mem: 6307M
[32m[03/25 10:07:58 d2.utils.events]: [39m eta: 1:59:14  iter: 2679  total_loss: 0.6954  loss_cls: 0.3603  loss_box_reg: 0.2963  loss_rpn_cls: 0.02343  loss_rpn_loc: 0.0286  time: 0.5830  data_time: 0.0131  lr: 0.001  max_mem: 6307M
[32m[03/25 10:08:10 d2.utils.events]: [39m eta: 1:59:02  iter: 2699  total_loss: 0.7281  loss_cls: 0.4044  loss_box_reg: 0.2627  loss_rpn_cls: 0.02639  loss_rpn_loc: 0.02411  time: 0.5830  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 10:08:21 d2.utils.events]: [39m eta: 1:58:51  iter: 2719  total_loss: 0.6925  loss_cls: 0.3729  loss_box_reg: 0.2487  loss_rpn_cls: 0.01691  loss_rpn_loc: 0.03817  time: 0.5829  data_time: 0.0127  lr: 0.001  max_mem: 6307M
[32m[03/25 10:08:33 d2.utils.events]: [39m eta: 1:58:40  iter: 2739  total_loss: 0.7078  loss_cls: 0.3897  loss_box_reg: 0.2724  loss_rpn_cls: 0.01579  loss_rpn_loc: 0.02117  time: 0.5829  data_time: 0.0128  lr: 0.001  max_mem: 6307M
[32m[03/25 10:08:45 d2.utils.events]: [39m eta: 1:58:29  iter: 2759  total_loss: 0.7973  loss_cls: 0.4358  loss_box_reg: 0.2512  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.01781  time: 0.5830  data_time: 0.0163  lr: 0.001  max_mem: 6307M
[32m[03/25 10:08:57 d2.utils.events]: [39m eta: 1:58:18  iter: 2779  total_loss: 0.6894  loss_cls: 0.366  loss_box_reg: 0.2391  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01403  time: 0.5830  data_time: 0.0130  lr: 0.001  max_mem: 6307M
[32m[03/25 10:09:08 d2.utils.events]: [39m eta: 1:58:06  iter: 2799  total_loss: 0.7204  loss_cls: 0.372  loss_box_reg: 0.3113  loss_rpn_cls: 0.022  loss_rpn_loc: 0.02921  time: 0.5830  data_time: 0.0127  lr: 0.001  max_mem: 6307M
[32m[03/25 10:09:20 d2.utils.events]: [39m eta: 1:57:54  iter: 2819  total_loss: 0.7475  loss_cls: 0.4001  loss_box_reg: 0.3057  loss_rpn_cls: 0.01956  loss_rpn_loc: 0.03198  time: 0.5830  data_time: 0.0138  lr: 0.001  max_mem: 6307M
[32m[03/25 10:09:31 d2.utils.events]: [39m eta: 1:57:42  iter: 2839  total_loss: 0.8068  loss_cls: 0.3743  loss_box_reg: 0.3227  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.03536  time: 0.5829  data_time: 0.0129  lr: 0.001  max_mem: 6307M
[32m[03/25 10:09:43 d2.utils.events]: [39m eta: 1:57:30  iter: 2859  total_loss: 0.6572  loss_cls: 0.3948  loss_box_reg: 0.2264  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.02248  time: 0.5829  data_time: 0.0146  lr: 0.001  max_mem: 6307M
[32m[03/25 10:09:55 d2.utils.events]: [39m eta: 1:57:18  iter: 2879  total_loss: 0.7149  loss_cls: 0.4174  loss_box_reg: 0.2517  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.01786  time: 0.5829  data_time: 0.0141  lr: 0.001  max_mem: 6307M
[32m[03/25 10:10:06 d2.utils.events]: [39m eta: 1:57:06  iter: 2899  total_loss: 0.8096  loss_cls: 0.4377  loss_box_reg: 0.3051  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.02124  time: 0.5829  data_time: 0.0133  lr: 0.001  max_mem: 6307M
[32m[03/25 10:10:18 d2.utils.events]: [39m eta: 1:56:55  iter: 2919  total_loss: 0.6606  loss_cls: 0.3625  loss_box_reg: 0.2616  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.01955  time: 0.5829  data_time: 0.0131  lr: 0.001  max_mem: 6307M
[32m[03/25 10:10:30 d2.utils.events]: [39m eta: 1:56:44  iter: 2939  total_loss: 0.5899  loss_cls: 0.3265  loss_box_reg: 0.192  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01456  time: 0.5829  data_time: 0.0133  lr: 0.001  max_mem: 6307M
[32m[03/25 10:10:41 d2.utils.events]: [39m eta: 1:56:33  iter: 2959  total_loss: 0.7233  loss_cls: 0.3934  loss_box_reg: 0.2874  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.02497  time: 0.5829  data_time: 0.0132  lr: 0.001  max_mem: 6307M
[32m[03/25 10:10:53 d2.utils.events]: [39m eta: 1:56:22  iter: 2979  total_loss: 0.7273  loss_cls: 0.3646  loss_box_reg: 0.2715  loss_rpn_cls: 0.01789  loss_rpn_loc: 0.02382  time: 0.5829  data_time: 0.0132  lr: 0.001  max_mem: 6307M
[32m[03/25 10:11:06 d2.data.datasets.coco]: [39mLoaded 4883 images in COCO format from ../../dataset/train.json
[32m[03/25 10:11:07 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/25 10:11:07 d2.data.common]: [39mSerializing 4883 elements to byte tensors and concatenating them all ...
[32m[03/25 10:11:07 d2.data.common]: [39mSerialized dataset takes 2.19 MiB
[31m[5mWARNING[39m[25m [32m[03/25 10:11:07 d2.evaluation.coco_evaluation]: [39mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[03/25 10:11:07 d2.evaluation.evaluator]: [39mStart inference on 4883 batches
[32m[03/25 10:11:08 d2.evaluation.evaluator]: [39mInference done 11/4883. Dataloading: 0.0007 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:03:46
[32m[03/25 10:11:13 d2.evaluation.evaluator]: [39mInference done 117/4883. Dataloading: 0.0011 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:46
[32m[03/25 10:11:18 d2.evaluation.evaluator]: [39mInference done 222/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:03:42
[32m[03/25 10:11:23 d2.evaluation.evaluator]: [39mInference done 327/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:03:37
[32m[03/25 10:11:28 d2.evaluation.evaluator]: [39mInference done 433/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:03:31
[32m[03/25 10:11:33 d2.evaluation.evaluator]: [39mInference done 540/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:03:26
[32m[03/25 10:11:38 d2.evaluation.evaluator]: [39mInference done 647/4883. Dataloading: 0.0012 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:20
[32m[03/25 10:11:43 d2.evaluation.evaluator]: [39mInference done 751/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:03:16
[32m[03/25 10:11:48 d2.evaluation.evaluator]: [39mInference done 854/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:03:12
[32m[03/25 10:11:53 d2.evaluation.evaluator]: [39mInference done 960/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:03:06
[32m[03/25 10:11:58 d2.evaluation.evaluator]: [39mInference done 1067/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:03:01
[32m[03/25 10:12:03 d2.evaluation.evaluator]: [39mInference done 1172/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:56
[32m[03/25 10:12:08 d2.evaluation.evaluator]: [39mInference done 1278/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:51
[32m[03/25 10:12:13 d2.evaluation.evaluator]: [39mInference done 1385/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:46
[32m[03/25 10:12:18 d2.evaluation.evaluator]: [39mInference done 1492/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:41
[32m[03/25 10:12:23 d2.evaluation.evaluator]: [39mInference done 1600/4883. Dataloading: 0.0012 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:02:35
[32m[03/25 10:12:28 d2.evaluation.evaluator]: [39mInference done 1707/4883. Dataloading: 0.0012 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:02:30
[32m[03/25 10:12:33 d2.evaluation.evaluator]: [39mInference done 1812/4883. Dataloading: 0.0012 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:02:25
[32m[03/25 10:12:38 d2.evaluation.evaluator]: [39mInference done 1915/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:21
[32m[03/25 10:12:43 d2.evaluation.evaluator]: [39mInference done 2022/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:15
[32m[03/25 10:12:48 d2.evaluation.evaluator]: [39mInference done 2128/4883. Dataloading: 0.0012 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:10
[32m[03/25 10:12:53 d2.evaluation.evaluator]: [39mInference done 2233/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:05
[32m[03/25 10:12:58 d2.evaluation.evaluator]: [39mInference done 2335/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:01
[32m[03/25 10:13:03 d2.evaluation.evaluator]: [39mInference done 2440/4883. Dataloading: 0.0012 s/iter. Inference: 0.0460 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:01:56
[32m[03/25 10:13:08 d2.evaluation.evaluator]: [39mInference done 2545/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:01:51
[32m[03/25 10:13:13 d2.evaluation.evaluator]: [39mInference done 2645/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:46
[32m[03/25 10:13:18 d2.evaluation.evaluator]: [39mInference done 2749/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:41
[32m[03/25 10:13:23 d2.evaluation.evaluator]: [39mInference done 2854/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:36
[32m[03/25 10:13:28 d2.evaluation.evaluator]: [39mInference done 2960/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:31
[32m[03/25 10:13:33 d2.evaluation.evaluator]: [39mInference done 3065/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:26
[32m[03/25 10:13:38 d2.evaluation.evaluator]: [39mInference done 3170/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:21
[32m[03/25 10:13:43 d2.evaluation.evaluator]: [39mInference done 3276/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:16
[32m[03/25 10:13:48 d2.evaluation.evaluator]: [39mInference done 3381/4883. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:01:11
[32m[03/25 10:13:53 d2.evaluation.evaluator]: [39mInference done 3481/4883. Dataloading: 0.0012 s/iter. Inference: 0.0462 s/iter. Eval: 0.0003 s/iter. Total: 0.0478 s/iter. ETA=0:01:06
[32m[03/25 10:13:58 d2.evaluation.evaluator]: [39mInference done 3578/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:01:02
[32m[03/25 10:14:03 d2.evaluation.evaluator]: [39mInference done 3684/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:57
[32m[03/25 10:14:08 d2.evaluation.evaluator]: [39mInference done 3789/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:52
[32m[03/25 10:14:14 d2.evaluation.evaluator]: [39mInference done 3893/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:47
[32m[03/25 10:14:19 d2.evaluation.evaluator]: [39mInference done 3994/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:42
[32m[03/25 10:14:24 d2.evaluation.evaluator]: [39mInference done 4100/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:37
[32m[03/25 10:14:29 d2.evaluation.evaluator]: [39mInference done 4205/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:32
[32m[03/25 10:14:34 d2.evaluation.evaluator]: [39mInference done 4309/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:27
[32m[03/25 10:14:39 d2.evaluation.evaluator]: [39mInference done 4413/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:22
[32m[03/25 10:14:44 d2.evaluation.evaluator]: [39mInference done 4517/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:17
[32m[03/25 10:14:49 d2.evaluation.evaluator]: [39mInference done 4623/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:12
[32m[03/25 10:14:54 d2.evaluation.evaluator]: [39mInference done 4728/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:07
[32m[03/25 10:14:59 d2.evaluation.evaluator]: [39mInference done 4835/4883. Dataloading: 0.0012 s/iter. Inference: 0.0463 s/iter. Eval: 0.0003 s/iter. Total: 0.0479 s/iter. ETA=0:00:02
[32m[03/25 10:15:01 d2.evaluation.evaluator]: [39mTotal inference time: 0:03:53.696387 (0.047908 s / iter per device, on 1 devices)
[32m[03/25 10:15:01 d2.evaluation.evaluator]: [39mTotal inference pure compute time: 0:03:45 (0.046305 s / iter per device, on 1 devices)
[32m[03/25 10:15:02 d2.evaluation.coco_evaluation]: [39mPreparing results for COCO format ...
[32m[03/25 10:15:02 d2.evaluation.coco_evaluation]: [39mSaving results to ./output_eval/coco_instances_results.json
[32m[03/25 10:15:03 d2.evaluation.coco_evaluation]: [39mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.63s)
creating index...
index created!
[32m[03/25 10:15:03 d2.evaluation.fast_eval_api]: [39mEvaluate annotation type *bbox*
[32m[03/25 10:15:06 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.evaluate() finished in 2.90 seconds.
[32m[03/25 10:15:06 d2.evaluation.fast_eval_api]: [39mAccumulating evaluation results...
[32m[03/25 10:15:07 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.accumulate() finished in 0.69 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.433
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.056
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.269
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.511
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627
[32m[03/25 10:15:07 d2.evaluation.coco_evaluation]: [39mEvaluation results for bbox:
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 31.198 | 43.279 | 34.373 | 0.802 | 5.595 | 37.190 |
[32m[03/25 10:15:07 d2.evaluation.coco_evaluation]: [39mPer-category bbox AP:
| category      | AP     | category    | AP     | category   | AP     |
|:--------------|:-------|:------------|:-------|:-----------|:-------|
| General trash | 15.807 | Paper       | 25.876 | Paper pack | 29.088 |
| Metal         | 30.849 | Glass       | 31.645 | Plastic    | 22.637 |
| Styrofoam     | 26.145 | Plastic bag | 49.899 | Battery    | 49.279 |
| Clothing      | 30.750 |             |        |            |        |
[32m[03/25 10:15:07 d2.engine.defaults]: [39mEvaluation results for coco_trash_train in csv format:
[32m[03/25 10:15:07 d2.evaluation.testing]: [39mcopypaste: Task: bbox
[32m[03/25 10:15:07 d2.evaluation.testing]: [39mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/25 10:15:07 d2.evaluation.testing]: [39mcopypaste: 31.1976,43.2790,34.3728,0.8018,5.5954,37.1897
[31m[4m[5mERROR[39m[24m[25m [32m[03/25 10:15:07 d2.engine.train_loop]: [39mException during training:
Traceback (most recent call last):
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 151, in train
    self.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 181, in after_step
    h.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 449, in after_step
    self._do_eval()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 422, in _do_eval
    results = self._func()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 460, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 624, in test
    print_csv_format(results_i)
  File "/opt/ml/detection/baseline/detectron2/detectron2/evaluation/testing.py", line 41, in print_csv_format
    wandb.log(eval_dict)
NameError: name 'wandb' is not defined
[32m[03/25 10:15:07 d2.engine.hooks]: [39mOverall training speed: 2997 iterations in 0:29:07 (0.5831 s / it)
[32m[03/25 10:15:07 d2.engine.hooks]: [39mTotal training time: 0:33:12 (0:04:04 on hooks)
[32m[03/25 10:15:07 d2.utils.events]: [39m eta: 1:56:11  iter: 2999  total_loss: 0.6594  loss_cls: 0.3599  loss_box_reg: 0.2624  loss_rpn_cls: 0.01669  loss_rpn_loc: 0.02399  time: 0.5829  data_time: 0.0135  lr: 0.001  max_mem: 6307M
Traceback (most recent call last):
  File "train.py", line 118, in <module>
    trainer.train()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 491, in train
    super().train(self.start_iter, self.max_iter)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 151, in train
    self.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 181, in after_step
    h.after_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 449, in after_step
    self._do_eval()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/hooks.py", line 422, in _do_eval
    results = self._func()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 460, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 624, in test
    print_csv_format(results_i)
  File "/opt/ml/detection/baseline/detectron2/detectron2/evaluation/testing.py", line 41, in print_csv_format
    wandb.log(eval_dict)
NameError: name 'wandb' is not defined