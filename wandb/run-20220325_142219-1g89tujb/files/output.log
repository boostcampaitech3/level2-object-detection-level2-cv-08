[32m[03/25 14:22:25 d2.engine.defaults]: [39mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[32m[03/25 14:22:25 d2.data.datasets.coco]: [39mLoaded 4280 images in COCO format from ../../dataset/SK_train_annotations.json
[32m[03/25 14:22:25 d2.data.build]: [39mRemoved 0 images with no usable annotations. 4280 images left.
[32m[03/25 14:22:25 d2.data.build]: [39mDistribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
[36m|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
[36m| General trash | 3468         |    Paper    | 5511         | Paper pack | 800          |
[36m|     Metal     | 827          |    Glass    | 900          |  Plastic   | 2591         |
[36m|   Styrofoam   | 1140         | Plastic bag | 4563         |  Battery   | 148          |
[36m|   Clothing    | 416          |             |              |            |              |
[36m|     total     | 20364        |             |              |            |              |
[32m[03/25 14:22:25 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[03/25 14:22:25 d2.data.common]: [39mSerializing 4280 elements to byte tensors and concatenating them all ...
[32m[03/25 14:22:25 d2.data.common]: [39mSerialized dataset takes 1.92 MiB
expected_results:
[]
[32m[03/25 14:22:26 d2.engine.train_loop]: [39mStarting training from iteration 0
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
/opt/ml/detection/baseline/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)
  num_fg = fg_inds.nonzero().numel()
[32m[03/25 14:22:29 d2.utils.events]: [39m eta: 0:56:52  iter: 9  total_loss: 3.64  loss_cls: 2.312  loss_box_reg: 0.4083  loss_rpn_cls: 0.892  loss_rpn_loc: 0.04603  time: 0.2131  data_time: 0.0325  lr: 9.991e-06  max_mem: 2109M
[32m[03/25 14:22:31 d2.utils.events]: [39m eta: 0:57:09  iter: 19  total_loss: 3.226  loss_cls: 2.233  loss_box_reg: 0.4083  loss_rpn_cls: 0.627  loss_rpn_loc: 0.03899  time: 0.2154  data_time: 0.0203  lr: 1.9981e-05  max_mem: 2109M
[32m[03/25 14:22:33 d2.utils.events]: [39m eta: 0:57:13  iter: 29  total_loss: 3.281  loss_cls: 1.852  loss_box_reg: 0.5223  loss_rpn_cls: 0.7682  loss_rpn_loc: 0.04619  time: 0.2170  data_time: 0.0088  lr: 2.9971e-05  max_mem: 2109M
[32m[03/25 14:22:35 d2.utils.events]: [39m eta: 0:57:08  iter: 39  total_loss: 2.7  loss_cls: 1.357  loss_box_reg: 0.6018  loss_rpn_cls: 0.5588  loss_rpn_loc: 0.04961  time: 0.2161  data_time: 0.0086  lr: 3.9961e-05  max_mem: 2109M
[32m[03/25 14:22:37 d2.utils.events]: [39m eta: 0:57:09  iter: 49  total_loss: 2.049  loss_cls: 0.9751  loss_box_reg: 0.6339  loss_rpn_cls: 0.3574  loss_rpn_loc: 0.0302  time: 0.2173  data_time: 0.0091  lr: 4.9951e-05  max_mem: 2109M
[32m[03/25 14:22:40 d2.utils.events]: [39m eta: 0:57:11  iter: 59  total_loss: 1.873  loss_cls: 0.9166  loss_box_reg: 0.7006  loss_rpn_cls: 0.153  loss_rpn_loc: 0.01747  time: 0.2174  data_time: 0.0101  lr: 5.9941e-05  max_mem: 2109M
[32m[03/25 14:22:42 d2.utils.events]: [39m eta: 0:57:12  iter: 69  total_loss: 1.644  loss_cls: 0.7064  loss_box_reg: 0.6212  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.02169  time: 0.2172  data_time: 0.0089  lr: 6.9931e-05  max_mem: 2109M
[32m[03/25 14:22:44 d2.utils.events]: [39m eta: 0:57:11  iter: 79  total_loss: 1.689  loss_cls: 0.7278  loss_box_reg: 0.6914  loss_rpn_cls: 0.1744  loss_rpn_loc: 0.03076  time: 0.2170  data_time: 0.0081  lr: 7.9921e-05  max_mem: 2109M
[32m[03/25 14:22:46 d2.utils.events]: [39m eta: 0:57:21  iter: 89  total_loss: 1.608  loss_cls: 0.7242  loss_box_reg: 0.7056  loss_rpn_cls: 0.09477  loss_rpn_loc: 0.02469  time: 0.2173  data_time: 0.0079  lr: 8.9911e-05  max_mem: 2109M
[32m[03/25 14:22:48 d2.utils.events]: [39m eta: 0:57:22  iter: 99  total_loss: 1.503  loss_cls: 0.7005  loss_box_reg: 0.6872  loss_rpn_cls: 0.05453  loss_rpn_loc: 0.01846  time: 0.2172  data_time: 0.0078  lr: 9.9901e-05  max_mem: 2109M
[32m[03/25 14:22:51 d2.utils.events]: [39m eta: 0:57:22  iter: 109  total_loss: 1.561  loss_cls: 0.7269  loss_box_reg: 0.6872  loss_rpn_cls: 0.08592  loss_rpn_loc: 0.02302  time: 0.2172  data_time: 0.0079  lr: 0.00010989  max_mem: 2109M
[32m[03/25 14:22:53 d2.utils.events]: [39m eta: 0:57:24  iter: 119  total_loss: 1.418  loss_cls: 0.6579  loss_box_reg: 0.659  loss_rpn_cls: 0.09692  loss_rpn_loc: 0.02302  time: 0.2177  data_time: 0.0094  lr: 0.00011988  max_mem: 2109M
[32m[03/25 14:22:55 d2.utils.events]: [39m eta: 0:57:28  iter: 129  total_loss: 1.451  loss_cls: 0.6488  loss_box_reg: 0.6135  loss_rpn_cls: 0.117  loss_rpn_loc: 0.04325  time: 0.2180  data_time: 0.0098  lr: 0.00012987  max_mem: 2109M
[32m[03/25 14:22:57 d2.utils.events]: [39m eta: 0:57:27  iter: 139  total_loss: 1.664  loss_cls: 0.7217  loss_box_reg: 0.6326  loss_rpn_cls: 0.162  loss_rpn_loc: 0.04685  time: 0.2186  data_time: 0.0090  lr: 0.00013986  max_mem: 2109M
[32m[03/25 14:22:59 d2.utils.events]: [39m eta: 0:57:24  iter: 149  total_loss: 1.714  loss_cls: 0.7025  loss_box_reg: 0.745  loss_rpn_cls: 0.1123  loss_rpn_loc: 0.03856  time: 0.2183  data_time: 0.0089  lr: 0.00014985  max_mem: 2109M
[32m[03/25 14:23:02 d2.utils.events]: [39m eta: 0:57:22  iter: 159  total_loss: 1.549  loss_cls: 0.6763  loss_box_reg: 0.729  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.0552  time: 0.2182  data_time: 0.0091  lr: 0.00015984  max_mem: 2109M
[32m[03/25 14:23:04 d2.utils.events]: [39m eta: 0:57:20  iter: 169  total_loss: 1.565  loss_cls: 0.6829  loss_box_reg: 0.6995  loss_rpn_cls: 0.1711  loss_rpn_loc: 0.06313  time: 0.2185  data_time: 0.0096  lr: 0.00016983  max_mem: 2109M
[32m[03/25 14:23:06 d2.utils.events]: [39m eta: 0:57:14  iter: 179  total_loss: 1.512  loss_cls: 0.704  loss_box_reg: 0.7232  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.03111  time: 0.2183  data_time: 0.0088  lr: 0.00017982  max_mem: 2109M
[32m[03/25 14:23:08 d2.utils.events]: [39m eta: 0:57:09  iter: 189  total_loss: 1.512  loss_cls: 0.7028  loss_box_reg: 0.7422  loss_rpn_cls: 0.09658  loss_rpn_loc: 0.02027  time: 0.2180  data_time: 0.0079  lr: 0.00018981  max_mem: 2109M
[32m[03/25 14:23:10 d2.utils.events]: [39m eta: 0:57:04  iter: 199  total_loss: 1.603  loss_cls: 0.7094  loss_box_reg: 0.7422  loss_rpn_cls: 0.09128  loss_rpn_loc: 0.02502  time: 0.2178  data_time: 0.0078  lr: 0.0001998  max_mem: 2109M
[32m[03/25 14:23:12 d2.utils.events]: [39m eta: 0:56:59  iter: 209  total_loss: 1.548  loss_cls: 0.6551  loss_box_reg: 0.6743  loss_rpn_cls: 0.09945  loss_rpn_loc: 0.02878  time: 0.2177  data_time: 0.0078  lr: 0.00020979  max_mem: 2109M
[32m[03/25 14:23:15 d2.utils.events]: [39m eta: 0:56:56  iter: 219  total_loss: 1.496  loss_cls: 0.6489  loss_box_reg: 0.6664  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.03182  time: 0.2176  data_time: 0.0084  lr: 0.00021978  max_mem: 2109M
[32m[03/25 14:23:17 d2.utils.events]: [39m eta: 0:56:55  iter: 229  total_loss: 1.671  loss_cls: 0.7294  loss_box_reg: 0.7768  loss_rpn_cls: 0.101  loss_rpn_loc: 0.04094  time: 0.2180  data_time: 0.0092  lr: 0.00022977  max_mem: 2109M
[32m[03/25 14:23:19 d2.utils.events]: [39m eta: 0:56:53  iter: 239  total_loss: 1.628  loss_cls: 0.7104  loss_box_reg: 0.7603  loss_rpn_cls: 0.08835  loss_rpn_loc: 0.03966  time: 0.2180  data_time: 0.0100  lr: 0.00023976  max_mem: 2109M
[32m[03/25 14:23:21 d2.utils.events]: [39m eta: 0:56:53  iter: 249  total_loss: 1.487  loss_cls: 0.6617  loss_box_reg: 0.7141  loss_rpn_cls: 0.07923  loss_rpn_loc: 0.03108  time: 0.2183  data_time: 0.0095  lr: 0.00024975  max_mem: 2109M
[32m[03/25 14:23:24 d2.utils.events]: [39m eta: 0:56:49  iter: 259  total_loss: 1.51  loss_cls: 0.6653  loss_box_reg: 0.7252  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.03505  time: 0.2182  data_time: 0.0083  lr: 0.00025974  max_mem: 2109M
[32m[03/25 14:23:26 d2.utils.events]: [39m eta: 0:56:44  iter: 269  total_loss: 1.495  loss_cls: 0.622  loss_box_reg: 0.7325  loss_rpn_cls: 0.09139  loss_rpn_loc: 0.03562  time: 0.2181  data_time: 0.0082  lr: 0.00026973  max_mem: 2109M
[32m[03/25 14:23:28 d2.utils.events]: [39m eta: 0:56:41  iter: 279  total_loss: 1.527  loss_cls: 0.6257  loss_box_reg: 0.6804  loss_rpn_cls: 0.1152  loss_rpn_loc: 0.05881  time: 0.2180  data_time: 0.0087  lr: 0.00027972  max_mem: 2109M
[32m[03/25 14:23:30 d2.utils.events]: [39m eta: 0:56:37  iter: 289  total_loss: 1.522  loss_cls: 0.6662  loss_box_reg: 0.6582  loss_rpn_cls: 0.1487  loss_rpn_loc: 0.05789  time: 0.2179  data_time: 0.0087  lr: 0.00028971  max_mem: 2109M
[32m[03/25 14:23:32 d2.utils.events]: [39m eta: 0:56:32  iter: 299  total_loss: 1.435  loss_cls: 0.6261  loss_box_reg: 0.6707  loss_rpn_cls: 0.08973  loss_rpn_loc: 0.02069  time: 0.2177  data_time: 0.0080  lr: 0.0002997  max_mem: 2109M
[32m[03/25 14:23:34 d2.utils.events]: [39m eta: 0:56:27  iter: 309  total_loss: 1.487  loss_cls: 0.6229  loss_box_reg: 0.7042  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.04313  time: 0.2176  data_time: 0.0078  lr: 0.00030969  max_mem: 2109M
[32m[03/25 14:23:36 d2.utils.events]: [39m eta: 0:56:23  iter: 319  total_loss: 1.471  loss_cls: 0.6091  loss_box_reg: 0.7042  loss_rpn_cls: 0.09268  loss_rpn_loc: 0.03534  time: 0.2175  data_time: 0.0083  lr: 0.00031968  max_mem: 2109M
[32m[03/25 14:23:39 d2.utils.events]: [39m eta: 0:56:19  iter: 329  total_loss: 1.471  loss_cls: 0.5982  loss_box_reg: 0.7042  loss_rpn_cls: 0.09268  loss_rpn_loc: 0.03458  time: 0.2174  data_time: 0.0083  lr: 0.00032967  max_mem: 2109M
[32m[03/25 14:23:41 d2.utils.events]: [39m eta: 0:56:15  iter: 339  total_loss: 1.575  loss_cls: 0.6755  loss_box_reg: 0.6869  loss_rpn_cls: 0.1218  loss_rpn_loc: 0.04151  time: 0.2172  data_time: 0.0078  lr: 0.00033966  max_mem: 2109M
[32m[03/25 14:23:43 d2.utils.events]: [39m eta: 0:56:11  iter: 349  total_loss: 1.564  loss_cls: 0.6689  loss_box_reg: 0.6768  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.03558  time: 0.2171  data_time: 0.0078  lr: 0.00034965  max_mem: 2109M
[32m[03/25 14:23:45 d2.utils.events]: [39m eta: 0:56:07  iter: 359  total_loss: 1.56  loss_cls: 0.6829  loss_box_reg: 0.6755  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.03964  time: 0.2170  data_time: 0.0077  lr: 0.00035964  max_mem: 2109M
[32m[03/25 14:23:47 d2.utils.events]: [39m eta: 0:56:04  iter: 369  total_loss: 1.485  loss_cls: 0.6672  loss_box_reg: 0.6755  loss_rpn_cls: 0.09634  loss_rpn_loc: 0.04129  time: 0.2169  data_time: 0.0080  lr: 0.00036963  max_mem: 2109M
[32m[03/25 14:23:49 d2.utils.events]: [39m eta: 0:56:02  iter: 379  total_loss: 1.358  loss_cls: 0.6102  loss_box_reg: 0.6235  loss_rpn_cls: 0.0925  loss_rpn_loc: 0.03513  time: 0.2169  data_time: 0.0083  lr: 0.00037962  max_mem: 2109M
[32m[03/25 14:23:52 d2.utils.events]: [39m eta: 0:56:01  iter: 389  total_loss: 1.348  loss_cls: 0.6109  loss_box_reg: 0.6277  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.03961  time: 0.2169  data_time: 0.0082  lr: 0.00038961  max_mem: 2109M
[32m[03/25 14:23:54 d2.utils.events]: [39m eta: 0:55:58  iter: 399  total_loss: 1.467  loss_cls: 0.6298  loss_box_reg: 0.6488  loss_rpn_cls: 0.125  loss_rpn_loc: 0.04256  time: 0.2169  data_time: 0.0080  lr: 0.0003996  max_mem: 2109M
[32m[03/25 14:23:56 d2.utils.events]: [39m eta: 0:55:55  iter: 409  total_loss: 1.351  loss_cls: 0.594  loss_box_reg: 0.6189  loss_rpn_cls: 0.08199  loss_rpn_loc: 0.0343  time: 0.2168  data_time: 0.0077  lr: 0.00040959  max_mem: 2109M
[32m[03/25 14:23:58 d2.utils.events]: [39m eta: 0:55:52  iter: 419  total_loss: 1.275  loss_cls: 0.5814  loss_box_reg: 0.5832  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.02867  time: 0.2168  data_time: 0.0076  lr: 0.00041958  max_mem: 2109M
[32m[03/25 14:24:00 d2.utils.events]: [39m eta: 0:55:49  iter: 429  total_loss: 1.31  loss_cls: 0.6146  loss_box_reg: 0.536  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.0256  time: 0.2167  data_time: 0.0076  lr: 0.00042957  max_mem: 2109M
[32m[03/25 14:24:02 d2.utils.events]: [39m eta: 0:55:46  iter: 439  total_loss: 1.158  loss_cls: 0.5855  loss_box_reg: 0.4642  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.02536  time: 0.2166  data_time: 0.0077  lr: 0.00043956  max_mem: 2109M
[32m[03/25 14:24:05 d2.utils.events]: [39m eta: 0:55:43  iter: 449  total_loss: 1.158  loss_cls: 0.5816  loss_box_reg: 0.4588  loss_rpn_cls: 0.08572  loss_rpn_loc: 0.03735  time: 0.2166  data_time: 0.0078  lr: 0.00044955  max_mem: 2109M
[32m[03/25 14:24:07 d2.utils.events]: [39m eta: 0:55:41  iter: 459  total_loss: 1.329  loss_cls: 0.5923  loss_box_reg: 0.5022  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.03757  time: 0.2166  data_time: 0.0080  lr: 0.00045954  max_mem: 2109M
[32m[03/25 14:24:09 d2.utils.events]: [39m eta: 0:55:39  iter: 469  total_loss: 1.09  loss_cls: 0.5586  loss_box_reg: 0.4516  loss_rpn_cls: 0.07524  loss_rpn_loc: 0.02762  time: 0.2167  data_time: 0.0079  lr: 0.00046953  max_mem: 2109M
[32m[03/25 14:24:11 d2.utils.events]: [39m eta: 0:55:36  iter: 479  total_loss: 1.202  loss_cls: 0.5652  loss_box_reg: 0.4868  loss_rpn_cls: 0.07974  loss_rpn_loc: 0.02599  time: 0.2166  data_time: 0.0079  lr: 0.00047952  max_mem: 2109M
[32m[03/25 14:24:13 d2.utils.events]: [39m eta: 0:55:33  iter: 489  total_loss: 1.316  loss_cls: 0.5977  loss_box_reg: 0.5158  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.04158  time: 0.2166  data_time: 0.0082  lr: 0.00048951  max_mem: 2109M
[32m[03/25 14:24:15 d2.utils.events]: [39m eta: 0:55:32  iter: 499  total_loss: 1.192  loss_cls: 0.5832  loss_box_reg: 0.4606  loss_rpn_cls: 0.08429  loss_rpn_loc: 0.02986  time: 0.2166  data_time: 0.0084  lr: 0.0004995  max_mem: 2109M
[32m[03/25 14:24:18 d2.utils.events]: [39m eta: 0:55:29  iter: 509  total_loss: 1.082  loss_cls: 0.5762  loss_box_reg: 0.4293  loss_rpn_cls: 0.0527  loss_rpn_loc: 0.02041  time: 0.2166  data_time: 0.0083  lr: 0.00050949  max_mem: 2109M
[32m[03/25 14:24:20 d2.utils.events]: [39m eta: 0:55:27  iter: 519  total_loss: 1.164  loss_cls: 0.5841  loss_box_reg: 0.4324  loss_rpn_cls: 0.07577  loss_rpn_loc: 0.02997  time: 0.2165  data_time: 0.0082  lr: 0.00051948  max_mem: 2109M
[32m[03/25 14:24:22 d2.utils.events]: [39m eta: 0:55:25  iter: 529  total_loss: 1.195  loss_cls: 0.5999  loss_box_reg: 0.4709  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.03185  time: 0.2167  data_time: 0.0084  lr: 0.00052947  max_mem: 2109M
[32m[03/25 14:24:24 d2.utils.events]: [39m eta: 0:55:23  iter: 539  total_loss: 1.25  loss_cls: 0.5939  loss_box_reg: 0.4912  loss_rpn_cls: 0.08932  loss_rpn_loc: 0.02084  time: 0.2169  data_time: 0.0093  lr: 0.00053946  max_mem: 2109M
[32m[03/25 14:24:27 d2.utils.events]: [39m eta: 0:55:22  iter: 549  total_loss: 1.242  loss_cls: 0.6122  loss_box_reg: 0.4666  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.0292  time: 0.2171  data_time: 0.0093  lr: 0.00054945  max_mem: 2109M
[32m[03/25 14:24:29 d2.utils.events]: [39m eta: 0:55:21  iter: 559  total_loss: 1.112  loss_cls: 0.583  loss_box_reg: 0.3983  loss_rpn_cls: 0.09601  loss_rpn_loc: 0.02712  time: 0.2174  data_time: 0.0088  lr: 0.00055944  max_mem: 2109M
[32m[03/25 14:24:31 d2.utils.events]: [39m eta: 0:55:19  iter: 569  total_loss: 1.193  loss_cls: 0.5633  loss_box_reg: 0.4089  loss_rpn_cls: 0.09091  loss_rpn_loc: 0.03101  time: 0.2176  data_time: 0.0091  lr: 0.00056943  max_mem: 2109M
[32m[03/25 14:24:34 d2.utils.events]: [39m eta: 0:55:18  iter: 579  total_loss: 1.261  loss_cls: 0.5924  loss_box_reg: 0.5163  loss_rpn_cls: 0.09102  loss_rpn_loc: 0.03798  time: 0.2177  data_time: 0.0088  lr: 0.00057942  max_mem: 2109M
[32m[03/25 14:24:36 d2.utils.events]: [39m eta: 0:55:17  iter: 589  total_loss: 1.332  loss_cls: 0.6351  loss_box_reg: 0.488  loss_rpn_cls: 0.09792  loss_rpn_loc: 0.04946  time: 0.2181  data_time: 0.0097  lr: 0.00058941  max_mem: 2109M
[32m[03/25 14:24:38 d2.utils.events]: [39m eta: 0:55:15  iter: 599  total_loss: 1.175  loss_cls: 0.6014  loss_box_reg: 0.4254  loss_rpn_cls: 0.08257  loss_rpn_loc: 0.01873  time: 0.2180  data_time: 0.0100  lr: 0.0005994  max_mem: 2109M
[32m[03/25 14:24:41 d2.utils.events]: [39m eta: 0:55:12  iter: 609  total_loss: 1.181  loss_cls: 0.6014  loss_box_reg: 0.4436  loss_rpn_cls: 0.08952  loss_rpn_loc: 0.02465  time: 0.2180  data_time: 0.0092  lr: 0.00060939  max_mem: 2109M
[32m[03/25 14:24:43 d2.utils.events]: [39m eta: 0:55:09  iter: 619  total_loss: 1.214  loss_cls: 0.5885  loss_box_reg: 0.4655  loss_rpn_cls: 0.09327  loss_rpn_loc: 0.0314  time: 0.2179  data_time: 0.0085  lr: 0.00061938  max_mem: 2109M
[32m[03/25 14:24:45 d2.utils.events]: [39m eta: 0:55:07  iter: 629  total_loss: 1.26  loss_cls: 0.5829  loss_box_reg: 0.4683  loss_rpn_cls: 0.09731  loss_rpn_loc: 0.03748  time: 0.2179  data_time: 0.0079  lr: 0.00062937  max_mem: 2109M
[32m[03/25 14:24:47 d2.utils.events]: [39m eta: 0:55:04  iter: 639  total_loss: 1.13  loss_cls: 0.6106  loss_box_reg: 0.4405  loss_rpn_cls: 0.09461  loss_rpn_loc: 0.03353  time: 0.2178  data_time: 0.0079  lr: 0.00063936  max_mem: 2109M
[32m[03/25 14:24:49 d2.utils.events]: [39m eta: 0:55:01  iter: 649  total_loss: 1.098  loss_cls: 0.5902  loss_box_reg: 0.4037  loss_rpn_cls: 0.08955  loss_rpn_loc: 0.02361  time: 0.2177  data_time: 0.0079  lr: 0.00064935  max_mem: 2109M
[32m[03/25 14:24:51 d2.utils.events]: [39m eta: 0:54:58  iter: 659  total_loss: 1.072  loss_cls: 0.5874  loss_box_reg: 0.4172  loss_rpn_cls: 0.06379  loss_rpn_loc: 0.02442  time: 0.2176  data_time: 0.0081  lr: 0.00065934  max_mem: 2109M
[32m[03/25 14:24:53 d2.utils.events]: [39m eta: 0:54:56  iter: 669  total_loss: 1.029  loss_cls: 0.5607  loss_box_reg: 0.395  loss_rpn_cls: 0.06595  loss_rpn_loc: 0.01723  time: 0.2176  data_time: 0.0086  lr: 0.00066933  max_mem: 2109M
[32m[03/25 14:24:56 d2.utils.events]: [39m eta: 0:54:53  iter: 679  total_loss: 1.066  loss_cls: 0.5423  loss_box_reg: 0.4031  loss_rpn_cls: 0.09021  loss_rpn_loc: 0.02477  time: 0.2175  data_time: 0.0085  lr: 0.00067932  max_mem: 2109M
[32m[03/25 14:24:58 d2.utils.events]: [39m eta: 0:54:51  iter: 689  total_loss: 1.182  loss_cls: 0.5804  loss_box_reg: 0.4349  loss_rpn_cls: 0.09627  loss_rpn_loc: 0.04024  time: 0.2175  data_time: 0.0089  lr: 0.00068931  max_mem: 2109M
[32m[03/25 14:25:00 d2.utils.events]: [39m eta: 0:54:50  iter: 699  total_loss: 1.167  loss_cls: 0.5867  loss_box_reg: 0.4376  loss_rpn_cls: 0.09794  loss_rpn_loc: 0.04082  time: 0.2176  data_time: 0.0106  lr: 0.0006993  max_mem: 2109M
[32m[03/25 14:25:02 d2.utils.events]: [39m eta: 0:54:49  iter: 709  total_loss: 1.13  loss_cls: 0.5825  loss_box_reg: 0.4135  loss_rpn_cls: 0.08948  loss_rpn_loc: 0.03299  time: 0.2176  data_time: 0.0100  lr: 0.00070929  max_mem: 2109M
[32m[03/25 14:25:04 d2.utils.events]: [39m eta: 0:54:47  iter: 719  total_loss: 1.13  loss_cls: 0.5631  loss_box_reg: 0.4301  loss_rpn_cls: 0.05954  loss_rpn_loc: 0.0233  time: 0.2176  data_time: 0.0081  lr: 0.00071928  max_mem: 2109M
[32m[03/25 14:25:07 d2.utils.events]: [39m eta: 0:54:45  iter: 729  total_loss: 1.181  loss_cls: 0.5631  loss_box_reg: 0.4294  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.02711  time: 0.2176  data_time: 0.0080  lr: 0.00072927  max_mem: 2109M
[32m[03/25 14:25:09 d2.utils.events]: [39m eta: 0:54:43  iter: 739  total_loss: 1.075  loss_cls: 0.5385  loss_box_reg: 0.3721  loss_rpn_cls: 0.06578  loss_rpn_loc: 0.03089  time: 0.2176  data_time: 0.0079  lr: 0.00073926  max_mem: 2109M
[32m[03/25 14:25:11 d2.utils.events]: [39m eta: 0:54:42  iter: 749  total_loss: 0.929  loss_cls: 0.5231  loss_box_reg: 0.3403  loss_rpn_cls: 0.04903  loss_rpn_loc: 0.01348  time: 0.2176  data_time: 0.0091  lr: 0.00074925  max_mem: 2109M
[32m[03/25 14:25:13 d2.utils.events]: [39m eta: 0:54:39  iter: 759  total_loss: 1.057  loss_cls: 0.5393  loss_box_reg: 0.393  loss_rpn_cls: 0.05317  loss_rpn_loc: 0.01732  time: 0.2177  data_time: 0.0111  lr: 0.00075924  max_mem: 2109M
[32m[03/25 14:25:15 d2.utils.events]: [39m eta: 0:54:37  iter: 769  total_loss: 1.206  loss_cls: 0.6187  loss_box_reg: 0.459  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.02762  time: 0.2177  data_time: 0.0106  lr: 0.00076923  max_mem: 2109M
[32m[03/25 14:25:18 d2.utils.events]: [39m eta: 0:54:35  iter: 779  total_loss: 1.068  loss_cls: 0.5582  loss_box_reg: 0.3966  loss_rpn_cls: 0.08353  loss_rpn_loc: 0.0304  time: 0.2177  data_time: 0.0088  lr: 0.00077922  max_mem: 2109M
[32m[03/25 14:25:20 d2.utils.events]: [39m eta: 0:54:33  iter: 789  total_loss: 1.067  loss_cls: 0.5342  loss_box_reg: 0.4  loss_rpn_cls: 0.08774  loss_rpn_loc: 0.0304  time: 0.2177  data_time: 0.0090  lr: 0.00078921  max_mem: 2109M
[32m[03/25 14:25:22 d2.utils.events]: [39m eta: 0:54:31  iter: 799  total_loss: 1.145  loss_cls: 0.5606  loss_box_reg: 0.4469  loss_rpn_cls: 0.08521  loss_rpn_loc: 0.02927  time: 0.2177  data_time: 0.0088  lr: 0.0007992  max_mem: 2109M
[32m[03/25 14:25:24 d2.utils.events]: [39m eta: 0:54:29  iter: 809  total_loss: 1.2  loss_cls: 0.6371  loss_box_reg: 0.478  loss_rpn_cls: 0.07314  loss_rpn_loc: 0.02927  time: 0.2178  data_time: 0.0083  lr: 0.00080919  max_mem: 2109M
[32m[03/25 14:25:26 d2.utils.events]: [39m eta: 0:54:27  iter: 819  total_loss: 1.156  loss_cls: 0.5865  loss_box_reg: 0.4627  loss_rpn_cls: 0.09126  loss_rpn_loc: 0.03045  time: 0.2178  data_time: 0.0082  lr: 0.00081918  max_mem: 2109M
[32m[03/25 14:25:29 d2.utils.events]: [39m eta: 0:54:25  iter: 829  total_loss: 1.069  loss_cls: 0.5786  loss_box_reg: 0.4298  loss_rpn_cls: 0.09126  loss_rpn_loc: 0.0315  time: 0.2178  data_time: 0.0079  lr: 0.00082917  max_mem: 2109M
[32m[03/25 14:25:31 d2.utils.events]: [39m eta: 0:54:23  iter: 839  total_loss: 1.029  loss_cls: 0.5454  loss_box_reg: 0.4132  loss_rpn_cls: 0.06054  loss_rpn_loc: 0.02741  time: 0.2178  data_time: 0.0082  lr: 0.00083916  max_mem: 2109M
[32m[03/25 14:25:33 d2.utils.events]: [39m eta: 0:54:22  iter: 849  total_loss: 0.9921  loss_cls: 0.5262  loss_box_reg: 0.3884  loss_rpn_cls: 0.05405  loss_rpn_loc: 0.01747  time: 0.2178  data_time: 0.0105  lr: 0.00084915  max_mem: 2109M
[32m[03/25 14:25:35 d2.utils.events]: [39m eta: 0:54:20  iter: 859  total_loss: 0.9611  loss_cls: 0.5218  loss_box_reg: 0.327  loss_rpn_cls: 0.05378  loss_rpn_loc: 0.01535  time: 0.2178  data_time: 0.0112  lr: 0.00085914  max_mem: 2109M
[32m[03/25 14:25:37 d2.utils.events]: [39m eta: 0:54:17  iter: 869  total_loss: 0.956  loss_cls: 0.5265  loss_box_reg: 0.3358  loss_rpn_cls: 0.05512  loss_rpn_loc: 0.02042  time: 0.2178  data_time: 0.0090  lr: 0.00086913  max_mem: 2109M
[32m[03/25 14:25:40 d2.utils.events]: [39m eta: 0:54:16  iter: 879  total_loss: 1.017  loss_cls: 0.5201  loss_box_reg: 0.3407  loss_rpn_cls: 0.07022  loss_rpn_loc: 0.03383  time: 0.2178  data_time: 0.0081  lr: 0.00087912  max_mem: 2109M
[32m[03/25 14:25:42 d2.utils.events]: [39m eta: 0:54:15  iter: 889  total_loss: 1.125  loss_cls: 0.5479  loss_box_reg: 0.3443  loss_rpn_cls: 0.07022  loss_rpn_loc: 0.03389  time: 0.2179  data_time: 0.0084  lr: 0.00088911  max_mem: 2109M
[32m[03/25 14:25:44 d2.utils.events]: [39m eta: 0:54:13  iter: 899  total_loss: 1.163  loss_cls: 0.5974  loss_box_reg: 0.4601  loss_rpn_cls: 0.08147  loss_rpn_loc: 0.02832  time: 0.2180  data_time: 0.0098  lr: 0.0008991  max_mem: 2109M
[32m[03/25 14:25:46 d2.utils.events]: [39m eta: 0:54:13  iter: 909  total_loss: 1.258  loss_cls: 0.5974  loss_box_reg: 0.4208  loss_rpn_cls: 0.123  loss_rpn_loc: 0.0528  time: 0.2180  data_time: 0.0099  lr: 0.00090909  max_mem: 2109M
[32m[03/25 14:25:48 d2.utils.events]: [39m eta: 0:54:11  iter: 919  total_loss: 1.163  loss_cls: 0.5623  loss_box_reg: 0.3965  loss_rpn_cls: 0.09478  loss_rpn_loc: 0.04744  time: 0.2180  data_time: 0.0090  lr: 0.00091908  max_mem: 2109M
[32m[03/25 14:25:51 d2.utils.events]: [39m eta: 0:54:09  iter: 929  total_loss: 1.043  loss_cls: 0.563  loss_box_reg: 0.3688  loss_rpn_cls: 0.0623  loss_rpn_loc: 0.01642  time: 0.2181  data_time: 0.0087  lr: 0.00092907  max_mem: 2109M
[32m[03/25 14:25:53 d2.utils.events]: [39m eta: 0:54:07  iter: 939  total_loss: 1.031  loss_cls: 0.5426  loss_box_reg: 0.3504  loss_rpn_cls: 0.09581  loss_rpn_loc: 0.03067  time: 0.2181  data_time: 0.0088  lr: 0.00093906  max_mem: 2109M
[32m[03/25 14:25:55 d2.utils.events]: [39m eta: 0:54:06  iter: 949  total_loss: 0.9367  loss_cls: 0.5029  loss_box_reg: 0.3136  loss_rpn_cls: 0.09394  loss_rpn_loc: 0.03377  time: 0.2181  data_time: 0.0086  lr: 0.00094905  max_mem: 2109M
[32m[03/25 14:25:57 d2.utils.events]: [39m eta: 0:54:04  iter: 959  total_loss: 0.9652  loss_cls: 0.5539  loss_box_reg: 0.3858  loss_rpn_cls: 0.04568  loss_rpn_loc: 0.02086  time: 0.2182  data_time: 0.0083  lr: 0.00095904  max_mem: 2109M
[32m[03/25 14:26:00 d2.utils.events]: [39m eta: 0:54:03  iter: 969  total_loss: 1.135  loss_cls: 0.5979  loss_box_reg: 0.3989  loss_rpn_cls: 0.06392  loss_rpn_loc: 0.02978  time: 0.2183  data_time: 0.0086  lr: 0.00096903  max_mem: 2109M
[32m[03/25 14:26:02 d2.utils.events]: [39m eta: 0:54:02  iter: 979  total_loss: 1.047  loss_cls: 0.5192  loss_box_reg: 0.3827  loss_rpn_cls: 0.06227  loss_rpn_loc: 0.02713  time: 0.2183  data_time: 0.0088  lr: 0.00097902  max_mem: 2109M
[32m[03/25 14:26:04 d2.utils.events]: [39m eta: 0:54:00  iter: 989  total_loss: 1.007  loss_cls: 0.5339  loss_box_reg: 0.3822  loss_rpn_cls: 0.06575  loss_rpn_loc: 0.02118  time: 0.2185  data_time: 0.0097  lr: 0.00098901  max_mem: 2109M
[32m[03/25 14:26:06 d2.utils.events]: [39m eta: 0:53:58  iter: 999  total_loss: 1.138  loss_cls: 0.5994  loss_box_reg: 0.4106  loss_rpn_cls: 0.07957  loss_rpn_loc: 0.03984  time: 0.2184  data_time: 0.0096  lr: 0.000999  max_mem: 2109M
[32m[03/25 14:26:09 d2.utils.events]: [39m eta: 0:53:56  iter: 1009  total_loss: 1.157  loss_cls: 0.5881  loss_box_reg: 0.4305  loss_rpn_cls: 0.08817  loss_rpn_loc: 0.03912  time: 0.2184  data_time: 0.0087  lr: 0.001  max_mem: 2109M
[32m[03/25 14:26:11 d2.utils.events]: [39m eta: 0:53:55  iter: 1019  total_loss: 1.14  loss_cls: 0.5658  loss_box_reg: 0.4379  loss_rpn_cls: 0.09881  loss_rpn_loc: 0.04867  time: 0.2184  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:26:13 d2.utils.events]: [39m eta: 0:53:54  iter: 1029  total_loss: 1.197  loss_cls: 0.6361  loss_box_reg: 0.4101  loss_rpn_cls: 0.09744  loss_rpn_loc: 0.05851  time: 0.2184  data_time: 0.0084  lr: 0.001  max_mem: 2109M
[32m[03/25 14:26:15 d2.utils.events]: [39m eta: 0:53:54  iter: 1039  total_loss: 1.107  loss_cls: 0.5708  loss_box_reg: 0.3985  loss_rpn_cls: 0.08784  loss_rpn_loc: 0.03991  time: 0.2184  data_time: 0.0084  lr: 0.001  max_mem: 2109M
[32m[03/25 14:26:17 d2.utils.events]: [39m eta: 0:53:52  iter: 1049  total_loss: 1.056  loss_cls: 0.4954  loss_box_reg: 0.4011  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.04513  time: 0.2184  data_time: 0.0082  lr: 0.001  max_mem: 2109M
[32m[03/25 14:26:20 d2.utils.events]: [39m eta: 0:53:49  iter: 1059  total_loss: 1.023  loss_cls: 0.5399  loss_box_reg: 0.4069  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.0324  time: 0.2183  data_time: 0.0079  lr: 0.001  max_mem: 2109M
[32m[03/25 14:26:23 d2.data.datasets.coco]: [39mLoaded 603 images in COCO format from ../../dataset/SK_val_annotations.json
[32m[03/25 14:26:23 d2.data.build]: [39mDistribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
[36m|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
[36m| General trash | 498          |    Paper    | 841          | Paper pack | 97           |
[36m|     Metal     | 109          |    Glass    | 82           |  Plastic   | 352          |
[36m|   Styrofoam   | 123          | Plastic bag | 615          |  Battery   | 11           |
[36m|   Clothing    | 52           |             |              |            |              |
[36m|     total     | 2780         |             |              |            |              |
[32m[03/25 14:26:23 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/25 14:26:23 d2.data.common]: [39mSerializing 603 elements to byte tensors and concatenating them all ...
[32m[03/25 14:26:23 d2.data.common]: [39mSerialized dataset takes 0.27 MiB
[31m[5mWARNING[39m[25m [32m[03/25 14:26:23 d2.evaluation.coco_evaluation]: [39mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[03/25 14:26:23 d2.evaluation.evaluator]: [39mStart inference on 603 batches
[32m[03/25 14:26:24 d2.evaluation.evaluator]: [39mInference done 11/603. Dataloading: 0.0007 s/iter. Inference: 0.0471 s/iter. Eval: 0.0006 s/iter. Total: 0.0484 s/iter. ETA=0:00:28
[32m[03/25 14:26:29 d2.evaluation.evaluator]: [39mInference done 113/603. Dataloading: 0.0013 s/iter. Inference: 0.0474 s/iter. Eval: 0.0004 s/iter. Total: 0.0491 s/iter. ETA=0:00:24
[32m[03/25 14:26:34 d2.evaluation.evaluator]: [39mInference done 215/603. Dataloading: 0.0013 s/iter. Inference: 0.0476 s/iter. Eval: 0.0004 s/iter. Total: 0.0493 s/iter. ETA=0:00:19
[32m[03/25 14:26:39 d2.evaluation.evaluator]: [39mInference done 314/603. Dataloading: 0.0013 s/iter. Inference: 0.0476 s/iter. Eval: 0.0007 s/iter. Total: 0.0497 s/iter. ETA=0:00:14
[32m[03/25 14:26:44 d2.evaluation.evaluator]: [39mInference done 416/603. Dataloading: 0.0013 s/iter. Inference: 0.0476 s/iter. Eval: 0.0006 s/iter. Total: 0.0496 s/iter. ETA=0:00:09
[32m[03/25 14:26:49 d2.evaluation.evaluator]: [39mInference done 523/603. Dataloading: 0.0012 s/iter. Inference: 0.0472 s/iter. Eval: 0.0006 s/iter. Total: 0.0491 s/iter. ETA=0:00:03
[32m[03/25 14:26:53 d2.evaluation.evaluator]: [39mTotal inference time: 0:00:29.502190 (0.049335 s / iter per device, on 1 devices)
[32m[03/25 14:26:53 d2.evaluation.evaluator]: [39mTotal inference pure compute time: 0:00:28 (0.047419 s / iter per device, on 1 devices)
[32m[03/25 14:26:54 d2.evaluation.coco_evaluation]: [39mPreparing results for COCO format ...
[32m[03/25 14:26:54 d2.evaluation.coco_evaluation]: [39mSaving results to ./output_eval/coco_instances_results.json
[32m[03/25 14:26:54 d2.evaluation.coco_evaluation]: [39mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
[32m[03/25 14:26:54 d2.evaluation.fast_eval_api]: [39mEvaluate annotation type *bbox*
[32m[03/25 14:26:55 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.evaluate() finished in 0.62 seconds.
[32m[03/25 14:26:55 d2.evaluation.fast_eval_api]: [39mAccumulating evaluation results...
[32m[03/25 14:26:55 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.accumulate() finished in 0.17 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.119
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.076
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.090
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.281
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368
[32m[03/25 14:26:55 d2.evaluation.coco_evaluation]: [39mEvaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 7.159 | 11.919 | 7.573  | 0.002 | 0.631 | 8.994 |
[32m[03/25 14:26:55 d2.evaluation.coco_evaluation]: [39mPer-category bbox AP:
| category      | AP    | category    | AP     | category   | AP     |
|:--------------|:------|:------------|:-------|:-----------|:-------|
| General trash | 4.332 | Paper       | 8.891  | Paper pack | 12.660 |
| Metal         | 6.276 | Glass       | 8.988  | Plastic    | 5.372  |
| Styrofoam     | 6.985 | Plastic bag | 14.678 | Battery    | 0.000  |
| Clothing      | 3.408 |             |        |            |        |
[32m[03/25 14:26:55 d2.engine.defaults]: [39mEvaluation results for coco_trash_test in csv format:
[32m[03/25 14:26:55 d2.evaluation.testing]: [39mcopypaste: Task: bbox
[32m[03/25 14:26:55 d2.evaluation.testing]: [39mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/25 14:26:55 d2.evaluation.testing]: [39mcopypaste: 7.1589,11.9190,7.5733,0.0021,0.6310,8.9936
[32m[03/25 14:26:55 d2.utils.events]: [39m eta: 0:53:47  iter: 1069  total_loss: 0.9201  loss_cls: 0.5304  loss_box_reg: 0.3381  loss_rpn_cls: 0.03888  loss_rpn_loc: 0.01032  time: 0.2184  data_time: 0.0083  lr: 0.001  max_mem: 2109M
[32m[03/25 14:26:57 d2.utils.events]: [39m eta: 0:53:45  iter: 1079  total_loss: 0.9608  loss_cls: 0.5021  loss_box_reg: 0.3653  loss_rpn_cls: 0.06164  loss_rpn_loc: 0.02132  time: 0.2185  data_time: 0.0094  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:00 d2.utils.events]: [39m eta: 0:53:43  iter: 1089  total_loss: 1.106  loss_cls: 0.5471  loss_box_reg: 0.3963  loss_rpn_cls: 0.07807  loss_rpn_loc: 0.02411  time: 0.2186  data_time: 0.0105  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:02 d2.utils.events]: [39m eta: 0:53:41  iter: 1099  total_loss: 1.24  loss_cls: 0.6783  loss_box_reg: 0.4443  loss_rpn_cls: 0.08982  loss_rpn_loc: 0.02325  time: 0.2186  data_time: 0.0100  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:04 d2.utils.events]: [39m eta: 0:53:39  iter: 1109  total_loss: 1.093  loss_cls: 0.5728  loss_box_reg: 0.3764  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.01925  time: 0.2187  data_time: 0.0094  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:06 d2.utils.events]: [39m eta: 0:53:37  iter: 1119  total_loss: 0.9241  loss_cls: 0.5425  loss_box_reg: 0.3343  loss_rpn_cls: 0.04571  loss_rpn_loc: 0.01535  time: 0.2188  data_time: 0.0095  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:09 d2.utils.events]: [39m eta: 0:53:34  iter: 1129  total_loss: 0.9359  loss_cls: 0.5196  loss_box_reg: 0.3427  loss_rpn_cls: 0.0421  loss_rpn_loc: 0.01225  time: 0.2188  data_time: 0.0097  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:11 d2.utils.events]: [39m eta: 0:53:32  iter: 1139  total_loss: 1.066  loss_cls: 0.5196  loss_box_reg: 0.3858  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.01895  time: 0.2188  data_time: 0.0097  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:13 d2.utils.events]: [39m eta: 0:53:30  iter: 1149  total_loss: 1.097  loss_cls: 0.5943  loss_box_reg: 0.4151  loss_rpn_cls: 0.06485  loss_rpn_loc: 0.02719  time: 0.2189  data_time: 0.0091  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:16 d2.utils.events]: [39m eta: 0:53:28  iter: 1159  total_loss: 1.048  loss_cls: 0.5229  loss_box_reg: 0.3886  loss_rpn_cls: 0.05684  loss_rpn_loc: 0.02356  time: 0.2191  data_time: 0.0093  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:18 d2.utils.events]: [39m eta: 0:53:27  iter: 1169  total_loss: 1.096  loss_cls: 0.5549  loss_box_reg: 0.3886  loss_rpn_cls: 0.07948  loss_rpn_loc: 0.03026  time: 0.2191  data_time: 0.0097  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:20 d2.utils.events]: [39m eta: 0:53:26  iter: 1179  total_loss: 1.14  loss_cls: 0.5872  loss_box_reg: 0.4352  loss_rpn_cls: 0.0912  loss_rpn_loc: 0.0431  time: 0.2195  data_time: 0.0112  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:23 d2.utils.events]: [39m eta: 0:53:25  iter: 1189  total_loss: 0.9373  loss_cls: 0.4745  loss_box_reg: 0.3769  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.02756  time: 0.2195  data_time: 0.0109  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:25 d2.utils.events]: [39m eta: 0:53:23  iter: 1199  total_loss: 0.8782  loss_cls: 0.5265  loss_box_reg: 0.3343  loss_rpn_cls: 0.04794  loss_rpn_loc: 0.02516  time: 0.2195  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:27 d2.utils.events]: [39m eta: 0:53:22  iter: 1209  total_loss: 0.926  loss_cls: 0.5244  loss_box_reg: 0.3565  loss_rpn_cls: 0.05058  loss_rpn_loc: 0.02528  time: 0.2195  data_time: 0.0087  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:29 d2.utils.events]: [39m eta: 0:53:20  iter: 1219  total_loss: 0.8782  loss_cls: 0.4843  loss_box_reg: 0.3164  loss_rpn_cls: 0.04355  loss_rpn_loc: 0.01261  time: 0.2196  data_time: 0.0100  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:32 d2.utils.events]: [39m eta: 0:53:17  iter: 1229  total_loss: 1  loss_cls: 0.5176  loss_box_reg: 0.3256  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.0299  time: 0.2196  data_time: 0.0098  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:34 d2.utils.events]: [39m eta: 0:53:15  iter: 1239  total_loss: 1.088  loss_cls: 0.5393  loss_box_reg: 0.3961  loss_rpn_cls: 0.09664  loss_rpn_loc: 0.03997  time: 0.2196  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:36 d2.utils.events]: [39m eta: 0:53:12  iter: 1249  total_loss: 0.9769  loss_cls: 0.5145  loss_box_reg: 0.3625  loss_rpn_cls: 0.09265  loss_rpn_loc: 0.02825  time: 0.2195  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:38 d2.utils.events]: [39m eta: 0:53:09  iter: 1259  total_loss: 0.914  loss_cls: 0.49  loss_box_reg: 0.3227  loss_rpn_cls: 0.05711  loss_rpn_loc: 0.01659  time: 0.2195  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:40 d2.utils.events]: [39m eta: 0:53:08  iter: 1269  total_loss: 1.08  loss_cls: 0.4887  loss_box_reg: 0.3687  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.0302  time: 0.2195  data_time: 0.0087  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:43 d2.utils.events]: [39m eta: 0:53:07  iter: 1279  total_loss: 1.081  loss_cls: 0.5332  loss_box_reg: 0.4152  loss_rpn_cls: 0.09023  loss_rpn_loc: 0.05393  time: 0.2195  data_time: 0.0088  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:45 d2.utils.events]: [39m eta: 0:53:05  iter: 1289  total_loss: 1.046  loss_cls: 0.5278  loss_box_reg: 0.4091  loss_rpn_cls: 0.09325  loss_rpn_loc: 0.06096  time: 0.2195  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:47 d2.utils.events]: [39m eta: 0:53:04  iter: 1299  total_loss: 0.9639  loss_cls: 0.5278  loss_box_reg: 0.3446  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.03841  time: 0.2195  data_time: 0.0094  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:49 d2.utils.events]: [39m eta: 0:53:01  iter: 1309  total_loss: 1.094  loss_cls: 0.5748  loss_box_reg: 0.397  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.03841  time: 0.2195  data_time: 0.0099  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:51 d2.utils.events]: [39m eta: 0:53:00  iter: 1319  total_loss: 1.254  loss_cls: 0.5855  loss_box_reg: 0.4647  loss_rpn_cls: 0.1363  loss_rpn_loc: 0.04484  time: 0.2195  data_time: 0.0090  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:53 d2.utils.events]: [39m eta: 0:52:59  iter: 1329  total_loss: 1.174  loss_cls: 0.5726  loss_box_reg: 0.4517  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.04019  time: 0.2194  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:56 d2.utils.events]: [39m eta: 0:52:59  iter: 1339  total_loss: 1.117  loss_cls: 0.5733  loss_box_reg: 0.4243  loss_rpn_cls: 0.0903  loss_rpn_loc: 0.03942  time: 0.2194  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:27:58 d2.utils.events]: [39m eta: 0:52:58  iter: 1349  total_loss: 0.9902  loss_cls: 0.4987  loss_box_reg: 0.3174  loss_rpn_cls: 0.07739  loss_rpn_loc: 0.03096  time: 0.2195  data_time: 0.0093  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:00 d2.utils.events]: [39m eta: 0:52:58  iter: 1359  total_loss: 0.9255  loss_cls: 0.4862  loss_box_reg: 0.3271  loss_rpn_cls: 0.07591  loss_rpn_loc: 0.0306  time: 0.2195  data_time: 0.0094  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:02 d2.utils.events]: [39m eta: 0:52:56  iter: 1369  total_loss: 1.023  loss_cls: 0.5188  loss_box_reg: 0.3647  loss_rpn_cls: 0.0617  loss_rpn_loc: 0.03154  time: 0.2194  data_time: 0.0083  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:04 d2.utils.events]: [39m eta: 0:52:54  iter: 1379  total_loss: 1.002  loss_cls: 0.5052  loss_box_reg: 0.3808  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.02228  time: 0.2194  data_time: 0.0081  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:07 d2.utils.events]: [39m eta: 0:52:52  iter: 1389  total_loss: 0.9691  loss_cls: 0.5143  loss_box_reg: 0.3745  loss_rpn_cls: 0.06073  loss_rpn_loc: 0.02095  time: 0.2194  data_time: 0.0088  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:09 d2.utils.events]: [39m eta: 0:52:51  iter: 1399  total_loss: 1.021  loss_cls: 0.5144  loss_box_reg: 0.3329  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.03248  time: 0.2195  data_time: 0.0098  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:11 d2.utils.events]: [39m eta: 0:52:49  iter: 1409  total_loss: 0.8912  loss_cls: 0.4881  loss_box_reg: 0.3108  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.02793  time: 0.2195  data_time: 0.0093  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:13 d2.utils.events]: [39m eta: 0:52:47  iter: 1419  total_loss: 0.9185  loss_cls: 0.5369  loss_box_reg: 0.312  loss_rpn_cls: 0.06043  loss_rpn_loc: 0.01703  time: 0.2195  data_time: 0.0092  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:16 d2.utils.events]: [39m eta: 0:52:45  iter: 1429  total_loss: 1.094  loss_cls: 0.5962  loss_box_reg: 0.3779  loss_rpn_cls: 0.05532  loss_rpn_loc: 0.02125  time: 0.2195  data_time: 0.0094  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:18 d2.utils.events]: [39m eta: 0:52:45  iter: 1439  total_loss: 1.18  loss_cls: 0.5952  loss_box_reg: 0.4105  loss_rpn_cls: 0.08495  loss_rpn_loc: 0.03423  time: 0.2195  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:20 d2.utils.events]: [39m eta: 0:52:44  iter: 1449  total_loss: 1.183  loss_cls: 0.5922  loss_box_reg: 0.4402  loss_rpn_cls: 0.09535  loss_rpn_loc: 0.03614  time: 0.2195  data_time: 0.0084  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:22 d2.utils.events]: [39m eta: 0:52:41  iter: 1459  total_loss: 0.9934  loss_cls: 0.5099  loss_box_reg: 0.3536  loss_rpn_cls: 0.08441  loss_rpn_loc: 0.02961  time: 0.2195  data_time: 0.0089  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:24 d2.utils.events]: [39m eta: 0:52:39  iter: 1469  total_loss: 0.9296  loss_cls: 0.4717  loss_box_reg: 0.3637  loss_rpn_cls: 0.08353  loss_rpn_loc: 0.02098  time: 0.2194  data_time: 0.0087  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:27 d2.utils.events]: [39m eta: 0:52:38  iter: 1479  total_loss: 0.9053  loss_cls: 0.4586  loss_box_reg: 0.344  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.01708  time: 0.2194  data_time: 0.0093  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:29 d2.utils.events]: [39m eta: 0:52:37  iter: 1489  total_loss: 1.08  loss_cls: 0.5488  loss_box_reg: 0.3555  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.03279  time: 0.2194  data_time: 0.0108  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:31 d2.utils.events]: [39m eta: 0:52:35  iter: 1499  total_loss: 1.117  loss_cls: 0.5203  loss_box_reg: 0.3791  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.06481  time: 0.2195  data_time: 0.0106  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:33 d2.utils.events]: [39m eta: 0:52:33  iter: 1509  total_loss: 1.033  loss_cls: 0.5047  loss_box_reg: 0.3668  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.03935  time: 0.2195  data_time: 0.0092  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:35 d2.utils.events]: [39m eta: 0:52:31  iter: 1519  total_loss: 1.076  loss_cls: 0.5454  loss_box_reg: 0.3988  loss_rpn_cls: 0.07544  loss_rpn_loc: 0.03483  time: 0.2195  data_time: 0.0083  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:38 d2.utils.events]: [39m eta: 0:52:29  iter: 1529  total_loss: 1.004  loss_cls: 0.5396  loss_box_reg: 0.3644  loss_rpn_cls: 0.07713  loss_rpn_loc: 0.0353  time: 0.2195  data_time: 0.0092  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:40 d2.utils.events]: [39m eta: 0:52:25  iter: 1539  total_loss: 0.9737  loss_cls: 0.53  loss_box_reg: 0.3417  loss_rpn_cls: 0.06432  loss_rpn_loc: 0.02698  time: 0.2194  data_time: 0.0090  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:42 d2.utils.events]: [39m eta: 0:52:22  iter: 1549  total_loss: 0.9816  loss_cls: 0.5659  loss_box_reg: 0.3491  loss_rpn_cls: 0.05317  loss_rpn_loc: 0.02606  time: 0.2194  data_time: 0.0081  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:44 d2.utils.events]: [39m eta: 0:52:17  iter: 1559  total_loss: 1.033  loss_cls: 0.5809  loss_box_reg: 0.3704  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.0354  time: 0.2193  data_time: 0.0081  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:46 d2.utils.events]: [39m eta: 0:52:14  iter: 1569  total_loss: 1.01  loss_cls: 0.5213  loss_box_reg: 0.3763  loss_rpn_cls: 0.07806  loss_rpn_loc: 0.02711  time: 0.2193  data_time: 0.0080  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:48 d2.utils.events]: [39m eta: 0:52:11  iter: 1579  total_loss: 0.8896  loss_cls: 0.4697  loss_box_reg: 0.3238  loss_rpn_cls: 0.08595  loss_rpn_loc: 0.04815  time: 0.2193  data_time: 0.0080  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:50 d2.utils.events]: [39m eta: 0:52:06  iter: 1589  total_loss: 0.9099  loss_cls: 0.4726  loss_box_reg: 0.3544  loss_rpn_cls: 0.08605  loss_rpn_loc: 0.04309  time: 0.2192  data_time: 0.0079  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:53 d2.utils.events]: [39m eta: 0:52:04  iter: 1599  total_loss: 0.9672  loss_cls: 0.5109  loss_box_reg: 0.3299  loss_rpn_cls: 0.05471  loss_rpn_loc: 0.02421  time: 0.2192  data_time: 0.0081  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:55 d2.utils.events]: [39m eta: 0:52:02  iter: 1609  total_loss: 1.01  loss_cls: 0.536  loss_box_reg: 0.3351  loss_rpn_cls: 0.07037  loss_rpn_loc: 0.02421  time: 0.2192  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:57 d2.utils.events]: [39m eta: 0:52:00  iter: 1619  total_loss: 1.025  loss_cls: 0.5337  loss_box_reg: 0.4013  loss_rpn_cls: 0.08532  loss_rpn_loc: 0.02897  time: 0.2192  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:28:59 d2.utils.events]: [39m eta: 0:51:59  iter: 1629  total_loss: 0.9956  loss_cls: 0.5068  loss_box_reg: 0.3686  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.02524  time: 0.2191  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:01 d2.utils.events]: [39m eta: 0:51:57  iter: 1639  total_loss: 0.9711  loss_cls: 0.4777  loss_box_reg: 0.3815  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.02735  time: 0.2191  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:04 d2.utils.events]: [39m eta: 0:51:56  iter: 1649  total_loss: 1.02  loss_cls: 0.4981  loss_box_reg: 0.3947  loss_rpn_cls: 0.07061  loss_rpn_loc: 0.03332  time: 0.2191  data_time: 0.0093  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:06 d2.utils.events]: [39m eta: 0:51:54  iter: 1659  total_loss: 1.02  loss_cls: 0.5381  loss_box_reg: 0.3893  loss_rpn_cls: 0.07604  loss_rpn_loc: 0.02674  time: 0.2191  data_time: 0.0095  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:08 d2.utils.events]: [39m eta: 0:51:52  iter: 1669  total_loss: 1.008  loss_cls: 0.5395  loss_box_reg: 0.3711  loss_rpn_cls: 0.06707  loss_rpn_loc: 0.02518  time: 0.2191  data_time: 0.0088  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:10 d2.utils.events]: [39m eta: 0:51:50  iter: 1679  total_loss: 1.137  loss_cls: 0.5744  loss_box_reg: 0.3898  loss_rpn_cls: 0.07814  loss_rpn_loc: 0.02734  time: 0.2191  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:12 d2.utils.events]: [39m eta: 0:51:47  iter: 1689  total_loss: 0.934  loss_cls: 0.5233  loss_box_reg: 0.3531  loss_rpn_cls: 0.09334  loss_rpn_loc: 0.03552  time: 0.2190  data_time: 0.0082  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:14 d2.utils.events]: [39m eta: 0:51:44  iter: 1699  total_loss: 0.922  loss_cls: 0.4512  loss_box_reg: 0.3635  loss_rpn_cls: 0.08717  loss_rpn_loc: 0.03597  time: 0.2190  data_time: 0.0082  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:17 d2.utils.events]: [39m eta: 0:51:41  iter: 1709  total_loss: 1.079  loss_cls: 0.5335  loss_box_reg: 0.3833  loss_rpn_cls: 0.09128  loss_rpn_loc: 0.05173  time: 0.2190  data_time: 0.0082  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:19 d2.utils.events]: [39m eta: 0:51:38  iter: 1719  total_loss: 1.094  loss_cls: 0.5567  loss_box_reg: 0.3652  loss_rpn_cls: 0.09971  loss_rpn_loc: 0.05704  time: 0.2189  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:21 d2.utils.events]: [39m eta: 0:51:36  iter: 1729  total_loss: 1.015  loss_cls: 0.5266  loss_box_reg: 0.347  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.03099  time: 0.2189  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:23 d2.utils.events]: [39m eta: 0:51:34  iter: 1739  total_loss: 0.9831  loss_cls: 0.5192  loss_box_reg: 0.3718  loss_rpn_cls: 0.06191  loss_rpn_loc: 0.02023  time: 0.2190  data_time: 0.0079  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:25 d2.utils.events]: [39m eta: 0:51:32  iter: 1749  total_loss: 0.9518  loss_cls: 0.4956  loss_box_reg: 0.3877  loss_rpn_cls: 0.05501  loss_rpn_loc: 0.01508  time: 0.2190  data_time: 0.0079  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:28 d2.utils.events]: [39m eta: 0:51:31  iter: 1759  total_loss: 0.9267  loss_cls: 0.4874  loss_box_reg: 0.3508  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.01544  time: 0.2192  data_time: 0.0081  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:32 d2.utils.events]: [39m eta: 0:51:30  iter: 1769  total_loss: 0.9523  loss_cls: 0.511  loss_box_reg: 0.3293  loss_rpn_cls: 0.06731  loss_rpn_loc: 0.02548  time: 0.2203  data_time: 0.0096  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:35 d2.utils.events]: [39m eta: 0:51:28  iter: 1779  total_loss: 1.06  loss_cls: 0.511  loss_box_reg: 0.3791  loss_rpn_cls: 0.08762  loss_rpn_loc: 0.03986  time: 0.2204  data_time: 0.0097  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:37 d2.utils.events]: [39m eta: 0:51:26  iter: 1789  total_loss: 0.9461  loss_cls: 0.5315  loss_box_reg: 0.3561  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.02143  time: 0.2204  data_time: 0.0102  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:39 d2.utils.events]: [39m eta: 0:51:24  iter: 1799  total_loss: 0.8684  loss_cls: 0.5191  loss_box_reg: 0.3614  loss_rpn_cls: 0.04344  loss_rpn_loc: 0.01614  time: 0.2204  data_time: 0.0110  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:41 d2.utils.events]: [39m eta: 0:51:21  iter: 1809  total_loss: 0.8967  loss_cls: 0.4871  loss_box_reg: 0.354  loss_rpn_cls: 0.04104  loss_rpn_loc: 0.01343  time: 0.2204  data_time: 0.0089  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:43 d2.utils.events]: [39m eta: 0:51:19  iter: 1819  total_loss: 0.9736  loss_cls: 0.5367  loss_box_reg: 0.3447  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.02348  time: 0.2203  data_time: 0.0083  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:45 d2.utils.events]: [39m eta: 0:51:16  iter: 1829  total_loss: 1.034  loss_cls: 0.5398  loss_box_reg: 0.3677  loss_rpn_cls: 0.07048  loss_rpn_loc: 0.03171  time: 0.2203  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:48 d2.utils.events]: [39m eta: 0:51:14  iter: 1839  total_loss: 0.9755  loss_cls: 0.5271  loss_box_reg: 0.3316  loss_rpn_cls: 0.04854  loss_rpn_loc: 0.02035  time: 0.2203  data_time: 0.0086  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:50 d2.utils.events]: [39m eta: 0:51:11  iter: 1849  total_loss: 0.9604  loss_cls: 0.5247  loss_box_reg: 0.3383  loss_rpn_cls: 0.05341  loss_rpn_loc: 0.02086  time: 0.2203  data_time: 0.0088  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:52 d2.utils.events]: [39m eta: 0:51:08  iter: 1859  total_loss: 0.8912  loss_cls: 0.524  loss_box_reg: 0.2847  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.02243  time: 0.2203  data_time: 0.0094  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:54 d2.utils.events]: [39m eta: 0:51:06  iter: 1869  total_loss: 0.8221  loss_cls: 0.4489  loss_box_reg: 0.2972  loss_rpn_cls: 0.0555  loss_rpn_loc: 0.02231  time: 0.2203  data_time: 0.0092  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:56 d2.utils.events]: [39m eta: 0:51:05  iter: 1879  total_loss: 0.8084  loss_cls: 0.4288  loss_box_reg: 0.3015  loss_rpn_cls: 0.06233  loss_rpn_loc: 0.02048  time: 0.2203  data_time: 0.0082  lr: 0.001  max_mem: 2109M
[32m[03/25 14:29:59 d2.utils.events]: [39m eta: 0:51:02  iter: 1889  total_loss: 0.8716  loss_cls: 0.4694  loss_box_reg: 0.3139  loss_rpn_cls: 0.05802  loss_rpn_loc: 0.01758  time: 0.2203  data_time: 0.0079  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:02 d2.utils.events]: [39m eta: 0:51:00  iter: 1899  total_loss: 0.9657  loss_cls: 0.5198  loss_box_reg: 0.3471  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.02778  time: 0.2208  data_time: 0.0078  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:06 d2.utils.events]: [39m eta: 0:50:58  iter: 1909  total_loss: 0.9289  loss_cls: 0.4973  loss_box_reg: 0.3303  loss_rpn_cls: 0.0673  loss_rpn_loc: 0.02816  time: 0.2217  data_time: 0.0078  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:10 d2.utils.events]: [39m eta: 0:50:56  iter: 1919  total_loss: 1.011  loss_cls: 0.5317  loss_box_reg: 0.3375  loss_rpn_cls: 0.08879  loss_rpn_loc: 0.03605  time: 0.2227  data_time: 0.0083  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:14 d2.utils.events]: [39m eta: 0:50:55  iter: 1929  total_loss: 1.026  loss_cls: 0.5549  loss_box_reg: 0.358  loss_rpn_cls: 0.08836  loss_rpn_loc: 0.03605  time: 0.2236  data_time: 0.0102  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:18 d2.utils.events]: [39m eta: 0:50:53  iter: 1939  total_loss: 0.9766  loss_cls: 0.5275  loss_box_reg: 0.3615  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.02836  time: 0.2245  data_time: 0.0097  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:22 d2.utils.events]: [39m eta: 0:50:51  iter: 1949  total_loss: 0.9967  loss_cls: 0.4995  loss_box_reg: 0.3884  loss_rpn_cls: 0.05669  loss_rpn_loc: 0.03078  time: 0.2256  data_time: 0.0085  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:26 d2.utils.events]: [39m eta: 0:50:49  iter: 1959  total_loss: 0.8805  loss_cls: 0.4692  loss_box_reg: 0.337  loss_rpn_cls: 0.04795  loss_rpn_loc: 0.01665  time: 0.2265  data_time: 0.0101  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:30 d2.utils.events]: [39m eta: 0:50:47  iter: 1969  total_loss: 0.8865  loss_cls: 0.4703  loss_box_reg: 0.343  loss_rpn_cls: 0.06334  loss_rpn_loc: 0.02141  time: 0.2274  data_time: 0.0112  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:34 d2.utils.events]: [39m eta: 0:50:46  iter: 1979  total_loss: 0.9237  loss_cls: 0.5092  loss_box_reg: 0.368  loss_rpn_cls: 0.05298  loss_rpn_loc: 0.02141  time: 0.2283  data_time: 0.0103  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:38 d2.utils.events]: [39m eta: 0:50:44  iter: 1989  total_loss: 0.8309  loss_cls: 0.4669  loss_box_reg: 0.2972  loss_rpn_cls: 0.03529  loss_rpn_loc: 0.01222  time: 0.2292  data_time: 0.0107  lr: 0.001  max_mem: 2109M
Traceback (most recent call last):
  File "train.py", line 123, in <module>
    trainer.train()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 491, in train
    super().train(self.start_iter, self.max_iter)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 150, in train
    self.run_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 501, in run_step
    self._trainer.run_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 276, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/meta_arch/rcnn.py", line 157, in forward
    proposals, proposal_losses = self.proposal_generator(images, features, gt_instances)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/proposal_generator/rpn.py", line 471, in forward
    gt_labels, gt_boxes = self.label_and_sample_anchors(anchors, gt_instances)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/proposal_generator/rpn.py", line 340, in label_and_sample_anchors
    matched_idxs, gt_labels_i = retry_if_cuda_oom(self.anchor_matcher)(match_quality_matrix)
  File "/opt/ml/detection/baseline/detectron2/detectron2/utils/memory.py", line 70, in wrapped
    return func(*args, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/matcher.py", line 88, in __call__
    assert torch.all(match_quality_matrix >= 0)
KeyboardInterrupt
[32m[03/25 14:30:42 d2.utils.events]: [39m eta: 0:50:44  iter: 1999  total_loss: 1.005  loss_cls: 0.4906  loss_box_reg: 0.3895  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.01505  time: 0.2300  data_time: 0.0101  lr: 0.001  max_mem: 2109M
[32m[03/25 14:30:43 d2.engine.hooks]: [39mOverall training speed: 1999 iterations in 0:07:40 (0.2302 s / it)
[32m[03/25 14:30:43 d2.engine.hooks]: [39mTotal training time: 0:08:16 (0:00:35 on hooks)
[32m[03/25 14:30:43 d2.utils.events]: [39m eta: 0:50:43  iter: 2001  total_loss: 1.005  loss_cls: 0.4961  loss_box_reg: 0.3895  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.01505  time: 0.2301  data_time: 0.0099  lr: 0.001  max_mem: 2109M