[32m[03/28 03:17:57 d2.engine.defaults]: [39mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
  )
)
[32m[03/28 03:17:57 d2.data.datasets.coco]: [39mLoaded 4280 images in COCO format from ../../dataset/SK_train_annotations.json
[32m[03/28 03:17:57 d2.data.build]: [39mRemoved 0 images with no usable annotations. 4280 images left.
[32m[03/28 03:17:57 d2.data.build]: [39mDistribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
[36m|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
[36m| General trash | 3468         |    Paper    | 5511         | Paper pack | 800          |
[36m|     Metal     | 827          |    Glass    | 900          |  Plastic   | 2591         |
[36m|   Styrofoam   | 1140         | Plastic bag | 4563         |  Battery   | 148          |
[36m|   Clothing    | 416          |             |              |            |              |
[36m|     total     | 20364        |             |              |            |              |
[32m[03/28 03:17:57 d2.data.build]: [39mUsing training sampler RepeatFactorTrainingSampler
[32m[03/28 03:17:57 d2.data.common]: [39mSerializing 4280 elements to byte tensors and concatenating them all ...
[32m[03/28 03:17:58 d2.data.common]: [39mSerialized dataset takes 1.92 MiB
expected_results:
[]
[32m[03/28 03:17:58 d2.engine.train_loop]: [39mStarting training from iteration 0
/opt/ml/detection/baseline/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)
  num_fg = fg_inds.nonzero().numel()
/opt/conda/envs/detection/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
[32m[03/28 03:18:00 d2.utils.events]: [39m eta: 5:30:27  iter: 4  total_loss: 3.694  loss_cls: 2.254  loss_box_reg: 0.4587  loss_rpn_cls: 0.8132  loss_rpn_loc: 0.0431  time: 0.1862  data_time: 0.0724  lr: 4.996e-06  max_mem: 1789M
[32m[03/28 03:18:01 d2.utils.events]: [39m eta: 5:29:35  iter: 9  total_loss: 3.602  loss_cls: 2.245  loss_box_reg: 0.4457  loss_rpn_cls: 0.7781  loss_rpn_loc: 0.04357  time: 0.1849  data_time: 0.0403  lr: 9.991e-06  max_mem: 1789M
[32m[03/28 03:18:02 d2.utils.events]: [39m eta: 5:29:20  iter: 14  total_loss: 3.653  loss_cls: 2.224  loss_box_reg: 0.4543  loss_rpn_cls: 0.821  loss_rpn_loc: 0.04886  time: 0.1855  data_time: 0.0297  lr: 1.4986e-05  max_mem: 1789M
[32m[03/28 03:18:03 d2.utils.events]: [39m eta: 5:28:56  iter: 19  total_loss: 3.666  loss_cls: 2.197  loss_box_reg: 0.4544  loss_rpn_cls: 0.8964  loss_rpn_loc: 0.05608  time: 0.1851  data_time: 0.0242  lr: 1.9981e-05  max_mem: 1789M
[32m[03/28 03:18:04 d2.utils.events]: [39m eta: 5:28:39  iter: 24  total_loss: 3.644  loss_cls: 2.03  loss_box_reg: 0.4763  loss_rpn_cls: 0.9958  loss_rpn_loc: 0.06388  time: 0.1849  data_time: 0.0082  lr: 2.4976e-05  max_mem: 1789M
[32m[03/28 03:18:05 d2.utils.events]: [39m eta: 5:29:01  iter: 29  total_loss: 3.563  loss_cls: 1.85  loss_box_reg: 0.5291  loss_rpn_cls: 0.9335  loss_rpn_loc: 0.06201  time: 0.1848  data_time: 0.0082  lr: 2.9971e-05  max_mem: 1789M
[32m[03/28 03:18:06 d2.utils.events]: [39m eta: 5:29:17  iter: 34  total_loss: 3.15  loss_cls: 1.562  loss_box_reg: 0.5872  loss_rpn_cls: 0.9329  loss_rpn_loc: 0.06735  time: 0.1863  data_time: 0.0088  lr: 3.4966e-05  max_mem: 1789M
[32m[03/28 03:18:07 d2.utils.events]: [39m eta: 5:29:42  iter: 39  total_loss: 2.723  loss_cls: 1.348  loss_box_reg: 0.5995  loss_rpn_cls: 0.6792  loss_rpn_loc: 0.04525  time: 0.1876  data_time: 0.0097  lr: 3.9961e-05  max_mem: 1789M
[32m[03/28 03:18:07 d2.utils.events]: [39m eta: 5:29:53  iter: 44  total_loss: 2.612  loss_cls: 1.157  loss_box_reg: 0.6595  loss_rpn_cls: 0.6357  loss_rpn_loc: 0.04337  time: 0.1875  data_time: 0.0097  lr: 4.4956e-05  max_mem: 1789M
[32m[03/28 03:18:08 d2.utils.events]: [39m eta: 5:30:12  iter: 49  total_loss: 2.058  loss_cls: 1.005  loss_box_reg: 0.6654  loss_rpn_cls: 0.335  loss_rpn_loc: 0.03421  time: 0.1875  data_time: 0.0097  lr: 4.9951e-05  max_mem: 1789M
[32m[03/28 03:18:09 d2.utils.events]: [39m eta: 5:30:15  iter: 54  total_loss: 2.009  loss_cls: 0.9318  loss_box_reg: 0.7248  loss_rpn_cls: 0.335  loss_rpn_loc: 0.03421  time: 0.1889  data_time: 0.0095  lr: 5.4946e-05  max_mem: 1789M
[32m[03/28 03:18:10 d2.utils.events]: [39m eta: 5:31:06  iter: 59  total_loss: 2.036  loss_cls: 0.8873  loss_box_reg: 0.7579  loss_rpn_cls: 0.3287  loss_rpn_loc: 0.05151  time: 0.1906  data_time: 0.0086  lr: 5.9941e-05  max_mem: 1789M
[32m[03/28 03:18:12 d2.utils.events]: [39m eta: 5:31:34  iter: 64  total_loss: 2.036  loss_cls: 0.8426  loss_box_reg: 0.7653  loss_rpn_cls: 0.3287  loss_rpn_loc: 0.05151  time: 0.1923  data_time: 0.0088  lr: 6.4936e-05  max_mem: 1789M
[32m[03/28 03:18:13 d2.utils.events]: [39m eta: 5:33:04  iter: 69  total_loss: 1.97  loss_cls: 0.8142  loss_box_reg: 0.7515  loss_rpn_cls: 0.3216  loss_rpn_loc: 0.05479  time: 0.1935  data_time: 0.0090  lr: 6.9931e-05  max_mem: 1789M
[32m[03/28 03:18:14 d2.utils.events]: [39m eta: 5:34:17  iter: 74  total_loss: 1.612  loss_cls: 0.7983  loss_box_reg: 0.6919  loss_rpn_cls: 0.2112  loss_rpn_loc: 0.0469  time: 0.1947  data_time: 0.0087  lr: 7.4926e-05  max_mem: 1789M
[32m[03/28 03:18:15 d2.utils.events]: [39m eta: 5:35:45  iter: 79  total_loss: 1.562  loss_cls: 0.7403  loss_box_reg: 0.6617  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.03306  time: 0.1958  data_time: 0.0088  lr: 7.9921e-05  max_mem: 1789M
[32m[03/28 03:18:16 d2.utils.events]: [39m eta: 5:35:45  iter: 84  total_loss: 1.579  loss_cls: 0.7352  loss_box_reg: 0.6617  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.04042  time: 0.1960  data_time: 0.0089  lr: 8.4916e-05  max_mem: 1789M
[32m[03/28 03:18:17 d2.utils.events]: [39m eta: 5:36:03  iter: 89  total_loss: 1.451  loss_cls: 0.7043  loss_box_reg: 0.6188  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.04174  time: 0.1963  data_time: 0.0087  lr: 8.9911e-05  max_mem: 1789M
[32m[03/28 03:18:18 d2.utils.events]: [39m eta: 5:36:49  iter: 94  total_loss: 1.502  loss_cls: 0.7062  loss_box_reg: 0.6652  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.04301  time: 0.1970  data_time: 0.0088  lr: 9.4906e-05  max_mem: 1789M
[32m[03/28 03:18:19 d2.utils.events]: [39m eta: 5:36:01  iter: 99  total_loss: 1.53  loss_cls: 0.7161  loss_box_reg: 0.6653  loss_rpn_cls: 0.124  loss_rpn_loc: 0.0459  time: 0.1962  data_time: 0.0086  lr: 9.9901e-05  max_mem: 1789M
[32m[03/28 03:18:20 d2.utils.events]: [39m eta: 5:35:39  iter: 104  total_loss: 1.502  loss_cls: 0.6853  loss_box_reg: 0.6657  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.04301  time: 0.1955  data_time: 0.0083  lr: 0.0001049  max_mem: 1789M
[32m[03/28 03:18:21 d2.utils.events]: [39m eta: 5:35:39  iter: 109  total_loss: 1.623  loss_cls: 0.7569  loss_box_reg: 0.7451  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.04369  time: 0.1957  data_time: 0.0085  lr: 0.00010989  max_mem: 1789M
[32m[03/28 03:18:22 d2.utils.events]: [39m eta: 5:35:46  iter: 114  total_loss: 1.623  loss_cls: 0.7569  loss_box_reg: 0.7445  loss_rpn_cls: 0.09411  loss_rpn_loc: 0.04062  time: 0.1957  data_time: 0.0085  lr: 0.00011489  max_mem: 1789M
[32m[03/28 03:18:23 d2.utils.events]: [39m eta: 5:35:38  iter: 119  total_loss: 1.584  loss_cls: 0.7474  loss_box_reg: 0.7259  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.04451  time: 0.1953  data_time: 0.0088  lr: 0.00011988  max_mem: 1789M
[32m[03/28 03:18:24 d2.utils.events]: [39m eta: 5:35:18  iter: 124  total_loss: 1.584  loss_cls: 0.7248  loss_box_reg: 0.7054  loss_rpn_cls: 0.1535  loss_rpn_loc: 0.05216  time: 0.1950  data_time: 0.0088  lr: 0.00012488  max_mem: 1789M
[32m[03/28 03:18:24 d2.utils.events]: [39m eta: 5:34:28  iter: 129  total_loss: 1.683  loss_cls: 0.7203  loss_box_reg: 0.7347  loss_rpn_cls: 0.1446  loss_rpn_loc: 0.05404  time: 0.1946  data_time: 0.0086  lr: 0.00012987  max_mem: 1789M
[32m[03/28 03:18:25 d2.utils.events]: [39m eta: 5:34:05  iter: 134  total_loss: 1.618  loss_cls: 0.725  loss_box_reg: 0.7426  loss_rpn_cls: 0.1292  loss_rpn_loc: 0.05404  time: 0.1942  data_time: 0.0084  lr: 0.00013487  max_mem: 1789M
[32m[03/28 03:18:26 d2.utils.events]: [39m eta: 5:33:42  iter: 139  total_loss: 1.6  loss_cls: 0.7068  loss_box_reg: 0.7343  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.0374  time: 0.1939  data_time: 0.0082  lr: 0.00013986  max_mem: 1789M
[32m[03/28 03:18:27 d2.utils.events]: [39m eta: 5:33:45  iter: 144  total_loss: 1.595  loss_cls: 0.7244  loss_box_reg: 0.7633  loss_rpn_cls: 0.09221  loss_rpn_loc: 0.02887  time: 0.1936  data_time: 0.0082  lr: 0.00014486  max_mem: 1789M
[32m[03/28 03:18:28 d2.utils.events]: [39m eta: 5:33:04  iter: 149  total_loss: 1.582  loss_cls: 0.714  loss_box_reg: 0.7355  loss_rpn_cls: 0.08237  loss_rpn_loc: 0.02882  time: 0.1933  data_time: 0.0083  lr: 0.00014985  max_mem: 1789M
[32m[03/28 03:18:29 d2.utils.events]: [39m eta: 5:32:34  iter: 154  total_loss: 1.627  loss_cls: 0.7164  loss_box_reg: 0.7449  loss_rpn_cls: 0.09428  loss_rpn_loc: 0.0366  time: 0.1930  data_time: 0.0083  lr: 0.00015485  max_mem: 1789M
[32m[03/28 03:18:30 d2.utils.events]: [39m eta: 5:31:59  iter: 159  total_loss: 1.711  loss_cls: 0.8049  loss_box_reg: 0.7617  loss_rpn_cls: 0.09447  loss_rpn_loc: 0.04321  time: 0.1927  data_time: 0.0082  lr: 0.00015984  max_mem: 1789M
[32m[03/28 03:18:31 d2.utils.events]: [39m eta: 5:31:42  iter: 164  total_loss: 1.776  loss_cls: 0.819  loss_box_reg: 0.7644  loss_rpn_cls: 0.149  loss_rpn_loc: 0.05053  time: 0.1924  data_time: 0.0082  lr: 0.00016484  max_mem: 1789M
[32m[03/28 03:18:32 d2.utils.events]: [39m eta: 5:31:17  iter: 169  total_loss: 1.712  loss_cls: 0.8026  loss_box_reg: 0.7828  loss_rpn_cls: 0.149  loss_rpn_loc: 0.05053  time: 0.1922  data_time: 0.0081  lr: 0.00016983  max_mem: 1789M
[32m[03/28 03:18:33 d2.utils.events]: [39m eta: 5:31:02  iter: 174  total_loss: 1.704  loss_cls: 0.7593  loss_box_reg: 0.7538  loss_rpn_cls: 0.1275  loss_rpn_loc: 0.0513  time: 0.1919  data_time: 0.0081  lr: 0.00017483  max_mem: 1789M
[32m[03/28 03:18:34 d2.utils.events]: [39m eta: 5:30:58  iter: 179  total_loss: 1.706  loss_cls: 0.7062  loss_box_reg: 0.7178  loss_rpn_cls: 0.15  loss_rpn_loc: 0.04921  time: 0.1918  data_time: 0.0081  lr: 0.00017982  max_mem: 1789M
[32m[03/28 03:18:35 d2.utils.events]: [39m eta: 5:31:12  iter: 184  total_loss: 1.63  loss_cls: 0.6988  loss_box_reg: 0.6773  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.04554  time: 0.1919  data_time: 0.0083  lr: 0.00018482  max_mem: 1789M
[32m[03/28 03:18:36 d2.utils.events]: [39m eta: 5:31:13  iter: 189  total_loss: 1.671  loss_cls: 0.7299  loss_box_reg: 0.7128  loss_rpn_cls: 0.114  loss_rpn_loc: 0.04075  time: 0.1918  data_time: 0.0084  lr: 0.00018981  max_mem: 1789M
[32m[03/28 03:18:37 d2.utils.events]: [39m eta: 5:31:10  iter: 194  total_loss: 1.681  loss_cls: 0.733  loss_box_reg: 0.7128  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.03687  time: 0.1916  data_time: 0.0085  lr: 0.00019481  max_mem: 1789M
[32m[03/28 03:18:38 d2.utils.events]: [39m eta: 5:31:05  iter: 199  total_loss: 1.602  loss_cls: 0.7231  loss_box_reg: 0.7055  loss_rpn_cls: 0.1  loss_rpn_loc: 0.03507  time: 0.1915  data_time: 0.0085  lr: 0.0001998  max_mem: 1789M
[32m[03/28 03:18:39 d2.utils.events]: [39m eta: 5:31:08  iter: 204  total_loss: 1.55  loss_cls: 0.7124  loss_box_reg: 0.708  loss_rpn_cls: 0.08415  loss_rpn_loc: 0.0261  time: 0.1914  data_time: 0.0084  lr: 0.0002048  max_mem: 1789M
[32m[03/28 03:18:40 d2.utils.events]: [39m eta: 5:31:03  iter: 209  total_loss: 1.55  loss_cls: 0.7015  loss_box_reg: 0.6958  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.03062  time: 0.1914  data_time: 0.0088  lr: 0.00020979  max_mem: 1789M
[32m[03/28 03:18:40 d2.utils.events]: [39m eta: 5:30:55  iter: 214  total_loss: 1.532  loss_cls: 0.6913  loss_box_reg: 0.696  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.03062  time: 0.1913  data_time: 0.0087  lr: 0.00021479  max_mem: 1789M
[32m[03/28 03:18:41 d2.utils.events]: [39m eta: 5:31:01  iter: 219  total_loss: 1.532  loss_cls: 0.6884  loss_box_reg: 0.7234  loss_rpn_cls: 0.08428  loss_rpn_loc: 0.03083  time: 0.1914  data_time: 0.0101  lr: 0.00021978  max_mem: 1789M
[32m[03/28 03:18:42 d2.utils.events]: [39m eta: 5:31:05  iter: 224  total_loss: 1.619  loss_cls: 0.6978  loss_box_reg: 0.7365  loss_rpn_cls: 0.07915  loss_rpn_loc: 0.03487  time: 0.1914  data_time: 0.0108  lr: 0.00022478  max_mem: 1789M
[32m[03/28 03:18:43 d2.utils.events]: [39m eta: 5:31:19  iter: 229  total_loss: 1.578  loss_cls: 0.6797  loss_box_reg: 0.7432  loss_rpn_cls: 0.07549  loss_rpn_loc: 0.0301  time: 0.1916  data_time: 0.0104  lr: 0.00022977  max_mem: 1789M
[32m[03/28 03:18:44 d2.utils.events]: [39m eta: 5:31:03  iter: 234  total_loss: 1.528  loss_cls: 0.6895  loss_box_reg: 0.7178  loss_rpn_cls: 0.07641  loss_rpn_loc: 0.02877  time: 0.1914  data_time: 0.0106  lr: 0.00023477  max_mem: 1789M
[32m[03/28 03:18:45 d2.utils.events]: [39m eta: 5:31:17  iter: 239  total_loss: 1.588  loss_cls: 0.6916  loss_box_reg: 0.7207  loss_rpn_cls: 0.07549  loss_rpn_loc: 0.02877  time: 0.1913  data_time: 0.0096  lr: 0.00023976  max_mem: 1789M
[32m[03/28 03:18:46 d2.utils.events]: [39m eta: 5:31:01  iter: 244  total_loss: 1.463  loss_cls: 0.677  loss_box_reg: 0.6904  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.02287  time: 0.1912  data_time: 0.0089  lr: 0.00024476  max_mem: 1789M
[32m[03/28 03:18:47 d2.utils.events]: [39m eta: 5:30:50  iter: 249  total_loss: 1.45  loss_cls: 0.6772  loss_box_reg: 0.6598  loss_rpn_cls: 0.06324  loss_rpn_loc: 0.02212  time: 0.1911  data_time: 0.0089  lr: 0.00024975  max_mem: 1789M
[32m[03/28 03:18:48 d2.utils.events]: [39m eta: 5:30:41  iter: 254  total_loss: 1.448  loss_cls: 0.6772  loss_box_reg: 0.6775  loss_rpn_cls: 0.05162  loss_rpn_loc: 0.02091  time: 0.1909  data_time: 0.0088  lr: 0.00025475  max_mem: 1789M
[32m[03/28 03:18:49 d2.utils.events]: [39m eta: 5:30:33  iter: 259  total_loss: 1.451  loss_cls: 0.6772  loss_box_reg: 0.6968  loss_rpn_cls: 0.05891  loss_rpn_loc: 0.02389  time: 0.1908  data_time: 0.0085  lr: 0.00025974  max_mem: 1789M
[32m[03/28 03:18:50 d2.utils.events]: [39m eta: 5:30:31  iter: 264  total_loss: 1.462  loss_cls: 0.6772  loss_box_reg: 0.7062  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.02558  time: 0.1906  data_time: 0.0085  lr: 0.00026474  max_mem: 1789M
[32m[03/28 03:18:51 d2.utils.events]: [39m eta: 5:30:29  iter: 269  total_loss: 1.534  loss_cls: 0.6837  loss_box_reg: 0.6968  loss_rpn_cls: 0.09  loss_rpn_loc: 0.03657  time: 0.1905  data_time: 0.0090  lr: 0.00026973  max_mem: 1789M
[32m[03/28 03:18:52 d2.utils.events]: [39m eta: 5:30:26  iter: 274  total_loss: 1.564  loss_cls: 0.6598  loss_box_reg: 0.6578  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.05585  time: 0.1904  data_time: 0.0092  lr: 0.00027473  max_mem: 1789M
[32m[03/28 03:18:53 d2.utils.events]: [39m eta: 5:30:27  iter: 279  total_loss: 1.534  loss_cls: 0.643  loss_box_reg: 0.637  loss_rpn_cls: 0.1463  loss_rpn_loc: 0.06228  time: 0.1903  data_time: 0.0091  lr: 0.00027972  max_mem: 1789M
[32m[03/28 03:18:54 d2.utils.events]: [39m eta: 5:30:28  iter: 284  total_loss: 1.611  loss_cls: 0.6695  loss_box_reg: 0.6487  loss_rpn_cls: 0.1463  loss_rpn_loc: 0.06228  time: 0.1904  data_time: 0.0091  lr: 0.00028472  max_mem: 1789M
[32m[03/28 03:18:55 d2.utils.events]: [39m eta: 5:30:30  iter: 289  total_loss: 1.572  loss_cls: 0.6829  loss_box_reg: 0.652  loss_rpn_cls: 0.1234  loss_rpn_loc: 0.0467  time: 0.1908  data_time: 0.0093  lr: 0.00028971  max_mem: 1789M
[32m[03/28 03:18:56 d2.utils.events]: [39m eta: 5:30:26  iter: 294  total_loss: 1.662  loss_cls: 0.6963  loss_box_reg: 0.6843  loss_rpn_cls: 0.1154  loss_rpn_loc: 0.03924  time: 0.1907  data_time: 0.0090  lr: 0.00029471  max_mem: 1789M
[32m[03/28 03:18:57 d2.utils.events]: [39m eta: 5:30:23  iter: 299  total_loss: 1.607  loss_cls: 0.7033  loss_box_reg: 0.6986  loss_rpn_cls: 0.1154  loss_rpn_loc: 0.04293  time: 0.1906  data_time: 0.0091  lr: 0.0002997  max_mem: 1789M
[32m[03/28 03:18:58 d2.utils.events]: [39m eta: 5:30:16  iter: 304  total_loss: 1.517  loss_cls: 0.6859  loss_box_reg: 0.6746  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.04293  time: 0.1905  data_time: 0.0094  lr: 0.0003047  max_mem: 1789M
[32m[03/28 03:18:59 d2.utils.events]: [39m eta: 5:30:14  iter: 309  total_loss: 1.529  loss_cls: 0.6835  loss_box_reg: 0.6723  loss_rpn_cls: 0.1422  loss_rpn_loc: 0.05527  time: 0.1904  data_time: 0.0087  lr: 0.00030969  max_mem: 1789M
[32m[03/28 03:18:59 d2.utils.events]: [39m eta: 5:30:00  iter: 314  total_loss: 1.529  loss_cls: 0.722  loss_box_reg: 0.6749  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.05507  time: 0.1903  data_time: 0.0086  lr: 0.00031469  max_mem: 1789M
[32m[03/28 03:19:00 d2.utils.events]: [39m eta: 5:29:45  iter: 319  total_loss: 1.494  loss_cls: 0.6752  loss_box_reg: 0.665  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.05032  time: 0.1901  data_time: 0.0085  lr: 0.00031968  max_mem: 1789M
[32m[03/28 03:19:01 d2.utils.events]: [39m eta: 5:29:28  iter: 324  total_loss: 1.508  loss_cls: 0.6928  loss_box_reg: 0.665  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.05731  time: 0.1900  data_time: 0.0082  lr: 0.00032468  max_mem: 1789M
[32m[03/28 03:19:02 d2.utils.events]: [39m eta: 5:29:23  iter: 329  total_loss: 1.475  loss_cls: 0.6928  loss_box_reg: 0.6928  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.05032  time: 0.1899  data_time: 0.0082  lr: 0.00032967  max_mem: 1789M
[32m[03/28 03:19:03 d2.utils.events]: [39m eta: 5:29:19  iter: 334  total_loss: 1.457  loss_cls: 0.6114  loss_box_reg: 0.6777  loss_rpn_cls: 0.09392  loss_rpn_loc: 0.03556  time: 0.1897  data_time: 0.0082  lr: 0.00033467  max_mem: 1789M
[32m[03/28 03:19:04 d2.utils.events]: [39m eta: 5:29:19  iter: 339  total_loss: 1.516  loss_cls: 0.697  loss_box_reg: 0.6879  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.05066  time: 0.1896  data_time: 0.0085  lr: 0.00033966  max_mem: 1789M
[32m[03/28 03:19:05 d2.utils.events]: [39m eta: 5:29:17  iter: 344  total_loss: 1.516  loss_cls: 0.6872  loss_box_reg: 0.6983  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.04489  time: 0.1896  data_time: 0.0087  lr: 0.00034466  max_mem: 1789M
[32m[03/28 03:19:06 d2.utils.events]: [39m eta: 5:29:10  iter: 349  total_loss: 1.516  loss_cls: 0.6872  loss_box_reg: 0.6714  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.03913  time: 0.1895  data_time: 0.0087  lr: 0.00034965  max_mem: 1789M
[32m[03/28 03:19:07 d2.utils.events]: [39m eta: 5:29:07  iter: 354  total_loss: 1.51  loss_cls: 0.6566  loss_box_reg: 0.6322  loss_rpn_cls: 0.123  loss_rpn_loc: 0.05902  time: 0.1894  data_time: 0.0086  lr: 0.00035465  max_mem: 1789M
[32m[03/28 03:19:08 d2.utils.events]: [39m eta: 5:29:02  iter: 359  total_loss: 1.488  loss_cls: 0.6527  loss_box_reg: 0.6281  loss_rpn_cls: 0.08751  loss_rpn_loc: 0.03616  time: 0.1894  data_time: 0.0086  lr: 0.00035964  max_mem: 1789M
[32m[03/28 03:19:09 d2.utils.events]: [39m eta: 5:29:00  iter: 364  total_loss: 1.447  loss_cls: 0.6502  loss_box_reg: 0.6162  loss_rpn_cls: 0.0742  loss_rpn_loc: 0.02075  time: 0.1893  data_time: 0.0087  lr: 0.00036464  max_mem: 1789M
[32m[03/28 03:19:10 d2.utils.events]: [39m eta: 5:28:56  iter: 369  total_loss: 1.4  loss_cls: 0.6221  loss_box_reg: 0.628  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.01803  time: 0.1892  data_time: 0.0086  lr: 0.00036963  max_mem: 1789M
[32m[03/28 03:19:11 d2.utils.events]: [39m eta: 5:28:52  iter: 374  total_loss: 1.473  loss_cls: 0.6765  loss_box_reg: 0.6448  loss_rpn_cls: 0.0777  loss_rpn_loc: 0.0227  time: 0.1892  data_time: 0.0094  lr: 0.00037463  max_mem: 1789M
[32m[03/28 03:19:11 d2.utils.events]: [39m eta: 5:28:42  iter: 379  total_loss: 1.444  loss_cls: 0.6601  loss_box_reg: 0.6312  loss_rpn_cls: 0.09468  loss_rpn_loc: 0.02942  time: 0.1891  data_time: 0.0093  lr: 0.00037962  max_mem: 1789M
[32m[03/28 03:19:12 d2.utils.events]: [39m eta: 5:28:38  iter: 384  total_loss: 1.43  loss_cls: 0.6627  loss_box_reg: 0.6263  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.04301  time: 0.1890  data_time: 0.0091  lr: 0.00038462  max_mem: 1789M
[32m[03/28 03:19:13 d2.utils.events]: [39m eta: 5:28:33  iter: 389  total_loss: 1.43  loss_cls: 0.6627  loss_box_reg: 0.6438  loss_rpn_cls: 0.09201  loss_rpn_loc: 0.0392  time: 0.1889  data_time: 0.0092  lr: 0.00038961  max_mem: 1789M
[32m[03/28 03:19:14 d2.utils.events]: [39m eta: 5:28:29  iter: 394  total_loss: 1.377  loss_cls: 0.6209  loss_box_reg: 0.6222  loss_rpn_cls: 0.08349  loss_rpn_loc: 0.02947  time: 0.1888  data_time: 0.0085  lr: 0.00039461  max_mem: 1789M
[32m[03/28 03:19:15 d2.utils.events]: [39m eta: 5:28:23  iter: 399  total_loss: 1.413  loss_cls: 0.6622  loss_box_reg: 0.6222  loss_rpn_cls: 0.09201  loss_rpn_loc: 0.04045  time: 0.1887  data_time: 0.0084  lr: 0.0003996  max_mem: 1789M
[32m[03/28 03:19:16 d2.utils.events]: [39m eta: 5:28:15  iter: 404  total_loss: 1.412  loss_cls: 0.6575  loss_box_reg: 0.6177  loss_rpn_cls: 0.08261  loss_rpn_loc: 0.03308  time: 0.1886  data_time: 0.0083  lr: 0.0004046  max_mem: 1789M
[32m[03/28 03:19:17 d2.utils.events]: [39m eta: 5:28:04  iter: 409  total_loss: 1.412  loss_cls: 0.6552  loss_box_reg: 0.6049  loss_rpn_cls: 0.09214  loss_rpn_loc: 0.03804  time: 0.1885  data_time: 0.0082  lr: 0.00040959  max_mem: 1789M
[32m[03/28 03:19:18 d2.utils.events]: [39m eta: 5:27:59  iter: 414  total_loss: 1.41  loss_cls: 0.6552  loss_box_reg: 0.5933  loss_rpn_cls: 0.08405  loss_rpn_loc: 0.03804  time: 0.1884  data_time: 0.0082  lr: 0.00041459  max_mem: 1789M
[32m[03/28 03:19:19 d2.utils.events]: [39m eta: 5:27:42  iter: 419  total_loss: 1.362  loss_cls: 0.6336  loss_box_reg: 0.5834  loss_rpn_cls: 0.08405  loss_rpn_loc: 0.03269  time: 0.1883  data_time: 0.0083  lr: 0.00041958  max_mem: 1789M
[32m[03/28 03:19:20 d2.utils.events]: [39m eta: 5:27:41  iter: 424  total_loss: 1.372  loss_cls: 0.641  loss_box_reg: 0.5579  loss_rpn_cls: 0.09852  loss_rpn_loc: 0.03731  time: 0.1882  data_time: 0.0083  lr: 0.00042458  max_mem: 1789M
[32m[03/28 03:19:21 d2.utils.events]: [39m eta: 5:27:38  iter: 429  total_loss: 1.335  loss_cls: 0.6089  loss_box_reg: 0.5411  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.025  time: 0.1882  data_time: 0.0086  lr: 0.00042957  max_mem: 1789M
[32m[03/28 03:19:22 d2.utils.events]: [39m eta: 5:27:33  iter: 434  total_loss: 1.395  loss_cls: 0.6491  loss_box_reg: 0.5557  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.04806  time: 0.1881  data_time: 0.0087  lr: 0.00043457  max_mem: 1789M
[32m[03/28 03:19:22 d2.utils.events]: [39m eta: 5:27:20  iter: 439  total_loss: 1.354  loss_cls: 0.6302  loss_box_reg: 0.527  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.0403  time: 0.1880  data_time: 0.0086  lr: 0.00043956  max_mem: 1789M
[32m[03/28 03:19:23 d2.utils.events]: [39m eta: 5:26:53  iter: 444  total_loss: 1.402  loss_cls: 0.6557  loss_box_reg: 0.53  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.04796  time: 0.1879  data_time: 0.0086  lr: 0.00044456  max_mem: 1789M
[32m[03/28 03:19:24 d2.utils.events]: [39m eta: 5:26:49  iter: 449  total_loss: 1.44  loss_cls: 0.6848  loss_box_reg: 0.5457  loss_rpn_cls: 0.1321  loss_rpn_loc: 0.0519  time: 0.1879  data_time: 0.0083  lr: 0.00044955  max_mem: 1789M
[32m[03/28 03:19:25 d2.utils.events]: [39m eta: 5:26:47  iter: 454  total_loss: 1.372  loss_cls: 0.6758  loss_box_reg: 0.5362  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.04502  time: 0.1878  data_time: 0.0086  lr: 0.00045455  max_mem: 1789M
[32m[03/28 03:19:26 d2.utils.events]: [39m eta: 5:26:41  iter: 459  total_loss: 1.345  loss_cls: 0.6649  loss_box_reg: 0.5362  loss_rpn_cls: 0.08898  loss_rpn_loc: 0.03366  time: 0.1877  data_time: 0.0087  lr: 0.00045954  max_mem: 1789M
[32m[03/28 03:19:27 d2.utils.events]: [39m eta: 5:26:36  iter: 464  total_loss: 1.289  loss_cls: 0.6207  loss_box_reg: 0.5301  loss_rpn_cls: 0.0691  loss_rpn_loc: 0.0235  time: 0.1876  data_time: 0.0088  lr: 0.00046454  max_mem: 1789M
[32m[03/28 03:19:28 d2.utils.events]: [39m eta: 5:26:28  iter: 469  total_loss: 1.237  loss_cls: 0.6108  loss_box_reg: 0.5301  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.02338  time: 0.1876  data_time: 0.0088  lr: 0.00046953  max_mem: 1789M
[32m[03/28 03:19:29 d2.utils.events]: [39m eta: 5:26:20  iter: 474  total_loss: 1.176  loss_cls: 0.6012  loss_box_reg: 0.4998  loss_rpn_cls: 0.06494  loss_rpn_loc: 0.01982  time: 0.1875  data_time: 0.0086  lr: 0.00047453  max_mem: 1812M
[32m[03/28 03:19:30 d2.utils.events]: [39m eta: 5:26:18  iter: 479  total_loss: 1.354  loss_cls: 0.6525  loss_box_reg: 0.5461  loss_rpn_cls: 0.08594  loss_rpn_loc: 0.03021  time: 0.1875  data_time: 0.0088  lr: 0.00047952  max_mem: 1812M
[32m[03/28 03:19:31 d2.utils.events]: [39m eta: 5:26:04  iter: 484  total_loss: 1.375  loss_cls: 0.6361  loss_box_reg: 0.5177  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.04753  time: 0.1874  data_time: 0.0088  lr: 0.00048452  max_mem: 1812M
[32m[03/28 03:19:32 d2.utils.events]: [39m eta: 5:25:56  iter: 489  total_loss: 1.288  loss_cls: 0.6294  loss_box_reg: 0.4993  loss_rpn_cls: 0.09958  loss_rpn_loc: 0.04272  time: 0.1874  data_time: 0.0088  lr: 0.00048951  max_mem: 1812M
[32m[03/28 03:19:33 d2.utils.events]: [39m eta: 5:25:48  iter: 494  total_loss: 1.194  loss_cls: 0.5989  loss_box_reg: 0.4614  loss_rpn_cls: 0.08645  loss_rpn_loc: 0.0375  time: 0.1873  data_time: 0.0089  lr: 0.00049451  max_mem: 1812M
[32m[03/28 03:19:33 d2.utils.events]: [39m eta: 5:25:42  iter: 499  total_loss: 1.256  loss_cls: 0.5983  loss_box_reg: 0.4767  loss_rpn_cls: 0.0925  loss_rpn_loc: 0.04272  time: 0.1872  data_time: 0.0086  lr: 0.0004995  max_mem: 1812M
[32m[03/28 03:19:34 d2.utils.events]: [39m eta: 5:25:32  iter: 504  total_loss: 1.206  loss_cls: 0.5815  loss_box_reg: 0.4376  loss_rpn_cls: 0.0925  loss_rpn_loc: 0.04272  time: 0.1872  data_time: 0.0086  lr: 0.0005045  max_mem: 1812M
[32m[03/28 03:19:35 d2.utils.events]: [39m eta: 5:25:26  iter: 509  total_loss: 1.267  loss_cls: 0.5815  loss_box_reg: 0.4332  loss_rpn_cls: 0.08713  loss_rpn_loc: 0.05115  time: 0.1872  data_time: 0.0089  lr: 0.00050949  max_mem: 1812M
[32m[03/28 03:19:36 d2.utils.events]: [39m eta: 5:25:25  iter: 514  total_loss: 1.384  loss_cls: 0.6321  loss_box_reg: 0.5337  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.06161  time: 0.1872  data_time: 0.0095  lr: 0.00051449  max_mem: 1812M
[32m[03/28 03:19:37 d2.utils.events]: [39m eta: 5:25:27  iter: 519  total_loss: 1.201  loss_cls: 0.6106  loss_box_reg: 0.4217  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.04132  time: 0.1872  data_time: 0.0102  lr: 0.00051948  max_mem: 1812M
[32m[03/28 03:19:38 d2.utils.events]: [39m eta: 5:25:23  iter: 524  total_loss: 1.299  loss_cls: 0.633  loss_box_reg: 0.4525  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.04132  time: 0.1871  data_time: 0.0101  lr: 0.00052448  max_mem: 1812M
[32m[03/28 03:19:39 d2.utils.events]: [39m eta: 5:25:22  iter: 529  total_loss: 1.276  loss_cls: 0.6302  loss_box_reg: 0.451  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.04833  time: 0.1871  data_time: 0.0097  lr: 0.00052947  max_mem: 1812M
[32m[03/28 03:19:40 d2.utils.events]: [39m eta: 5:25:21  iter: 534  total_loss: 1.276  loss_cls: 0.6221  loss_box_reg: 0.4394  loss_rpn_cls: 0.109  loss_rpn_loc: 0.04213  time: 0.1870  data_time: 0.0091  lr: 0.00053447  max_mem: 1812M
[32m[03/28 03:19:41 d2.utils.events]: [39m eta: 5:25:20  iter: 539  total_loss: 1.276  loss_cls: 0.6146  loss_box_reg: 0.4394  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.04833  time: 0.1870  data_time: 0.0083  lr: 0.00053946  max_mem: 1812M
[32m[03/28 03:19:42 d2.utils.events]: [39m eta: 5:25:15  iter: 544  total_loss: 1.26  loss_cls: 0.6146  loss_box_reg: 0.4444  loss_rpn_cls: 0.103  loss_rpn_loc: 0.03666  time: 0.1870  data_time: 0.0083  lr: 0.00054446  max_mem: 1812M
[32m[03/28 03:19:43 d2.utils.events]: [39m eta: 5:25:04  iter: 549  total_loss: 1.271  loss_cls: 0.6248  loss_box_reg: 0.4444  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.03666  time: 0.1869  data_time: 0.0082  lr: 0.00054945  max_mem: 1812M
[32m[03/28 03:19:44 d2.utils.events]: [39m eta: 5:25:03  iter: 554  total_loss: 1.235  loss_cls: 0.6345  loss_box_reg: 0.4657  loss_rpn_cls: 0.09398  loss_rpn_loc: 0.03666  time: 0.1869  data_time: 0.0082  lr: 0.00055445  max_mem: 1812M
[32m[03/28 03:19:45 d2.utils.events]: [39m eta: 5:24:58  iter: 559  total_loss: 1.224  loss_cls: 0.6308  loss_box_reg: 0.4634  loss_rpn_cls: 0.08325  loss_rpn_loc: 0.02607  time: 0.1868  data_time: 0.0082  lr: 0.00055944  max_mem: 1812M
[32m[03/28 03:19:46 d2.utils.events]: [39m eta: 5:24:55  iter: 564  total_loss: 1.18  loss_cls: 0.6258  loss_box_reg: 0.4387  loss_rpn_cls: 0.07713  loss_rpn_loc: 0.02202  time: 0.1868  data_time: 0.0081  lr: 0.00056444  max_mem: 1812M
[32m[03/28 03:19:46 d2.utils.events]: [39m eta: 5:24:50  iter: 569  total_loss: 1.18  loss_cls: 0.6128  loss_box_reg: 0.4387  loss_rpn_cls: 0.07713  loss_rpn_loc: 0.02135  time: 0.1867  data_time: 0.0081  lr: 0.00056943  max_mem: 1812M
[32m[03/28 03:19:47 d2.utils.events]: [39m eta: 5:24:43  iter: 574  total_loss: 1.206  loss_cls: 0.6062  loss_box_reg: 0.4389  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.02941  time: 0.1867  data_time: 0.0081  lr: 0.00057443  max_mem: 1812M
[32m[03/28 03:19:48 d2.utils.events]: [39m eta: 5:24:40  iter: 579  total_loss: 1.211  loss_cls: 0.6009  loss_box_reg: 0.4531  loss_rpn_cls: 0.08922  loss_rpn_loc: 0.04482  time: 0.1866  data_time: 0.0081  lr: 0.00057942  max_mem: 1812M
[32m[03/28 03:19:49 d2.utils.events]: [39m eta: 5:24:34  iter: 584  total_loss: 1.249  loss_cls: 0.6042  loss_box_reg: 0.4769  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.04482  time: 0.1866  data_time: 0.0083  lr: 0.00058442  max_mem: 1812M
[32m[03/28 03:19:50 d2.utils.events]: [39m eta: 5:24:30  iter: 589  total_loss: 1.226  loss_cls: 0.6148  loss_box_reg: 0.4769  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.04063  time: 0.1865  data_time: 0.0084  lr: 0.00058941  max_mem: 1812M
[32m[03/28 03:19:51 d2.utils.events]: [39m eta: 5:24:28  iter: 594  total_loss: 1.157  loss_cls: 0.5953  loss_box_reg: 0.3975  loss_rpn_cls: 0.07683  loss_rpn_loc: 0.02995  time: 0.1865  data_time: 0.0083  lr: 0.00059441  max_mem: 1812M
[32m[03/28 03:19:52 d2.utils.events]: [39m eta: 5:24:14  iter: 599  total_loss: 1.151  loss_cls: 0.5989  loss_box_reg: 0.4486  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.02717  time: 0.1864  data_time: 0.0083  lr: 0.0005994  max_mem: 1812M
[32m[03/28 03:19:53 d2.utils.events]: [39m eta: 5:24:06  iter: 604  total_loss: 1.181  loss_cls: 0.6215  loss_box_reg: 0.4508  loss_rpn_cls: 0.05528  loss_rpn_loc: 0.02717  time: 0.1864  data_time: 0.0081  lr: 0.0006044  max_mem: 1812M
[32m[03/28 03:19:54 d2.utils.events]: [39m eta: 5:24:01  iter: 609  total_loss: 1.181  loss_cls: 0.6061  loss_box_reg: 0.4508  loss_rpn_cls: 0.0594  loss_rpn_loc: 0.03211  time: 0.1863  data_time: 0.0081  lr: 0.00060939  max_mem: 1812M
[32m[03/28 03:19:55 d2.utils.events]: [39m eta: 5:23:59  iter: 614  total_loss: 1.232  loss_cls: 0.6429  loss_box_reg: 0.4768  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.03468  time: 0.1863  data_time: 0.0081  lr: 0.00061439  max_mem: 1812M
[32m[03/28 03:19:56 d2.utils.events]: [39m eta: 5:23:51  iter: 619  total_loss: 1.154  loss_cls: 0.6379  loss_box_reg: 0.4395  loss_rpn_cls: 0.07892  loss_rpn_loc: 0.03374  time: 0.1862  data_time: 0.0081  lr: 0.00061938  max_mem: 1812M
[32m[03/28 03:19:56 d2.utils.events]: [39m eta: 5:23:48  iter: 624  total_loss: 1.154  loss_cls: 0.624  loss_box_reg: 0.4421  loss_rpn_cls: 0.08348  loss_rpn_loc: 0.03168  time: 0.1862  data_time: 0.0081  lr: 0.00062438  max_mem: 1812M
[32m[03/28 03:19:57 d2.utils.events]: [39m eta: 5:23:39  iter: 629  total_loss: 1.154  loss_cls: 0.644  loss_box_reg: 0.4421  loss_rpn_cls: 0.07892  loss_rpn_loc: 0.03128  time: 0.1861  data_time: 0.0081  lr: 0.00062937  max_mem: 1812M
[32m[03/28 03:19:58 d2.utils.events]: [39m eta: 5:23:31  iter: 634  total_loss: 1.159  loss_cls: 0.6251  loss_box_reg: 0.4132  loss_rpn_cls: 0.09035  loss_rpn_loc: 0.03374  time: 0.1861  data_time: 0.0081  lr: 0.00063437  max_mem: 1812M
[32m[03/28 03:19:59 d2.utils.events]: [39m eta: 5:23:28  iter: 639  total_loss: 1.199  loss_cls: 0.6637  loss_box_reg: 0.4397  loss_rpn_cls: 0.09204  loss_rpn_loc: 0.03372  time: 0.1860  data_time: 0.0081  lr: 0.00063936  max_mem: 1812M
[32m[03/28 03:20:00 d2.utils.events]: [39m eta: 5:23:24  iter: 644  total_loss: 1.198  loss_cls: 0.6418  loss_box_reg: 0.4479  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.03641  time: 0.1860  data_time: 0.0081  lr: 0.00064436  max_mem: 1812M
[32m[03/28 03:20:01 d2.utils.events]: [39m eta: 5:23:18  iter: 649  total_loss: 1.207  loss_cls: 0.6335  loss_box_reg: 0.4719  loss_rpn_cls: 0.08476  loss_rpn_loc: 0.03641  time: 0.1859  data_time: 0.0081  lr: 0.00064935  max_mem: 1812M
[32m[03/28 03:20:02 d2.utils.events]: [39m eta: 5:23:15  iter: 654  total_loss: 1.206  loss_cls: 0.6187  loss_box_reg: 0.4635  loss_rpn_cls: 0.06085  loss_rpn_loc: 0.02088  time: 0.1859  data_time: 0.0082  lr: 0.00065435  max_mem: 1812M
[32m[03/28 03:20:03 d2.utils.events]: [39m eta: 5:23:12  iter: 659  total_loss: 1.2  loss_cls: 0.5975  loss_box_reg: 0.4542  loss_rpn_cls: 0.06085  loss_rpn_loc: 0.02088  time: 0.1858  data_time: 0.0083  lr: 0.00065934  max_mem: 1812M
[32m[03/28 03:20:04 d2.utils.events]: [39m eta: 5:23:07  iter: 664  total_loss: 1.156  loss_cls: 0.5704  loss_box_reg: 0.4008  loss_rpn_cls: 0.06932  loss_rpn_loc: 0.01876  time: 0.1858  data_time: 0.0084  lr: 0.00066434  max_mem: 1812M
[32m[03/28 03:20:05 d2.utils.events]: [39m eta: 5:23:05  iter: 669  total_loss: 0.983  loss_cls: 0.5419  loss_box_reg: 0.3688  loss_rpn_cls: 0.05201  loss_rpn_loc: 0.01815  time: 0.1857  data_time: 0.0083  lr: 0.00066933  max_mem: 1812M
[32m[03/28 03:20:06 d2.utils.events]: [39m eta: 5:23:03  iter: 674  total_loss: 1.026  loss_cls: 0.5691  loss_box_reg: 0.3905  loss_rpn_cls: 0.05308  loss_rpn_loc: 0.01727  time: 0.1857  data_time: 0.0083  lr: 0.00067433  max_mem: 1812M
[32m[03/28 03:20:06 d2.utils.events]: [39m eta: 5:22:59  iter: 679  total_loss: 1.088  loss_cls: 0.5691  loss_box_reg: 0.4401  loss_rpn_cls: 0.05308  loss_rpn_loc: 0.0182  time: 0.1856  data_time: 0.0082  lr: 0.00067932  max_mem: 1812M
[32m[03/28 03:20:07 d2.utils.events]: [39m eta: 5:22:50  iter: 684  total_loss: 1.188  loss_cls: 0.6143  loss_box_reg: 0.4578  loss_rpn_cls: 0.06418  loss_rpn_loc: 0.02861  time: 0.1856  data_time: 0.0082  lr: 0.00068432  max_mem: 1812M
[32m[03/28 03:20:08 d2.utils.events]: [39m eta: 5:22:48  iter: 689  total_loss: 1.007  loss_cls: 0.5645  loss_box_reg: 0.3802  loss_rpn_cls: 0.08542  loss_rpn_loc: 0.02976  time: 0.1856  data_time: 0.0082  lr: 0.00068931  max_mem: 1812M
[32m[03/28 03:20:09 d2.utils.events]: [39m eta: 5:22:45  iter: 694  total_loss: 1.121  loss_cls: 0.5666  loss_box_reg: 0.3779  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.05319  time: 0.1856  data_time: 0.0082  lr: 0.00069431  max_mem: 1812M
[32m[03/28 03:20:10 d2.utils.events]: [39m eta: 5:22:46  iter: 699  total_loss: 1.086  loss_cls: 0.5616  loss_box_reg: 0.3682  loss_rpn_cls: 0.08998  loss_rpn_loc: 0.03519  time: 0.1856  data_time: 0.0083  lr: 0.0006993  max_mem: 1812M
[32m[03/28 03:20:11 d2.utils.events]: [39m eta: 5:22:54  iter: 704  total_loss: 1.144  loss_cls: 0.5794  loss_box_reg: 0.4025  loss_rpn_cls: 0.09078  loss_rpn_loc: 0.03802  time: 0.1856  data_time: 0.0083  lr: 0.0007043  max_mem: 1812M
[32m[03/28 03:20:12 d2.utils.events]: [39m eta: 5:22:55  iter: 709  total_loss: 1.24  loss_cls: 0.6039  loss_box_reg: 0.4459  loss_rpn_cls: 0.09995  loss_rpn_loc: 0.04757  time: 0.1857  data_time: 0.0088  lr: 0.00070929  max_mem: 1812M
[32m[03/28 03:20:13 d2.utils.events]: [39m eta: 5:22:53  iter: 714  total_loss: 1.122  loss_cls: 0.5882  loss_box_reg: 0.403  loss_rpn_cls: 0.07743  loss_rpn_loc: 0.02867  time: 0.1857  data_time: 0.0090  lr: 0.00071429  max_mem: 1812M
[32m[03/28 03:20:14 d2.utils.events]: [39m eta: 5:22:52  iter: 719  total_loss: 1.186  loss_cls: 0.5882  loss_box_reg: 0.41  loss_rpn_cls: 0.08848  loss_rpn_loc: 0.03369  time: 0.1857  data_time: 0.0091  lr: 0.00071928  max_mem: 1812M
[32m[03/28 03:20:15 d2.utils.events]: [39m eta: 5:22:51  iter: 724  total_loss: 1.047  loss_cls: 0.5667  loss_box_reg: 0.3747  loss_rpn_cls: 0.06457  loss_rpn_loc: 0.02153  time: 0.1857  data_time: 0.0092  lr: 0.00072428  max_mem: 1812M
[32m[03/28 03:20:16 d2.utils.events]: [39m eta: 5:22:48  iter: 729  total_loss: 1.001  loss_cls: 0.5299  loss_box_reg: 0.3562  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.0198  time: 0.1857  data_time: 0.0087  lr: 0.00072927  max_mem: 1812M
[32m[03/28 03:20:17 d2.utils.events]: [39m eta: 5:22:41  iter: 734  total_loss: 1.067  loss_cls: 0.5648  loss_box_reg: 0.3661  loss_rpn_cls: 0.0601  loss_rpn_loc: 0.02251  time: 0.1856  data_time: 0.0086  lr: 0.00073427  max_mem: 1812M
[32m[03/28 03:20:18 d2.utils.events]: [39m eta: 5:22:47  iter: 739  total_loss: 1.001  loss_cls: 0.5299  loss_box_reg: 0.3427  loss_rpn_cls: 0.05113  loss_rpn_loc: 0.02089  time: 0.1856  data_time: 0.0085  lr: 0.00073926  max_mem: 1812M
[32m[03/28 03:20:19 d2.utils.events]: [39m eta: 5:22:44  iter: 744  total_loss: 1.019  loss_cls: 0.5441  loss_box_reg: 0.3409  loss_rpn_cls: 0.06  loss_rpn_loc: 0.0264  time: 0.1856  data_time: 0.0085  lr: 0.00074426  max_mem: 1812M
[32m[03/28 03:20:20 d2.utils.events]: [39m eta: 5:22:32  iter: 749  total_loss: 1.091  loss_cls: 0.5918  loss_box_reg: 0.36  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.02729  time: 0.1856  data_time: 0.0084  lr: 0.00074925  max_mem: 1812M
[32m[03/28 03:20:21 d2.utils.events]: [39m eta: 5:22:28  iter: 754  total_loss: 1.103  loss_cls: 0.5918  loss_box_reg: 0.4008  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.02729  time: 0.1855  data_time: 0.0084  lr: 0.00075425  max_mem: 1812M
[32m[03/28 03:20:21 d2.utils.events]: [39m eta: 5:22:26  iter: 759  total_loss: 1.215  loss_cls: 0.6266  loss_box_reg: 0.4486  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.03669  time: 0.1855  data_time: 0.0084  lr: 0.00075924  max_mem: 1812M
[32m[03/28 03:20:22 d2.utils.events]: [39m eta: 5:22:25  iter: 764  total_loss: 1.143  loss_cls: 0.5983  loss_box_reg: 0.4197  loss_rpn_cls: 0.07134  loss_rpn_loc: 0.03033  time: 0.1855  data_time: 0.0083  lr: 0.00076424  max_mem: 1812M
[32m[03/28 03:20:23 d2.utils.events]: [39m eta: 5:22:25  iter: 769  total_loss: 1.035  loss_cls: 0.5629  loss_box_reg: 0.3855  loss_rpn_cls: 0.06289  loss_rpn_loc: 0.02371  time: 0.1855  data_time: 0.0084  lr: 0.00076923  max_mem: 1812M
[32m[03/28 03:20:24 d2.utils.events]: [39m eta: 5:22:23  iter: 774  total_loss: 1.076  loss_cls: 0.565  loss_box_reg: 0.4047  loss_rpn_cls: 0.06093  loss_rpn_loc: 0.02937  time: 0.1855  data_time: 0.0084  lr: 0.00077423  max_mem: 1812M
[32m[03/28 03:20:25 d2.utils.events]: [39m eta: 5:22:22  iter: 779  total_loss: 1.068  loss_cls: 0.565  loss_box_reg: 0.4018  loss_rpn_cls: 0.06334  loss_rpn_loc: 0.02835  time: 0.1855  data_time: 0.0083  lr: 0.00077922  max_mem: 1812M
[32m[03/28 03:20:26 d2.utils.events]: [39m eta: 5:22:22  iter: 784  total_loss: 1.152  loss_cls: 0.5931  loss_box_reg: 0.4271  loss_rpn_cls: 0.08033  loss_rpn_loc: 0.03342  time: 0.1854  data_time: 0.0084  lr: 0.00078422  max_mem: 1812M
[32m[03/28 03:20:27 d2.utils.events]: [39m eta: 5:22:25  iter: 789  total_loss: 1.192  loss_cls: 0.6365  loss_box_reg: 0.4404  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.05091  time: 0.1854  data_time: 0.0084  lr: 0.00078921  max_mem: 1812M
[32m[03/28 03:20:28 d2.utils.events]: [39m eta: 5:22:20  iter: 794  total_loss: 1.192  loss_cls: 0.6275  loss_box_reg: 0.4264  loss_rpn_cls: 0.09733  loss_rpn_loc: 0.04992  time: 0.1854  data_time: 0.0084  lr: 0.00079421  max_mem: 1812M
[32m[03/28 03:20:29 d2.utils.events]: [39m eta: 5:22:18  iter: 799  total_loss: 1.226  loss_cls: 0.5951  loss_box_reg: 0.4463  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.04792  time: 0.1854  data_time: 0.0084  lr: 0.0007992  max_mem: 1812M
[32m[03/28 03:20:30 d2.utils.events]: [39m eta: 5:22:16  iter: 804  total_loss: 1.218  loss_cls: 0.6133  loss_box_reg: 0.4219  loss_rpn_cls: 0.08925  loss_rpn_loc: 0.02299  time: 0.1853  data_time: 0.0083  lr: 0.0008042  max_mem: 1812M
[32m[03/28 03:20:31 d2.utils.events]: [39m eta: 5:22:16  iter: 809  total_loss: 1.021  loss_cls: 0.5271  loss_box_reg: 0.3634  loss_rpn_cls: 0.05391  loss_rpn_loc: 0.01896  time: 0.1853  data_time: 0.0087  lr: 0.00080919  max_mem: 1812M
[32m[03/28 03:20:32 d2.utils.events]: [39m eta: 5:22:17  iter: 814  total_loss: 1.025  loss_cls: 0.5517  loss_box_reg: 0.3634  loss_rpn_cls: 0.05391  loss_rpn_loc: 0.02044  time: 0.1853  data_time: 0.0088  lr: 0.00081419  max_mem: 1812M
[32m[03/28 03:20:33 d2.utils.events]: [39m eta: 5:22:19  iter: 819  total_loss: 0.962  loss_cls: 0.5332  loss_box_reg: 0.3262  loss_rpn_cls: 0.0492  loss_rpn_loc: 0.02044  time: 0.1854  data_time: 0.0089  lr: 0.00081918  max_mem: 1812M
[32m[03/28 03:20:33 d2.utils.events]: [39m eta: 5:22:22  iter: 824  total_loss: 1.008  loss_cls: 0.55  loss_box_reg: 0.3387  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.02296  time: 0.1853  data_time: 0.0089  lr: 0.00082418  max_mem: 1812M
[32m[03/28 03:20:34 d2.utils.events]: [39m eta: 5:22:26  iter: 829  total_loss: 1.038  loss_cls: 0.5606  loss_box_reg: 0.3461  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.02864  time: 0.1853  data_time: 0.0085  lr: 0.00082917  max_mem: 1812M
[32m[03/28 03:20:35 d2.utils.events]: [39m eta: 5:22:22  iter: 834  total_loss: 1.149  loss_cls: 0.5804  loss_box_reg: 0.3993  loss_rpn_cls: 0.07841  loss_rpn_loc: 0.0317  time: 0.1853  data_time: 0.0085  lr: 0.00083417  max_mem: 1812M
[32m[03/28 03:20:36 d2.utils.events]: [39m eta: 5:22:28  iter: 839  total_loss: 1.198  loss_cls: 0.6303  loss_box_reg: 0.414  loss_rpn_cls: 0.08491  loss_rpn_loc: 0.03602  time: 0.1853  data_time: 0.0085  lr: 0.00083916  max_mem: 1812M
[32m[03/28 03:20:37 d2.utils.events]: [39m eta: 5:22:30  iter: 844  total_loss: 1.208  loss_cls: 0.6466  loss_box_reg: 0.4217  loss_rpn_cls: 0.07657  loss_rpn_loc: 0.0404  time: 0.1853  data_time: 0.0096  lr: 0.00084416  max_mem: 1812M
[32m[03/28 03:20:38 d2.utils.events]: [39m eta: 5:22:30  iter: 849  total_loss: 1.208  loss_cls: 0.6502  loss_box_reg: 0.44  loss_rpn_cls: 0.08135  loss_rpn_loc: 0.0436  time: 0.1853  data_time: 0.0097  lr: 0.00084915  max_mem: 1812M
[32m[03/28 03:20:39 d2.utils.events]: [39m eta: 5:22:30  iter: 854  total_loss: 1.272  loss_cls: 0.6646  loss_box_reg: 0.4351  loss_rpn_cls: 0.08189  loss_rpn_loc: 0.04678  time: 0.1853  data_time: 0.0097  lr: 0.00085415  max_mem: 1812M
[32m[03/28 03:20:40 d2.utils.events]: [39m eta: 5:22:29  iter: 859  total_loss: 1.332  loss_cls: 0.6646  loss_box_reg: 0.4351  loss_rpn_cls: 0.08163  loss_rpn_loc: 0.05122  time: 0.1853  data_time: 0.0097  lr: 0.00085914  max_mem: 1812M
[32m[03/28 03:20:41 d2.utils.events]: [39m eta: 5:22:29  iter: 864  total_loss: 1.323  loss_cls: 0.6821  loss_box_reg: 0.4228  loss_rpn_cls: 0.08163  loss_rpn_loc: 0.05029  time: 0.1853  data_time: 0.0086  lr: 0.00086414  max_mem: 1812M
[32m[03/28 03:20:42 d2.utils.events]: [39m eta: 5:22:28  iter: 869  total_loss: 1.356  loss_cls: 0.724  loss_box_reg: 0.4585  loss_rpn_cls: 0.08395  loss_rpn_loc: 0.05704  time: 0.1853  data_time: 0.0085  lr: 0.00086913  max_mem: 1812M
[32m[03/28 03:20:43 d2.utils.events]: [39m eta: 5:22:28  iter: 874  total_loss: 1.347  loss_cls: 0.6566  loss_box_reg: 0.4384  loss_rpn_cls: 0.08395  loss_rpn_loc: 0.04329  time: 0.1853  data_time: 0.0086  lr: 0.00087413  max_mem: 1812M
[32m[03/28 03:20:44 d2.utils.events]: [39m eta: 5:22:27  iter: 879  total_loss: 1.248  loss_cls: 0.6302  loss_box_reg: 0.4586  loss_rpn_cls: 0.08603  loss_rpn_loc: 0.03586  time: 0.1853  data_time: 0.0086  lr: 0.00087912  max_mem: 1812M
[32m[03/28 03:20:45 d2.utils.events]: [39m eta: 5:22:27  iter: 884  total_loss: 1.236  loss_cls: 0.6144  loss_box_reg: 0.4697  loss_rpn_cls: 0.08701  loss_rpn_loc: 0.02984  time: 0.1853  data_time: 0.0086  lr: 0.00088412  max_mem: 1812M
[32m[03/28 03:20:46 d2.utils.events]: [39m eta: 5:22:27  iter: 889  total_loss: 1.17  loss_cls: 0.5904  loss_box_reg: 0.3876  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.02984  time: 0.1853  data_time: 0.0085  lr: 0.00088911  max_mem: 1812M
[32m[03/28 03:20:47 d2.utils.events]: [39m eta: 5:22:26  iter: 894  total_loss: 1.184  loss_cls: 0.5749  loss_box_reg: 0.4122  loss_rpn_cls: 0.0856  loss_rpn_loc: 0.03218  time: 0.1853  data_time: 0.0085  lr: 0.00089411  max_mem: 1812M
[32m[03/28 03:20:47 d2.utils.events]: [39m eta: 5:22:25  iter: 899  total_loss: 1.184  loss_cls: 0.5815  loss_box_reg: 0.3858  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.03218  time: 0.1853  data_time: 0.0085  lr: 0.0008991  max_mem: 1812M
[32m[03/28 03:20:48 d2.utils.events]: [39m eta: 5:22:24  iter: 904  total_loss: 1.193  loss_cls: 0.5949  loss_box_reg: 0.3878  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.03142  time: 0.1853  data_time: 0.0085  lr: 0.0009041  max_mem: 1812M
[32m[03/28 03:20:49 d2.utils.events]: [39m eta: 5:22:24  iter: 909  total_loss: 1.239  loss_cls: 0.5949  loss_box_reg: 0.4405  loss_rpn_cls: 0.08949  loss_rpn_loc: 0.03142  time: 0.1852  data_time: 0.0086  lr: 0.00090909  max_mem: 1812M
[32m[03/28 03:20:50 d2.utils.events]: [39m eta: 5:22:22  iter: 914  total_loss: 1.148  loss_cls: 0.5817  loss_box_reg: 0.4164  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.02833  time: 0.1852  data_time: 0.0084  lr: 0.00091409  max_mem: 1812M
[32m[03/28 03:20:51 d2.utils.events]: [39m eta: 5:22:21  iter: 919  total_loss: 1.143  loss_cls: 0.6006  loss_box_reg: 0.4279  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.02847  time: 0.1852  data_time: 0.0084  lr: 0.00091908  max_mem: 1812M
[32m[03/28 03:20:52 d2.utils.events]: [39m eta: 5:22:21  iter: 924  total_loss: 1.083  loss_cls: 0.5708  loss_box_reg: 0.4279  loss_rpn_cls: 0.0831  loss_rpn_loc: 0.03264  time: 0.1852  data_time: 0.0084  lr: 0.00092408  max_mem: 1812M
[32m[03/28 03:20:53 d2.utils.events]: [39m eta: 5:22:19  iter: 929  total_loss: 1.083  loss_cls: 0.5708  loss_box_reg: 0.3943  loss_rpn_cls: 0.06373  loss_rpn_loc: 0.03217  time: 0.1852  data_time: 0.0083  lr: 0.00092907  max_mem: 1812M
[32m[03/28 03:20:54 d2.utils.events]: [39m eta: 5:22:18  iter: 934  total_loss: 1.083  loss_cls: 0.5601  loss_box_reg: 0.3966  loss_rpn_cls: 0.06373  loss_rpn_loc: 0.03264  time: 0.1852  data_time: 0.0083  lr: 0.00093407  max_mem: 1812M
[32m[03/28 03:20:55 d2.utils.events]: [39m eta: 5:22:18  iter: 939  total_loss: 1.093  loss_cls: 0.5601  loss_box_reg: 0.3914  loss_rpn_cls: 0.08032  loss_rpn_loc: 0.03861  time: 0.1853  data_time: 0.0089  lr: 0.00093906  max_mem: 1812M
[32m[03/28 03:20:56 d2.utils.events]: [39m eta: 5:22:19  iter: 944  total_loss: 1.224  loss_cls: 0.5806  loss_box_reg: 0.4386  loss_rpn_cls: 0.07846  loss_rpn_loc: 0.03206  time: 0.1853  data_time: 0.0092  lr: 0.00094406  max_mem: 1812M
[32m[03/28 03:20:57 d2.utils.events]: [39m eta: 5:22:17  iter: 949  total_loss: 1.172  loss_cls: 0.5537  loss_box_reg: 0.4221  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.0344  time: 0.1853  data_time: 0.0093  lr: 0.00094905  max_mem: 1812M
[32m[03/28 03:20:58 d2.utils.events]: [39m eta: 5:22:16  iter: 954  total_loss: 1.267  loss_cls: 0.6149  loss_box_reg: 0.4221  loss_rpn_cls: 0.072  loss_rpn_loc: 0.0344  time: 0.1853  data_time: 0.0094  lr: 0.00095405  max_mem: 1812M
[32m[03/28 03:20:59 d2.utils.events]: [39m eta: 5:22:18  iter: 959  total_loss: 1.158  loss_cls: 0.6138  loss_box_reg: 0.3529  loss_rpn_cls: 0.072  loss_rpn_loc: 0.03814  time: 0.1853  data_time: 0.0115  lr: 0.00095904  max_mem: 1812M
[32m[03/28 03:21:00 d2.utils.events]: [39m eta: 5:22:16  iter: 964  total_loss: 1.241  loss_cls: 0.6442  loss_box_reg: 0.3638  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.04001  time: 0.1853  data_time: 0.0115  lr: 0.00096404  max_mem: 1812M
[32m[03/28 03:21:01 d2.utils.events]: [39m eta: 5:22:15  iter: 969  total_loss: 1.289  loss_cls: 0.6452  loss_box_reg: 0.4893  loss_rpn_cls: 0.08589  loss_rpn_loc: 0.04001  time: 0.1853  data_time: 0.0117  lr: 0.00096903  max_mem: 1812M
[32m[03/28 03:21:02 d2.utils.events]: [39m eta: 5:22:13  iter: 974  total_loss: 1.302  loss_cls: 0.6542  loss_box_reg: 0.4959  loss_rpn_cls: 0.092  loss_rpn_loc: 0.04971  time: 0.1853  data_time: 0.0116  lr: 0.00097403  max_mem: 1812M
[32m[03/28 03:21:03 d2.utils.events]: [39m eta: 5:22:13  iter: 979  total_loss: 1.292  loss_cls: 0.6259  loss_box_reg: 0.4823  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.0353  time: 0.1853  data_time: 0.0092  lr: 0.00097902  max_mem: 1812M
[32m[03/28 03:21:04 d2.utils.events]: [39m eta: 5:22:14  iter: 984  total_loss: 1.292  loss_cls: 0.6402  loss_box_reg: 0.4823  loss_rpn_cls: 0.108  loss_rpn_loc: 0.04003  time: 0.1854  data_time: 0.0098  lr: 0.00098402  max_mem: 1812M
[32m[03/28 03:21:05 d2.utils.events]: [39m eta: 5:22:15  iter: 989  total_loss: 1.213  loss_cls: 0.6424  loss_box_reg: 0.4277  loss_rpn_cls: 0.08414  loss_rpn_loc: 0.04316  time: 0.1855  data_time: 0.0096  lr: 0.00098901  max_mem: 1812M
[32m[03/28 03:21:06 d2.utils.events]: [39m eta: 5:22:17  iter: 994  total_loss: 1.141  loss_cls: 0.6004  loss_box_reg: 0.4161  loss_rpn_cls: 0.08222  loss_rpn_loc: 0.03875  time: 0.1856  data_time: 0.0097  lr: 0.00099401  max_mem: 1812M
[32m[03/28 03:21:07 d2.utils.events]: [39m eta: 5:22:19  iter: 999  total_loss: 1.126  loss_cls: 0.615  loss_box_reg: 0.4098  loss_rpn_cls: 0.08092  loss_rpn_loc: 0.0388  time: 0.1857  data_time: 0.0097  lr: 0.000999  max_mem: 1812M
[32m[03/28 03:21:08 d2.utils.events]: [39m eta: 5:22:15  iter: 1004  total_loss: 0.9925  loss_cls: 0.5121  loss_box_reg: 0.3505  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.03678  time: 0.1857  data_time: 0.0087  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:08 d2.utils.events]: [39m eta: 5:22:13  iter: 1009  total_loss: 0.9426  loss_cls: 0.5121  loss_box_reg: 0.3293  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.02871  time: 0.1856  data_time: 0.0086  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:09 d2.utils.events]: [39m eta: 5:22:10  iter: 1014  total_loss: 0.9584  loss_cls: 0.5431  loss_box_reg: 0.3203  loss_rpn_cls: 0.05422  loss_rpn_loc: 0.0178  time: 0.1856  data_time: 0.0087  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:10 d2.utils.events]: [39m eta: 5:22:08  iter: 1019  total_loss: 0.9809  loss_cls: 0.5431  loss_box_reg: 0.3203  loss_rpn_cls: 0.05692  loss_rpn_loc: 0.02237  time: 0.1856  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:11 d2.utils.events]: [39m eta: 5:22:04  iter: 1024  total_loss: 0.9193  loss_cls: 0.5522  loss_box_reg: 0.3189  loss_rpn_cls: 0.06204  loss_rpn_loc: 0.02366  time: 0.1856  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:12 d2.utils.events]: [39m eta: 5:22:00  iter: 1029  total_loss: 0.9718  loss_cls: 0.5534  loss_box_reg: 0.3349  loss_rpn_cls: 0.06038  loss_rpn_loc: 0.02422  time: 0.1856  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:13 d2.utils.events]: [39m eta: 5:21:59  iter: 1034  total_loss: 1.002  loss_cls: 0.56  loss_box_reg: 0.3644  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.028  time: 0.1856  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:14 d2.utils.events]: [39m eta: 5:21:58  iter: 1039  total_loss: 1.001  loss_cls: 0.56  loss_box_reg: 0.3876  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.028  time: 0.1856  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:15 d2.utils.events]: [39m eta: 5:21:56  iter: 1044  total_loss: 1.05  loss_cls: 0.5705  loss_box_reg: 0.3885  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.03604  time: 0.1856  data_time: 0.0082  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:16 d2.utils.events]: [39m eta: 5:21:55  iter: 1049  total_loss: 0.9794  loss_cls: 0.5103  loss_box_reg: 0.3876  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.02679  time: 0.1856  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:17 d2.utils.events]: [39m eta: 5:21:51  iter: 1054  total_loss: 0.9399  loss_cls: 0.4989  loss_box_reg: 0.3841  loss_rpn_cls: 0.06389  loss_rpn_loc: 0.02292  time: 0.1856  data_time: 0.0085  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:18 d2.utils.events]: [39m eta: 5:21:50  iter: 1059  total_loss: 0.9356  loss_cls: 0.5268  loss_box_reg: 0.3684  loss_rpn_cls: 0.0447  loss_rpn_loc: 0.01725  time: 0.1855  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:19 d2.utils.events]: [39m eta: 5:21:48  iter: 1064  total_loss: 0.9879  loss_cls: 0.5286  loss_box_reg: 0.4206  loss_rpn_cls: 0.0447  loss_rpn_loc: 0.02753  time: 0.1855  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:21 d2.data.datasets.coco]: [39mLoaded 603 images in COCO format from ../../dataset/SK_val_annotations.json
[32m[03/28 03:21:21 d2.data.build]: [39mDistribution of instances among all 10 categories:
[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |
[36m|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|
[36m| General trash | 498          |    Paper    | 841          | Paper pack | 97           |
[36m|     Metal     | 109          |    Glass    | 82           |  Plastic   | 352          |
[36m|   Styrofoam   | 123          | Plastic bag | 615          |  Battery   | 11           |
[36m|   Clothing    | 52           |             |              |            |              |
[36m|     total     | 2780         |             |              |            |              |
[32m[03/28 03:21:21 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/28 03:21:21 d2.data.common]: [39mSerializing 603 elements to byte tensors and concatenating them all ...
[32m[03/28 03:21:21 d2.data.common]: [39mSerialized dataset takes 0.27 MiB
[31m[5mWARNING[39m[25m [32m[03/28 03:21:21 d2.evaluation.coco_evaluation]: [39mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[03/28 03:21:21 d2.evaluation.evaluator]: [39mStart inference on 603 batches
[32m[03/28 03:21:22 d2.evaluation.evaluator]: [39mInference done 11/603. Dataloading: 0.0010 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:00:27
[32m[03/28 03:21:27 d2.evaluation.evaluator]: [39mInference done 118/603. Dataloading: 0.0011 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:00:22
[32m[03/28 03:21:32 d2.evaluation.evaluator]: [39mInference done 224/603. Dataloading: 0.0011 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:00:17
[32m[03/28 03:21:37 d2.evaluation.evaluator]: [39mInference done 330/603. Dataloading: 0.0011 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:00:12
[32m[03/28 03:21:42 d2.evaluation.evaluator]: [39mInference done 436/603. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:07
[32m[03/28 03:21:47 d2.evaluation.evaluator]: [39mInference done 541/603. Dataloading: 0.0012 s/iter. Inference: 0.0458 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:02
[32m[03/28 03:21:50 d2.evaluation.evaluator]: [39mTotal inference time: 0:00:28.488422 (0.047640 s / iter per device, on 1 devices)
[32m[03/28 03:21:50 d2.evaluation.evaluator]: [39mTotal inference pure compute time: 0:00:27 (0.046024 s / iter per device, on 1 devices)
[32m[03/28 03:21:50 d2.evaluation.coco_evaluation]: [39mPreparing results for COCO format ...
[32m[03/28 03:21:50 d2.evaluation.coco_evaluation]: [39mSaving results to ./output_eval/coco_instances_results.json
[32m[03/28 03:21:51 d2.evaluation.coco_evaluation]: [39mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.18s)
creating index...
index created!
[32m[03/28 03:21:51 d2.evaluation.fast_eval_api]: [39mEvaluate annotation type *bbox*
[32m[03/28 03:21:51 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.evaluate() finished in 0.46 seconds.
[32m[03/28 03:21:51 d2.evaluation.fast_eval_api]: [39mAccumulating evaluation results...
[32m[03/28 03:21:52 d2.evaluation.fast_eval_api]: [39mCOCOeval_opt.accumulate() finished in 0.16 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437
[32m[03/28 03:21:52 d2.evaluation.coco_evaluation]: [39mEvaluation results for bbox:
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 10.841 | 18.133 | 12.049 | 0.000 | 0.577 | 13.289 |
[32m[03/28 03:21:52 d2.evaluation.coco_evaluation]: [39mPer-category bbox AP:
| category      | AP    | category    | AP     | category   | AP     |
|:--------------|:------|:------------|:-------|:-----------|:-------|
| General trash | 3.133 | Paper       | 8.992  | Paper pack | 11.812 |
| Metal         | 6.778 | Glass       | 6.205  | Plastic    | 5.930  |
| Styrofoam     | 6.612 | Plastic bag | 17.848 | Battery    | 33.371 |
| Clothing      | 7.725 |             |        |            |        |
[32m[03/28 03:21:52 d2.engine.defaults]: [39mEvaluation results for coco_trash_test in csv format:
[32m[03/28 03:21:52 d2.evaluation.testing]: [39mcopypaste: Task: bbox
[32m[03/28 03:21:52 d2.evaluation.testing]: [39mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/28 03:21:52 d2.evaluation.testing]: [39mcopypaste: 10.8406,18.1326,12.0489,0.0000,0.5774,13.2889
[32m[03/28 03:21:52 d2.utils.events]: [39m eta: 5:21:42  iter: 1069  total_loss: 0.9699  loss_cls: 0.5255  loss_box_reg: 0.3926  loss_rpn_cls: 0.05112  loss_rpn_loc: 0.02429  time: 0.1855  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:53 d2.utils.events]: [39m eta: 5:21:41  iter: 1074  total_loss: 0.9699  loss_cls: 0.5338  loss_box_reg: 0.3999  loss_rpn_cls: 0.04538  loss_rpn_loc: 0.02429  time: 0.1855  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:54 d2.utils.events]: [39m eta: 5:21:40  iter: 1079  total_loss: 0.9967  loss_cls: 0.5203  loss_box_reg: 0.4052  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.02518  time: 0.1855  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:54 d2.utils.events]: [39m eta: 5:21:35  iter: 1084  total_loss: 0.9547  loss_cls: 0.4968  loss_box_reg: 0.3559  loss_rpn_cls: 0.0494  loss_rpn_loc: 0.02518  time: 0.1855  data_time: 0.0085  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:55 d2.utils.events]: [39m eta: 5:21:33  iter: 1089  total_loss: 0.9972  loss_cls: 0.5211  loss_box_reg: 0.4004  loss_rpn_cls: 0.04805  loss_rpn_loc: 0.02819  time: 0.1855  data_time: 0.0086  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:56 d2.utils.events]: [39m eta: 5:21:24  iter: 1094  total_loss: 1.094  loss_cls: 0.5598  loss_box_reg: 0.4346  loss_rpn_cls: 0.05642  loss_rpn_loc: 0.03161  time: 0.1855  data_time: 0.0085  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:57 d2.utils.events]: [39m eta: 5:21:19  iter: 1099  total_loss: 1.06  loss_cls: 0.5533  loss_box_reg: 0.424  loss_rpn_cls: 0.04511  loss_rpn_loc: 0.02768  time: 0.1855  data_time: 0.0085  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:58 d2.utils.events]: [39m eta: 5:21:17  iter: 1104  total_loss: 1.114  loss_cls: 0.581  loss_box_reg: 0.4316  loss_rpn_cls: 0.05195  loss_rpn_loc: 0.02768  time: 0.1855  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:21:59 d2.utils.events]: [39m eta: 5:21:13  iter: 1109  total_loss: 1.114  loss_cls: 0.5965  loss_box_reg: 0.4079  loss_rpn_cls: 0.059  loss_rpn_loc: 0.02483  time: 0.1854  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:00 d2.utils.events]: [39m eta: 5:21:08  iter: 1114  total_loss: 1.045  loss_cls: 0.553  loss_box_reg: 0.3698  loss_rpn_cls: 0.05142  loss_rpn_loc: 0.02261  time: 0.1854  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:01 d2.utils.events]: [39m eta: 5:21:02  iter: 1119  total_loss: 0.9901  loss_cls: 0.498  loss_box_reg: 0.3698  loss_rpn_cls: 0.04936  loss_rpn_loc: 0.02228  time: 0.1854  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:02 d2.utils.events]: [39m eta: 5:20:56  iter: 1124  total_loss: 0.887  loss_cls: 0.469  loss_box_reg: 0.3588  loss_rpn_cls: 0.04936  loss_rpn_loc: 0.01782  time: 0.1854  data_time: 0.0090  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:03 d2.utils.events]: [39m eta: 5:20:54  iter: 1129  total_loss: 0.8658  loss_cls: 0.4728  loss_box_reg: 0.375  loss_rpn_cls: 0.04127  loss_rpn_loc: 0.02037  time: 0.1854  data_time: 0.0091  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:04 d2.utils.events]: [39m eta: 5:20:50  iter: 1134  total_loss: 0.9663  loss_cls: 0.5018  loss_box_reg: 0.3666  loss_rpn_cls: 0.05614  loss_rpn_loc: 0.03846  time: 0.1853  data_time: 0.0093  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:05 d2.utils.events]: [39m eta: 5:20:48  iter: 1139  total_loss: 1.133  loss_cls: 0.5693  loss_box_reg: 0.3666  loss_rpn_cls: 0.09987  loss_rpn_loc: 0.04428  time: 0.1853  data_time: 0.0093  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:05 d2.utils.events]: [39m eta: 5:20:45  iter: 1144  total_loss: 1.135  loss_cls: 0.5686  loss_box_reg: 0.3272  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.05286  time: 0.1853  data_time: 0.0086  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:06 d2.utils.events]: [39m eta: 5:20:42  iter: 1149  total_loss: 1.168  loss_cls: 0.5686  loss_box_reg: 0.3627  loss_rpn_cls: 0.1251  loss_rpn_loc: 0.05286  time: 0.1853  data_time: 0.0086  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:07 d2.utils.events]: [39m eta: 5:20:39  iter: 1154  total_loss: 1.168  loss_cls: 0.5686  loss_box_reg: 0.4042  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.04262  time: 0.1853  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:08 d2.utils.events]: [39m eta: 5:20:38  iter: 1159  total_loss: 1.082  loss_cls: 0.5066  loss_box_reg: 0.3936  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.0347  time: 0.1853  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:09 d2.utils.events]: [39m eta: 5:20:35  iter: 1164  total_loss: 1.032  loss_cls: 0.5066  loss_box_reg: 0.3936  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.03208  time: 0.1853  data_time: 0.0087  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:10 d2.utils.events]: [39m eta: 5:20:34  iter: 1169  total_loss: 1.086  loss_cls: 0.5162  loss_box_reg: 0.3968  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.03054  time: 0.1854  data_time: 0.0120  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:11 d2.utils.events]: [39m eta: 5:20:36  iter: 1174  total_loss: 1.092  loss_cls: 0.5162  loss_box_reg: 0.3685  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.03403  time: 0.1854  data_time: 0.0127  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:12 d2.utils.events]: [39m eta: 5:20:36  iter: 1179  total_loss: 1.082  loss_cls: 0.5162  loss_box_reg: 0.3685  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.04234  time: 0.1854  data_time: 0.0129  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:13 d2.utils.events]: [39m eta: 5:20:34  iter: 1184  total_loss: 1.082  loss_cls: 0.5196  loss_box_reg: 0.3408  loss_rpn_cls: 0.06907  loss_rpn_loc: 0.0299  time: 0.1854  data_time: 0.0126  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:14 d2.utils.events]: [39m eta: 5:20:34  iter: 1189  total_loss: 1.018  loss_cls: 0.5182  loss_box_reg: 0.3279  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.02426  time: 0.1854  data_time: 0.0104  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:15 d2.utils.events]: [39m eta: 5:20:33  iter: 1194  total_loss: 0.9704  loss_cls: 0.5182  loss_box_reg: 0.3645  loss_rpn_cls: 0.05298  loss_rpn_loc: 0.02267  time: 0.1854  data_time: 0.0099  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:16 d2.utils.events]: [39m eta: 5:20:32  iter: 1199  total_loss: 1.003  loss_cls: 0.5515  loss_box_reg: 0.3864  loss_rpn_cls: 0.06473  loss_rpn_loc: 0.02267  time: 0.1855  data_time: 0.0105  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:17 d2.utils.events]: [39m eta: 5:20:32  iter: 1204  total_loss: 1.031  loss_cls: 0.5515  loss_box_reg: 0.3881  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.02131  time: 0.1855  data_time: 0.0105  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:18 d2.utils.events]: [39m eta: 5:20:31  iter: 1209  total_loss: 1.01  loss_cls: 0.5268  loss_box_reg: 0.3864  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.02958  time: 0.1855  data_time: 0.0097  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:19 d2.utils.events]: [39m eta: 5:20:31  iter: 1214  total_loss: 0.9973  loss_cls: 0.5375  loss_box_reg: 0.3665  loss_rpn_cls: 0.07157  loss_rpn_loc: 0.02845  time: 0.1855  data_time: 0.0114  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:20 d2.utils.events]: [39m eta: 5:20:31  iter: 1219  total_loss: 0.9217  loss_cls: 0.4653  loss_box_reg: 0.3176  loss_rpn_cls: 0.06164  loss_rpn_loc: 0.02465  time: 0.1855  data_time: 0.0108  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:21 d2.utils.events]: [39m eta: 5:20:29  iter: 1224  total_loss: 0.9296  loss_cls: 0.5045  loss_box_reg: 0.3176  loss_rpn_cls: 0.05294  loss_rpn_loc: 0.02845  time: 0.1855  data_time: 0.0108  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:22 d2.utils.events]: [39m eta: 5:20:28  iter: 1229  total_loss: 0.9236  loss_cls: 0.5066  loss_box_reg: 0.3011  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.02488  time: 0.1855  data_time: 0.0105  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:23 d2.utils.events]: [39m eta: 5:20:27  iter: 1234  total_loss: 0.871  loss_cls: 0.4805  loss_box_reg: 0.3384  loss_rpn_cls: 0.06058  loss_rpn_loc: 0.03028  time: 0.1855  data_time: 0.0088  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:23 d2.utils.events]: [39m eta: 5:20:25  iter: 1239  total_loss: 0.9907  loss_cls: 0.5327  loss_box_reg: 0.3665  loss_rpn_cls: 0.06058  loss_rpn_loc: 0.03122  time: 0.1855  data_time: 0.0087  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:24 d2.utils.events]: [39m eta: 5:20:24  iter: 1244  total_loss: 1.024  loss_cls: 0.5446  loss_box_reg: 0.3702  loss_rpn_cls: 0.06341  loss_rpn_loc: 0.03456  time: 0.1855  data_time: 0.0087  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:25 d2.utils.events]: [39m eta: 5:20:24  iter: 1249  total_loss: 1.084  loss_cls: 0.5686  loss_box_reg: 0.381  loss_rpn_cls: 0.0651  loss_rpn_loc: 0.03456  time: 0.1855  data_time: 0.0088  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:26 d2.utils.events]: [39m eta: 5:20:26  iter: 1254  total_loss: 1.084  loss_cls: 0.582  loss_box_reg: 0.3592  loss_rpn_cls: 0.06135  loss_rpn_loc: 0.0219  time: 0.1855  data_time: 0.0089  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:27 d2.utils.events]: [39m eta: 5:20:27  iter: 1259  total_loss: 1.114  loss_cls: 0.582  loss_box_reg: 0.365  loss_rpn_cls: 0.07495  loss_rpn_loc: 0.03524  time: 0.1855  data_time: 0.0089  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:28 d2.utils.events]: [39m eta: 5:20:26  iter: 1264  total_loss: 1.114  loss_cls: 0.5944  loss_box_reg: 0.4107  loss_rpn_cls: 0.08817  loss_rpn_loc: 0.04273  time: 0.1855  data_time: 0.0089  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:29 d2.utils.events]: [39m eta: 5:20:25  iter: 1269  total_loss: 1.027  loss_cls: 0.5589  loss_box_reg: 0.3495  loss_rpn_cls: 0.0913  loss_rpn_loc: 0.03593  time: 0.1855  data_time: 0.0095  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:30 d2.utils.events]: [39m eta: 5:20:25  iter: 1274  total_loss: 1.027  loss_cls: 0.5393  loss_box_reg: 0.3495  loss_rpn_cls: 0.08905  loss_rpn_loc: 0.03593  time: 0.1855  data_time: 0.0099  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:31 d2.utils.events]: [39m eta: 5:20:22  iter: 1279  total_loss: 1.013  loss_cls: 0.5334  loss_box_reg: 0.3489  loss_rpn_cls: 0.08905  loss_rpn_loc: 0.03852  time: 0.1855  data_time: 0.0099  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:32 d2.utils.events]: [39m eta: 5:20:22  iter: 1284  total_loss: 0.9895  loss_cls: 0.5238  loss_box_reg: 0.3373  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.03265  time: 0.1855  data_time: 0.0100  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:33 d2.utils.events]: [39m eta: 5:20:22  iter: 1289  total_loss: 1.048  loss_cls: 0.5277  loss_box_reg: 0.3527  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.03951  time: 0.1855  data_time: 0.0097  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:34 d2.utils.events]: [39m eta: 5:20:21  iter: 1294  total_loss: 0.9902  loss_cls: 0.509  loss_box_reg: 0.3501  loss_rpn_cls: 0.08233  loss_rpn_loc: 0.03951  time: 0.1855  data_time: 0.0092  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:35 d2.utils.events]: [39m eta: 5:20:20  iter: 1299  total_loss: 1.035  loss_cls: 0.5183  loss_box_reg: 0.354  loss_rpn_cls: 0.08625  loss_rpn_loc: 0.04317  time: 0.1855  data_time: 0.0091  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:36 d2.utils.events]: [39m eta: 5:20:19  iter: 1304  total_loss: 0.9891  loss_cls: 0.5074  loss_box_reg: 0.3346  loss_rpn_cls: 0.08625  loss_rpn_loc: 0.03984  time: 0.1855  data_time: 0.0096  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:37 d2.utils.events]: [39m eta: 5:20:18  iter: 1309  total_loss: 0.9728  loss_cls: 0.5322  loss_box_reg: 0.3205  loss_rpn_cls: 0.05768  loss_rpn_loc: 0.03275  time: 0.1855  data_time: 0.0092  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:38 d2.utils.events]: [39m eta: 5:20:18  iter: 1314  total_loss: 0.9986  loss_cls: 0.5571  loss_box_reg: 0.3365  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.03976  time: 0.1855  data_time: 0.0091  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:38 d2.utils.events]: [39m eta: 5:20:22  iter: 1319  total_loss: 1.009  loss_cls: 0.5571  loss_box_reg: 0.3597  loss_rpn_cls: 0.06856  loss_rpn_loc: 0.03538  time: 0.1855  data_time: 0.0091  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:39 d2.utils.events]: [39m eta: 5:20:23  iter: 1324  total_loss: 1.017  loss_cls: 0.5554  loss_box_reg: 0.3959  loss_rpn_cls: 0.07625  loss_rpn_loc: 0.03577  time: 0.1855  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:40 d2.utils.events]: [39m eta: 5:20:23  iter: 1329  total_loss: 1.017  loss_cls: 0.5502  loss_box_reg: 0.3948  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.02519  time: 0.1855  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:41 d2.utils.events]: [39m eta: 5:20:24  iter: 1334  total_loss: 1.012  loss_cls: 0.5274  loss_box_reg: 0.3905  loss_rpn_cls: 0.05727  loss_rpn_loc: 0.02493  time: 0.1855  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:42 d2.utils.events]: [39m eta: 5:20:23  iter: 1339  total_loss: 0.9615  loss_cls: 0.5076  loss_box_reg: 0.3488  loss_rpn_cls: 0.04432  loss_rpn_loc: 0.01791  time: 0.1855  data_time: 0.0098  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:43 d2.utils.events]: [39m eta: 5:20:25  iter: 1344  total_loss: 0.9315  loss_cls: 0.5222  loss_box_reg: 0.3469  loss_rpn_cls: 0.03483  loss_rpn_loc: 0.0158  time: 0.1856  data_time: 0.0110  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:44 d2.utils.events]: [39m eta: 5:20:25  iter: 1349  total_loss: 0.9973  loss_cls: 0.541  loss_box_reg: 0.3469  loss_rpn_cls: 0.04801  loss_rpn_loc: 0.01908  time: 0.1856  data_time: 0.0110  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:45 d2.utils.events]: [39m eta: 5:20:25  iter: 1354  total_loss: 1.011  loss_cls: 0.5676  loss_box_reg: 0.338  loss_rpn_cls: 0.04801  loss_rpn_loc: 0.01236  time: 0.1855  data_time: 0.0109  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:46 d2.utils.events]: [39m eta: 5:20:24  iter: 1359  total_loss: 1.007  loss_cls: 0.5778  loss_box_reg: 0.325  loss_rpn_cls: 0.04801  loss_rpn_loc: 0.01284  time: 0.1855  data_time: 0.0094  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:47 d2.utils.events]: [39m eta: 5:20:22  iter: 1364  total_loss: 0.989  loss_cls: 0.546  loss_box_reg: 0.3582  loss_rpn_cls: 0.05566  loss_rpn_loc: 0.01957  time: 0.1855  data_time: 0.0082  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:48 d2.utils.events]: [39m eta: 5:20:20  iter: 1369  total_loss: 0.9531  loss_cls: 0.5084  loss_box_reg: 0.3407  loss_rpn_cls: 0.04328  loss_rpn_loc: 0.01957  time: 0.1855  data_time: 0.0081  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:49 d2.utils.events]: [39m eta: 5:20:18  iter: 1374  total_loss: 0.9838  loss_cls: 0.511  loss_box_reg: 0.3456  loss_rpn_cls: 0.05437  loss_rpn_loc: 0.02971  time: 0.1855  data_time: 0.0081  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:50 d2.utils.events]: [39m eta: 5:20:15  iter: 1379  total_loss: 1.039  loss_cls: 0.5269  loss_box_reg: 0.3771  loss_rpn_cls: 0.09321  loss_rpn_loc: 0.04222  time: 0.1855  data_time: 0.0081  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:51 d2.utils.events]: [39m eta: 5:20:17  iter: 1384  total_loss: 1.062  loss_cls: 0.5568  loss_box_reg: 0.3717  loss_rpn_cls: 0.09321  loss_rpn_loc: 0.03579  time: 0.1855  data_time: 0.0082  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:52 d2.utils.events]: [39m eta: 5:20:16  iter: 1389  total_loss: 1.138  loss_cls: 0.5701  loss_box_reg: 0.3767  loss_rpn_cls: 0.09839  loss_rpn_loc: 0.05232  time: 0.1855  data_time: 0.0082  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:52 d2.utils.events]: [39m eta: 5:20:16  iter: 1394  total_loss: 1.02  loss_cls: 0.5432  loss_box_reg: 0.3717  loss_rpn_cls: 0.08702  loss_rpn_loc: 0.03042  time: 0.1854  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:53 d2.utils.events]: [39m eta: 5:20:16  iter: 1399  total_loss: 1.037  loss_cls: 0.5701  loss_box_reg: 0.3635  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.02874  time: 0.1854  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:54 d2.utils.events]: [39m eta: 5:20:15  iter: 1404  total_loss: 1.064  loss_cls: 0.5782  loss_box_reg: 0.3744  loss_rpn_cls: 0.07034  loss_rpn_loc: 0.0298  time: 0.1854  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:55 d2.utils.events]: [39m eta: 5:20:14  iter: 1409  total_loss: 1.139  loss_cls: 0.6057  loss_box_reg: 0.4015  loss_rpn_cls: 0.06298  loss_rpn_loc: 0.0274  time: 0.1854  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:56 d2.utils.events]: [39m eta: 5:20:13  iter: 1414  total_loss: 1.12  loss_cls: 0.6028  loss_box_reg: 0.3954  loss_rpn_cls: 0.07363  loss_rpn_loc: 0.02753  time: 0.1854  data_time: 0.0082  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:57 d2.utils.events]: [39m eta: 5:20:12  iter: 1419  total_loss: 1.12  loss_cls: 0.581  loss_box_reg: 0.3954  loss_rpn_cls: 0.07363  loss_rpn_loc: 0.02753  time: 0.1854  data_time: 0.0082  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:58 d2.utils.events]: [39m eta: 5:20:11  iter: 1424  total_loss: 1.099  loss_cls: 0.5757  loss_box_reg: 0.3756  loss_rpn_cls: 0.07631  loss_rpn_loc: 0.02753  time: 0.1854  data_time: 0.0082  lr: 0.001  max_mem: 1812M
[32m[03/28 03:22:59 d2.utils.events]: [39m eta: 5:20:10  iter: 1429  total_loss: 1.037  loss_cls: 0.5628  loss_box_reg: 0.3429  loss_rpn_cls: 0.06461  loss_rpn_loc: 0.0267  time: 0.1854  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:00 d2.utils.events]: [39m eta: 5:20:09  iter: 1434  total_loss: 0.9559  loss_cls: 0.5628  loss_box_reg: 0.3479  loss_rpn_cls: 0.04632  loss_rpn_loc: 0.01677  time: 0.1853  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:01 d2.utils.events]: [39m eta: 5:20:11  iter: 1439  total_loss: 0.9559  loss_cls: 0.5354  loss_box_reg: 0.3479  loss_rpn_cls: 0.03315  loss_rpn_loc: 0.01677  time: 0.1853  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:02 d2.utils.events]: [39m eta: 5:20:13  iter: 1444  total_loss: 0.9629  loss_cls: 0.5354  loss_box_reg: 0.3681  loss_rpn_cls: 0.03083  loss_rpn_loc: 0.01479  time: 0.1853  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:03 d2.utils.events]: [39m eta: 5:20:12  iter: 1449  total_loss: 1.014  loss_cls: 0.5438  loss_box_reg: 0.3941  loss_rpn_cls: 0.04309  loss_rpn_loc: 0.01569  time: 0.1853  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:03 d2.utils.events]: [39m eta: 5:20:10  iter: 1454  total_loss: 1.059  loss_cls: 0.5392  loss_box_reg: 0.4061  loss_rpn_cls: 0.06561  loss_rpn_loc: 0.02778  time: 0.1853  data_time: 0.0083  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:04 d2.utils.events]: [39m eta: 5:20:11  iter: 1459  total_loss: 1.041  loss_cls: 0.5516  loss_box_reg: 0.3506  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.02824  time: 0.1853  data_time: 0.0084  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:05 d2.utils.events]: [39m eta: 5:20:13  iter: 1464  total_loss: 1.073  loss_cls: 0.5516  loss_box_reg: 0.3667  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.03014  time: 0.1853  data_time: 0.0087  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:06 d2.utils.events]: [39m eta: 5:20:13  iter: 1469  total_loss: 1.025  loss_cls: 0.5305  loss_box_reg: 0.3305  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.02824  time: 0.1853  data_time: 0.0090  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:07 d2.utils.events]: [39m eta: 5:20:14  iter: 1474  total_loss: 0.9944  loss_cls: 0.4809  loss_box_reg: 0.3387  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.02773  time: 0.1853  data_time: 0.0091  lr: 0.001  max_mem: 1812M
[32m[03/28 03:23:08 d2.engine.hooks]: [39mOverall training speed: 1476 iterations in 0:04:33 (0.1854 s / it)
[32m[03/28 03:23:08 d2.engine.hooks]: [39mTotal training time: 0:05:08 (0:00:34 on hooks)
[32m[03/28 03:23:08 d2.utils.events]: [39m eta: 5:20:15  iter: 1478  total_loss: 0.9205  loss_cls: 0.474  loss_box_reg: 0.3324  loss_rpn_cls: 0.06331  loss_rpn_loc: 0.03004  time: 0.1853  data_time: 0.0090  lr: 0.001  max_mem: 1812M
Traceback (most recent call last):
  File "train.py", line 153, in <module>
    trainer.train()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 491, in train
    super().train(self.start_iter, self.max_iter)
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 150, in train
    self.run_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/defaults.py", line 501, in run_step
    self._trainer.run_step()
  File "/opt/ml/detection/baseline/detectron2/detectron2/engine/train_loop.py", line 400, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/meta_arch/rcnn.py", line 157, in forward
    proposals, proposal_losses = self.proposal_generator(images, features, gt_instances)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/proposal_generator/rpn.py", line 452, in forward
    anchors = self.anchor_generator(features)
  File "/opt/conda/envs/detection/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/anchor_generator.py", line 226, in forward
    anchors_over_all_feature_maps = self._grid_anchors(grid_sizes)
  File "/opt/ml/detection/baseline/detectron2/detectron2/modeling/anchor_generator.py", line 171, in _grid_anchors
    shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
KeyboardInterrupt