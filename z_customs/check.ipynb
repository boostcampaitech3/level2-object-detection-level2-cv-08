{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874ba7a9e5e94bbdbdad4672e1c501a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=50, continuous_update=False, description='Img idx'), IntSlider(value=50, contin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = widgets.IntSlider(description='Img idx', continuous_update=False)\n",
    "w1 = widgets.IntSlider(description='bbox threshold', continuous_update=False)\n",
    "w.value=50 # 처음 값 조정\n",
    "widgets.link((w, 'value'), (w1, 'value'))\n",
    "widgets.VBox([w, w1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5559f7a65378465d97edbe1c163896ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='freq', max=3, min=-1), Dropdown(description='color', opt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "@widgets.interact_manual(color=['blue', 'red', 'green'], lw=(1.0,10.0))\n",
    "def plot(freq=1, color='blue', lw=2, grid=True):\n",
    "    \n",
    "    t = np.linspace(-1, 1, 1000)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(t, np.sin(2*np.pi*freq*t), lw=lw, color=color)\n",
    "    ax.grid(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568df3ed8ac149e7899645c303799480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=10), IntSlider(value=0, description='threshold…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description='save image')\n",
    "output = widgets.Output()\n",
    "def clicked(b):\n",
    "    with output:\n",
    "        print('hi')\n",
    "@interact(idx=(0, 10), threshold=(0, 10))\n",
    "def showImg(idx=0, threshold=0):\n",
    "    display(button, output)\n",
    "    button.on_click(clicked)\n",
    "    print(idx, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroundTruthString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 197.6 193.7 745.4 663.4</td>\n",
       "      <td>train/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 0.0 407.4 57.6 588.0 7 0.0 455.6 144.6 637.2...</td>\n",
       "      <td>train/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 267.9 165.2 899.5 678.2</td>\n",
       "      <td>train/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 462.2 369.4 696.1 624.0 6 773.3 3.0 961.6999...</td>\n",
       "      <td>train/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 567.5 462.2 732.7 551.6 1 859.4 411.7 1023.5...</td>\n",
       "      <td>train/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   GroundTruthString        image_id\n",
       "0                         0 197.6 193.7 745.4 663.4   train/0000.jpg\n",
       "1  3 0.0 407.4 57.6 588.0 7 0.0 455.6 144.6 637.2...  train/0001.jpg\n",
       "2                         3 267.9 165.2 899.5 678.2   train/0002.jpg\n",
       "3  2 462.2 369.4 696.1 624.0 6 773.3 3.0 961.6999...  train/0003.jpg\n",
       "4  1 567.5 462.2 732.7 551.6 1 859.4 411.7 1023.5...  train/0004.jpg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeGroundTruthDF(annotation_path):\n",
    "    coco = COCO(annotation_path)\n",
    "\n",
    "    img_id = coco.getImgIds()\n",
    "    img_info = coco.loadImgs(img_id)\n",
    "    fnames = [info['file_name'] for info in img_info]\n",
    "    ids = [info['id'] for info in img_info]\n",
    "    \n",
    "    gt_string = []\n",
    "    for id in ids:\n",
    "        ann_id = coco.getAnnIds(imgIds=id)\n",
    "        annotation_info_list = coco.loadAnns(ann_id)\n",
    "\n",
    "        string_temp = \"\"\n",
    "        fname_idx = annotation_info_list[0]['image_id'] # img_id index\n",
    "        for ann_info in annotation_info_list:\n",
    "            category_id = ann_info['category_id']\n",
    "            x,y,w,h = ann_info['bbox'] # bbox coordinate\n",
    "            x,y,x1,y1 = str(x), str(y), str(x+w), str(y+h)\n",
    "            string_temp += (str(category_id) + ' ' + x + ' ' + y + ' ' + x1 + ' ' + y1 + ' ')\n",
    "            \n",
    "        gt_string.append(string_temp)\n",
    "    return pd.DataFrame(data=list(zip(gt_string, fnames)), columns=['GroundTruthString','image_id'])\n",
    "\n",
    "gt_df = makeGroundTruthDF('/opt/ml/detection/dataset/train.json')\n",
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no boxes found in test/4194.jpg!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1608, 3944, 504, 471, 761, 1769, 1082, 2719, 121, 298]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 같은 class에 대해서 confidence 기준 정렬\n",
    "# 그 중 IoU가 가장 큰 Bbox를 정답으로 여김\n",
    "submission = pd.read_csv('/opt/ml/detection/baseline/faster_rcnn/faster_rcnn_torchvision_submission_2.csv')\n",
    "\n",
    "def IOU(gt, pred):\n",
    "    gt = [float(gt[0]), float(gt[1]), float(gt[2]), float(gt[3])]\n",
    "    pred = [float(pred[0]), float(pred[1]), float(pred[2]), float(pred[3])]\n",
    "\n",
    "    gt_area = (gt[2]-gt[0])*(gt[3]-gt[1])\n",
    "    pred_area = (pred[2]-pred[0])*(pred[3]-pred[1])\n",
    "    \n",
    "    x = max(gt[0], pred[0])\n",
    "    y = max(gt[1], pred[1])\n",
    "    x1 = min(gt[2], pred[2])\n",
    "    y1 = min(gt[3], pred[3])\n",
    "\n",
    "    w = max(0, x1-x)\n",
    "    h = max(0, y1-y)\n",
    "\n",
    "    inter = w*h\n",
    "    iou = inter / (gt_area + pred_area - inter)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def matchBbox(gt_df, predict_df, iou_threshold=0):\n",
    "    wrong_per_cls = [0 for _ in range(10)]\n",
    "\n",
    "    for i in range(len(predict_df)):\n",
    "        try:\n",
    "            predict_string = np.asarray(predict_df.iloc[i]['PredictionString'].split(' ')[:-1]).reshape(-1, 6)\n",
    "            fname = predict_df.iloc[i]['image_id']\n",
    "            gt_string = np.asarray(gt_df.iloc[i]['GroundTruthString'].split(' ')[:-1]).reshape(-1, 5)\n",
    "            check = [False for _ in range(len(gt_string))]\n",
    "            for pred_row in predict_string:\n",
    "                pred_cls = pred_row[0]\n",
    "                pred_conf = pred_row[1]\n",
    "                max_iou = 0\n",
    "                correct_idx = -1\n",
    "                for idx, gt_row in enumerate(gt_string):\n",
    "                    if(check[idx]):\n",
    "                        continue\n",
    "                    gt_cls = gt_row[0]\n",
    "                    iou = IOU(gt_row[1:], pred_row[2:])\n",
    "                    if(gt_cls==pred_cls and iou >= iou_threshold and max_iou < iou):\n",
    "                        max_iou = iou\n",
    "                        correct_idx = idx\n",
    "                check[correct_idx]=True\n",
    "\n",
    "            for idx, gt_row in enumerate(gt_string):\n",
    "                if(not check[idx]):\n",
    "                    wrong_per_cls[int(gt_row[0])]+=1\n",
    "\n",
    "        except:\n",
    "            gt_string = np.asarray(gt_df.iloc[i]['GroundTruthString'].split(' ')[:-1]).reshape(-1, 5)\n",
    "            for gt_row in gt_string:\n",
    "                wrong_per_cls[int(gt_row[0])]+=1\n",
    "\n",
    "            img_id = predict_df.iloc[i]['image_id']\n",
    "            print(f'no boxes found in {img_id}!')\n",
    "\n",
    "            pass\n",
    "    return wrong_per_cls\n",
    "matchBbox(gt_df, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGroundTruthDF(annotation_path):\n",
    "    coco = COCO(annotation_path)\n",
    "\n",
    "    img_id = coco.getImgIds()\n",
    "    img_info = coco.loadImgs(img_id)\n",
    "    fnames = [info['file_name'] for info in img_info]\n",
    "    ids = [info['id'] for info in img_info]\n",
    "    \n",
    "    gt_string = []\n",
    "    for id in ids:\n",
    "        ann_id = coco.getAnnIds(imgIds=id)\n",
    "        annotation_info_list = coco.loadAnns(ann_id)\n",
    "        \n",
    "        string_temp = \"\"\n",
    "        fname_idx = annotation_info_list[0]['image_id'] # img_id index\n",
    "        for ann_info in annotation_info_list:\n",
    "            category_id = ann_info['category_id']\n",
    "            x,y,w,h = ann_info['bbox'] # bbox coordinate\n",
    "            x,y,x1,y1 = str(x), str(y), str(x+w), str(y+h)\n",
    "            string_temp += (str(category_id) + ' ' + x + ' ' + y + ' ' + x1 + ' ' + y1 + ' ')\n",
    "            \n",
    "        gt_string.append(string_temp)\n",
    "    return pd.DataFrame(data=list(zip(gt_string, fnames)), columns=['GroundTruthString','image_id'])\n",
    "\n",
    "gt_df = makeGroundTruthDF('/opt/ml/detection/dataset/train.json')\n",
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 class에 대해서 confidence 기준 정렬\n",
    "# 그 중 IoU가 가장 큰 Bbox를 정답으로 여김\n",
    "submission = pd.read_csv('/opt/ml/detection/baseline/mmdetection/work_dirs/yolov3_d53_320_273e_coco_custom_trash/submission_epoch_15.csv')\n",
    "\n",
    "def IOU(gt, pred):\n",
    "    gt = [float(gt[0]), float(gt[1]), float(gt[2]), float(gt[3])]\n",
    "    pred = [float(pred[0]), float(pred[1]), float(pred[2]), float(pred[3])]\n",
    "\n",
    "    gt_area = (gt[2]-gt[0])*(gt[3]-gt[1])\n",
    "    pred_area = (pred[2]-pred[0])*(pred[3]-pred[1])\n",
    "    \n",
    "    x = max(gt[0], pred[0])\n",
    "    y = max(gt[1], pred[1])\n",
    "    x1 = min(gt[2], pred[2])\n",
    "    y1 = min(gt[3], pred[3])\n",
    "\n",
    "    w = max(0, x1-x)\n",
    "    h = max(0, y1-y)\n",
    "\n",
    "    inter = w*h\n",
    "    iou = inter / (gt_area + pred_area - inter)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def matchBbox(gt_df, predict_df, iou_threshold=0):\n",
    "    wrong_per_cls = [0 for _ in range(10)]\n",
    "    # class별로 못 맞춘 개수 저장하는 변수\n",
    "    \n",
    "    total_img = len(predict_df)\n",
    "\n",
    "    img_pred_gt_match = [[] for _ in range(total_img)]\n",
    "    # 이미지마다 predict와 gt를 matching하고 맞춘 predict, gt를 저장하기 위한 변수\n",
    "    \n",
    "    for i in range(total_img):\n",
    "        # 모든 이미지에 대해 검사\n",
    "        try:\n",
    "            fname = predict_df.iloc[i]['image_id']\n",
    "            predict_string = np.asarray(predict_df.iloc[i]['PredictionString'].split(' ')[:-1]).reshape(-1, 6)\n",
    "            gt_string = np.asarray(gt_df.iloc[i]['GroundTruthString'].split(' ')[:-1]).reshape(-1, 5)\n",
    "            num_gt = len(gt_string)\n",
    "            num_pred = len(predict_string)\n",
    "\n",
    "            check = [False for _ in range(num_gt)]\n",
    "            # predict한 bbox와 matching된 ground_truth 확인하기\n",
    "            # matching된 게 있으면 True, 없으면 False저장\n",
    "\n",
    "            gt_pred_match = []\n",
    "            # 각각의 predict한 bbox와 가장 잘 맞는 gt bbox 저장하기 위한 리스트\n",
    "\n",
    "            for pred_idx, pred_row in enumerate(predict_string):\n",
    "                pred_cls = pred_row[0]\n",
    "                pred_conf = pred_row[1]\n",
    "\n",
    "                max_iou = 0\n",
    "                matched_gt_idx = -1\n",
    "                # predict한 bbox와 전체 gt와 비교하여 가장 잘 맞은 gt idx를 저장하기 위한 변수\n",
    "\n",
    "                for gt_idx, gt_row in enumerate(gt_string):\n",
    "                    \n",
    "                    iou = IOU(gt_row[1:], pred_row[2:])\n",
    "                    # predict bbox와 gt bbox IOU 계산\n",
    "                    gt_cls = gt_row[0]\n",
    "                    if(gt_cls==pred_cls and iou >= iou_threshold and max_iou < iou):\n",
    "                        # 만약 class가 동일하고, IOU가 threshold보다 크며, 이전까지 가장 잘 맞는 IOU보다 현재가 더 큰 경우 갱신\n",
    "                        max_iou = iou\n",
    "                        matched_gt_idx = gt_idx\n",
    "\n",
    "                if(matched_gt_idx!=-1):\n",
    "                    # threshold이상으로 잘 맞는 gt bbox가 있다면 저장\n",
    "                    \n",
    "                    gt_pred_match.append([pred_idx, matched_gt_idx, max_iou])\n",
    "                    # 이미지에서 predict한 bbox index, 가장 잘 맞는 gt index, 해당 IOU\n",
    "\n",
    "                    check[matched_gt_idx]=True\n",
    "                    # predict한 bbox가 gt를 잘 맞췄으니, 해당 gt를 True로 변경\n",
    "                    # (못 맞춘 gt 개수 파악을 위한 용도)\n",
    "\n",
    "            for idx, gt_row in enumerate(gt_string):\n",
    "                if(not check[idx]):\n",
    "                    # 만약 gt와 맞는 prediction이 없다면\n",
    "                    wrong_per_cls[int(gt_row[0])]+=1\n",
    "                    # 해당 gt의 class는 못 맞춘 것이므로 1증가\n",
    "            \n",
    "            img_pred_gt_match[i].append(gt_pred_match)\n",
    "            # 해당 이미지의 gt_pred_match를 저장\n",
    "            # 시각화할 때 편하려고 만듬\n",
    "\n",
    "        except:\n",
    "            # 예측한 bbox가 없는 경우\n",
    "            gt_string = np.asarray(gt_df.iloc[i]['GroundTruthString'].split(' ')[:-1]).reshape(-1, 5)\n",
    "            for gt_row in gt_string:\n",
    "                wrong_per_cls[int(gt_row[0])]+=1\n",
    "            # 모든 gt를 못 맞췄으므로 해당 gt class마다 1증가\n",
    "\n",
    "            img_id = predict_df.iloc[i]['image_id']\n",
    "            print(f'no boxes found in {img_id}!')\n",
    "\n",
    "            pass\n",
    "    return img_pred_gt_match, wrong_per_cls\n",
    "img_pred_gt_match, wrong_per_cls = matchBbox(gt_df, submission)\n",
    "print(wrong_per_cls)\n",
    "print(img_pred_gt_match[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ipywidgets import interact\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "num_img = len(submission)\n",
    "\n",
    "def showBoxes(img, boxes, ax, gt=True, clicked=-1):\n",
    "    # gt와 confidence score가 없으므로 argument로 넣어줌\n",
    "\n",
    "    palette = sns.color_palette('bright')\n",
    "    ax.imshow(img)\n",
    "    if gt:\n",
    "        for i in range(0, len(boxes)):\n",
    "            class_idx = int(boxes[i][0])\n",
    "            color = palette[class_idx]\n",
    "            x,y,x1,y1 = boxes[i][1:5]\n",
    "            x,y,x1,y1 = float(x), float(y), float(x1), float(y1)\n",
    "            ax.add_patch(\n",
    "                patches.Rectangle(\n",
    "                    (x,y), x1-x, y1-y,\n",
    "                    edgecolor=color,\n",
    "                    linewidth=1,\n",
    "                    fill=False,\n",
    "                    ),\n",
    "                )\n",
    "            text_y = y-20 if y>20 else y+20 \n",
    "            ax.text(x+18,text_y, f'{classes[class_idx]}', color='white', fontsize='5', weight='semibold', backgroundcolor=color)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    else:\n",
    "        for i in range(0, len(boxes)):\n",
    "            class_idx = int(boxes[i][0])\n",
    "            color = palette[class_idx]\n",
    "            conf = float(boxes[i][1])\n",
    "            x,y,x1,y1 = boxes[i][2:6]\n",
    "            x,y,x1,y1 = float(x), float(y), float(x1), float(y1)\n",
    "            ax.add_patch(\n",
    "                patches.Rectangle(\n",
    "                    (x,y), x1-x, y1-y,\n",
    "                    edgecolor=color,\n",
    "                    linewidth=1,\n",
    "                    fill=False,\n",
    "                    ),\n",
    "                )\n",
    "            text_y = y-20 if y>20 else y+20 \n",
    "            ax.text(x+18,text_y, f'{classes[class_idx]}({conf:.2f})', color='white', fontsize='5', weight='semibold', backgroundcolor=color)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "@interact(idx=(0, num_img-1))\n",
    "def showImg(idx):\n",
    "    fig, ax = plt.subplots(1, 3, dpi=150)\n",
    "    img = io.imread(os.path.join('/opt/ml/detection/dataset', submission.iloc[idx]['image_id']))\n",
    "    boxes_pred = np.asarray(submission.iloc[idx]['PredictionString'].split(' ')[:-1]).reshape(-1, 6)\n",
    "    boxes_gt = np.asarray(gt_df.iloc[idx]['GroundTruthString'].split(' ')[:-1]).reshape(-1, 5)\n",
    "\n",
    "    total_idx = np.ones(len(boxes_pred))\n",
    "    \n",
    "    try:\n",
    "        positive_box_idx = np.array(img_pred_gt_match[idx])[...,0].squeeze().astype(int)\n",
    "        boxes_pos = boxes_pred[positive_box_idx]\n",
    "        total_idx[positive_box_idx]=0\n",
    "        showBoxes(boxes_pos, ax[1])\n",
    "    except:\n",
    "        ax[1].imshow(img)  \n",
    "        ax[1].set_xticks([])\n",
    "        ax[1].set_yticks([])\n",
    "\n",
    "    negative_box_idx = np.where(total_idx==1)[0]\n",
    "    # 좀 조잡한데, positive랑 negative index 추출\n",
    "    boxes_neg = boxes_pred[negative_box_idx]\n",
    "        # positive, negative box 추출\n",
    "    ax[0].set_title('GT')\n",
    "    ax[1].set_title('Pos')\n",
    "    ax[2].set_title('Neg')\n",
    "    showBoxes(img, boxes_gt, ax[0], gt=True, clicked=-1)\n",
    "    showBoxes(img, boxes_neg, ax[2])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5d7164c64e63af887b53f785b7c056834a1b06812e2ab286d66941e0de4c0dd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mmdet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
